{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 14.3 用于预训练词嵌入的数据集\n",
    "- **目录**\n",
    "  - 14.3.1 读取词嵌入数据集\n",
    "  - 14.3.2 词嵌入的下采样\n",
    "  - 14.3.3 中心词和上下文词的提取\n",
    "  - 14.3.4 词嵌入负采样\n",
    "  - 14.3.5 小批量加载词嵌入训练数据实例\n",
    "  - 14.3.6 整合词嵌入数据集代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 现在已经了解了word2vec模型的技术细节和大致的训练方法，让我们来看看它们的实现。\n",
    "  - 具体地说，本节将以14.1节的跳元模型和14.2节的负采样为例。\n",
    "- 本节从用于预训练词嵌入模型的数据集开始：数据的原始格式将被转换为可以在训练期间迭代的小批量。\n",
    "- 本节的函数与API列表：\n",
    "  - read_ptb：读取PTB数据集。\n",
    "  - subsample：下采样。\n",
    "  - show_list_len_pair_hist：绘制了下采样前后每句话的词元数量的直方图。\n",
    "  - compare_counts：比较下采样前后的某个词元的词频。\n",
    "  - get_centers_and_contexts：获取“中心词-上下文词”对。\n",
    "  - RandomGenerator：对噪声词进行随机采样。\n",
    "  - get_negatives：返回负采样的噪声词（或负样本，二者表示相同对象，即通过负采样得到的词）。\n",
    "  - batchify：返回带有负采样的跳元模型的小批量样本。\n",
    "  - load_data_ptb：下载PTB数据集，然后将其加载到内存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "- **说明：如果发生Unable to retrieve source for @torch.jit._overload function警告**\n",
    "  - 则修改此文件“F:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torch\\_jit_internal.py”\n",
    "  <center><img src='../img/14_3_1.png'></center>\n",
    "  - 该警告不影响运行，只是有点影响观感。\n",
    "--------\n",
    "\n",
    "## 14.3.1 读取词嵌入数据集\n",
    "- 此处使用的数据集是[Penn Tree Bank（PTB）](https://catalog.ldc.upenn.edu/LDC99T42)。\n",
    "- 该语料库取自“华尔街日报”的文章，分为**训练集**、**验证集**和**测试集**。\n",
    "- 在原始格式中，文本文件的每一行表示由空格分隔的一句话。在这里，我们将每个单词视为一个词元。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# sentences数: 42069'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip',\n",
    "                       '319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "\n",
    "#@save\n",
    "def read_ptb():\n",
    "    \"\"\"将PTB数据集加载到文本行的列表中\"\"\"\n",
    "    data_dir = d2l.download_extract('ptb')\n",
    "    # Readthetrainingset.\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "sentences = read_ptb()\n",
    "f'# sentences数: {len(sentences)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " [['aer',\n",
       "   'banknote',\n",
       "   'berlitz',\n",
       "   'calloway',\n",
       "   'centrust',\n",
       "   'cluett',\n",
       "   'fromstein',\n",
       "   'gitano',\n",
       "   'guterman',\n",
       "   'hydro-quebec',\n",
       "   'ipo',\n",
       "   'kia',\n",
       "   'memotec',\n",
       "   'mlx',\n",
       "   'nahb',\n",
       "   'punts',\n",
       "   'rake',\n",
       "   'regatta',\n",
       "   'rubens',\n",
       "   'sim',\n",
       "   'snack-food',\n",
       "   'ssangyong',\n",
       "   'swapo',\n",
       "   'wachter'],\n",
       "  ['pierre',\n",
       "   '<unk>',\n",
       "   'N',\n",
       "   'years',\n",
       "   'old',\n",
       "   'will',\n",
       "   'join',\n",
       "   'the',\n",
       "   'board',\n",
       "   'as',\n",
       "   'a',\n",
       "   'nonexecutive',\n",
       "   'director',\n",
       "   'nov.',\n",
       "   'N']])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences),sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "- 在读取训练集之后，再为语料库构建了一个词表，其中出现次数少于10次的任何单词都将由“&lt;unk&gt;”词元替换。\n",
    "- 请注意，原始数据集还包含表示稀有（未知）单词的“&lt;unk&gt;”词元。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('for', 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.idx_to_token[10],vocab.token_to_idx['for']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "## 14.3.2 词嵌入的下采样\n",
    "\n",
    "- 文本数据通常有“the”、“a”和“in”等高频词：这些词在非常大的语料库中甚至可能出现数十亿次。\n",
    "- 然而，这些词经常在上下文窗口中与许多不同的词共同出现，**提供的有用信息很少**。\n",
    "  - 例如，考虑上下文窗口中的词“chip”：直观地说，它与低频单词“intel”的共现比与高频单词“a”的共现在训练中更有用。\n",
    "  - 此外，**大量（高频）单词导致模型的训练速度放慢**。\n",
    "- 因此，当训练词嵌入模型时，可以对高频单词进行**下采样**。具体地说，数据集中的每个词$w_i$将有概率地被丢弃\n",
    "$$ P(w_i) = \\max\\left(1 - \\sqrt{\\frac{t}{f(w_i)}}, 0\\right),\\tag{13.4.1}$$\n",
    "  - 其中$f(w_i)$是$w_i$的词数与数据集中的总词数的比率，常量$t$是超参数（在实验中为$10^{-4}$）。我们可以看到，只有当相对比率$f(w_i) > t$时，（高频）词$w_i$才能被丢弃，且该词的相对比率越高，被丢弃的概率就越大。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "- **说明：如何理解公式$13.4.1$ ?**\n",
    "  - 公式公式$13.4.1$ 用于下采样高频词。这种下采样策略是在词嵌入中为了减少训练的计算开销和改善词嵌入质量而采用的。\n",
    "  - **为什么下采样高频词？**\n",
    "    - 在文本数据中，某些高频词（如 \"the\"、\"is\"）提供的语义信息相对较少。\n",
    "    - **由于它们几乎在每个上下文中都出现，所以它们对于特定的语义关系的建模贡献不大**。\n",
    "    - 通过下采样这些词，我们可以减少训练的计算负担，并更加关注**对模型更有意义的低频词**。\n",
    "  - **如何理解$f(w_i)$ ?**\n",
    "    - $f(w_i)$是词$w_i$的词频与数据集中的总词数的比例。这给出了一个词在文本中的相对频率。\n",
    "    - 例如，如果 \"the\" 出现了 1000 次，而总词数是 10000，那么$f(\\text{\"the\"}) = 0.1$。\n",
    "  - **为什么使用$\\sqrt{\\frac{t}{f(w_i)}}$ ?**\n",
    "    - 这个公式的设计是为了**在词频$f(w_i)$增加时增加丢弃概率**。\n",
    "    - 常数$t$是一个阈值，决定哪些词有可能被下采样。\n",
    "    - 当$f(w_i)$小于$t$时，其丢弃概率接近于 0。而当$f(w_i)$远大于$t$时，丢弃概率接近于 1。\n",
    "  - **为什么有$\\max$函数？**\n",
    "    - $\\max$函数确保丢弃概率不会为负。这是为了处理那些频率非常低的词，因为在这些情况下，公式可能会给出负的概率值。\n",
    "- **示例：从下图可以看到随着词频的增加，其下采样概率也逐渐增加**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Python示例进一步理解：\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义下采样概率函数\n",
    "def subsampling_prob(f_wi, t=1e-4):\n",
    "    return max(1 - np.sqrt(t / f_wi), 0)\n",
    "\n",
    "# 生成模拟的词频数据\n",
    "frequencies = np.linspace(1e-5, 1e-2, 1000)  # 模拟从非常低频到较高频的单词\n",
    "\n",
    "# 计算丢弃概率\n",
    "drop_probs = [subsampling_prob(f) for f in frequencies]\n",
    "\n",
    "# 绘图\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用'SimHei'字体（黑体）\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(frequencies, drop_probs)\n",
    "plt.xlabel('词频 ($f(w_i)$)')\n",
    "plt.ylabel('丢弃概率 ($P(w_i)$)')\n",
    "plt.title('下采样概率 vs 词频')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def subsample(sentences, vocab):\n",
    "    \"\"\"下采样高频词\"\"\"\n",
    "    # 排除未知词元'<unk>'\n",
    "    sentences = [[token for token in line if vocab[token] != vocab.unk]\n",
    "                 for line in sentences]\n",
    "    counter = d2l.count_corpus(sentences)\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # 如果在下采样期间保留词元，则返回True\n",
    "    def keep(token):\n",
    "        '''\n",
    "        keep函数并没有计算丢弃概率。\n",
    "        相反，它比较一个随机数与下采样阈值。\n",
    "        如果随机数小于这个阈值，就保留这个词。\n",
    "        虽然这种方法并不直接计算丢弃概率，\n",
    "        但它仍然实现了与公式中描述的下采样策略相似的目的：高频词被丢弃的概率会更高。\n",
    "        也就是说：词抛弃是概率，并不是根据公式和阈值硬性规定的。\n",
    "        '''\n",
    "        return(random.uniform(0, 1) <\n",
    "               math.sqrt(1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    return ([[token for token in line if keep(token)] for line in sentences],\n",
    "            counter)\n",
    "\n",
    "subsampled, counter = subsample(sentences, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50770, 263)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词频字典\n",
    "counter['the'], counter['john']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42069,\n",
       " [[],\n",
       "  ['join', 'nov.'],\n",
       "  ['is', 'chairman', 'n.v.', 'dutch', 'publishing'],\n",
       "  ['years',\n",
       "   'of',\n",
       "   'consolidated',\n",
       "   'fields',\n",
       "   'plc',\n",
       "   'named',\n",
       "   'director',\n",
       "   'this',\n",
       "   'conglomerate'],\n",
       "  ['form',\n",
       "   'asbestos',\n",
       "   'once',\n",
       "   'used',\n",
       "   'kent',\n",
       "   'cigarette',\n",
       "   'filters',\n",
       "   'caused',\n",
       "   'high',\n",
       "   'percentage',\n",
       "   'of',\n",
       "   'cancer',\n",
       "   'deaths',\n",
       "   'group',\n",
       "   'exposed',\n",
       "   'more',\n",
       "   'years',\n",
       "   'researchers'],\n",
       "  ['asbestos',\n",
       "   'unusually',\n",
       "   'once',\n",
       "   'it',\n",
       "   'brief',\n",
       "   'causing',\n",
       "   'symptoms',\n",
       "   'show',\n",
       "   'up',\n",
       "   'decades',\n",
       "   'later',\n",
       "   'researchers'],\n",
       "  ['york-based',\n",
       "   'makes',\n",
       "   'kent',\n",
       "   'cigarettes',\n",
       "   'stopped',\n",
       "   'using',\n",
       "   'cigarette',\n",
       "   'filters',\n",
       "   'in'],\n",
       "  ['although',\n",
       "   'preliminary',\n",
       "   'findings',\n",
       "   'reported',\n",
       "   'more',\n",
       "   'ago',\n",
       "   'latest',\n",
       "   'appear',\n",
       "   'today',\n",
       "   'new',\n",
       "   'england',\n",
       "   'journal',\n",
       "   'medicine',\n",
       "   'likely',\n",
       "   'bring',\n",
       "   'attention',\n",
       "   'to'],\n",
       "  ['this', 'old', 'story'],\n",
       "  [\"'re\",\n",
       "   'talking',\n",
       "   'years',\n",
       "   'ago',\n",
       "   'before',\n",
       "   'anyone',\n",
       "   'heard',\n",
       "   'asbestos',\n",
       "   'having',\n",
       "   'any',\n",
       "   'questionable',\n",
       "   'properties']],\n",
       " collections.Counter)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subsampled),subsampled[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "- 下面的代码片段绘制了下采样前后每句话的词元数量的直方图。\n",
    "- 正如预期的那样，**下采样通过删除高频词来显著缩短句子**，这将使训练加速。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"253.825pt\" height=\"181.852389pt\" viewBox=\"0 0 253.825 181.852389\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-04-21T10:20:29.277424</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 181.852389 \n",
       "L 253.825 181.852389 \n",
       "L 253.825 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 51.325 147.402389 \n",
       "L 246.625 147.402389 \n",
       "L 246.625 8.802389 \n",
       "L 51.325 8.802389 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 60.202273 147.402389 \n",
       "L 67.449026 147.402389 \n",
       "L 67.449026 125.711477 \n",
       "L 60.202273 125.711477 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 78.319156 147.402389 \n",
       "L 85.565909 147.402389 \n",
       "L 85.565909 87.264132 \n",
       "L 78.319156 87.264132 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 96.436039 147.402389 \n",
       "L 103.682792 147.402389 \n",
       "L 103.682792 77.925825 \n",
       "L 96.436039 77.925825 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 114.552922 147.402389 \n",
       "L 121.799675 147.402389 \n",
       "L 121.799675 98.221735 \n",
       "L 114.552922 98.221735 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 132.669805 147.402389 \n",
       "L 139.916558 147.402389 \n",
       "L 139.916558 126.898597 \n",
       "L 132.669805 126.898597 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 150.786688 147.402389 \n",
       "L 158.033442 147.402389 \n",
       "L 158.033442 140.438321 \n",
       "L 150.786688 140.438321 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 168.903571 147.402389 \n",
       "L 176.150325 147.402389 \n",
       "L 176.150325 145.826857 \n",
       "L 168.903571 145.826857 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 187.020455 147.402389 \n",
       "L 194.267208 147.402389 \n",
       "L 194.267208 147.003035 \n",
       "L 187.020455 147.003035 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 205.137338 147.402389 \n",
       "L 212.384091 147.402389 \n",
       "L 212.384091 147.265624 \n",
       "L 205.137338 147.265624 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 223.254221 147.402389 \n",
       "L 230.500974 147.402389 \n",
       "L 230.500974 147.3258 \n",
       "L 223.254221 147.3258 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: #1f77b4\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 67.449026 147.402389 \n",
       "L 74.695779 147.402389 \n",
       "L 74.695779 15.402389 \n",
       "L 67.449026 15.402389 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 85.565909 147.402389 \n",
       "L 92.812662 147.402389 \n",
       "L 92.812662 59.998684 \n",
       "L 85.565909 59.998684 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 103.682792 147.402389 \n",
       "L 110.929545 147.402389 \n",
       "L 110.929545 137.248963 \n",
       "L 103.682792 137.248963 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 121.799675 147.402389 \n",
       "L 129.046429 147.402389 \n",
       "L 129.046429 146.86627 \n",
       "L 121.799675 146.86627 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 139.916558 147.402389 \n",
       "L 147.163312 147.402389 \n",
       "L 147.163312 147.353153 \n",
       "L 139.916558 147.353153 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 158.033442 147.402389 \n",
       "L 165.280195 147.402389 \n",
       "L 165.280195 147.402389 \n",
       "L 158.033442 147.402389 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 176.150325 147.402389 \n",
       "L 183.397078 147.402389 \n",
       "L 183.397078 147.402389 \n",
       "L 176.150325 147.402389 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 194.267208 147.402389 \n",
       "L 201.513961 147.402389 \n",
       "L 201.513961 147.402389 \n",
       "L 194.267208 147.402389 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 212.384091 147.402389 \n",
       "L 219.630844 147.402389 \n",
       "L 219.630844 147.402389 \n",
       "L 212.384091 147.402389 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 230.500974 147.402389 \n",
       "L 237.747727 147.402389 \n",
       "L 237.747727 147.402389 \n",
       "L 230.500974 147.402389 \n",
       "z\n",
       "\" clip-path=\"url(#pdf0dbe4508)\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"mbd924f7c3b\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbd924f7c3b\" x=\"58.390584\" y=\"147.402389\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(55.890584 161.277389) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-30\" d=\"M 225 2537 \n",
       "Q 250 3200 412 3587 \n",
       "Q 575 3975 875 4225 \n",
       "Q 1175 4475 1612 4475 \n",
       "Q 2050 4475 2375 4112 \n",
       "Q 2700 3750 2800 3200 \n",
       "Q 2900 2650 2862 1937 \n",
       "Q 2825 1225 2612 775 \n",
       "Q 2400 325 1975 150 \n",
       "Q 1550 -25 1125 187 \n",
       "Q 700 400 525 750 \n",
       "Q 350 1100 275 1487 \n",
       "Q 200 1875 225 2537 \n",
       "z\n",
       "M 750 2687 \n",
       "Q 675 2000 800 1462 \n",
       "Q 925 925 1212 700 \n",
       "Q 1500 475 1800 612 \n",
       "Q 2100 750 2237 1162 \n",
       "Q 2375 1575 2375 2062 \n",
       "Q 2375 2550 2337 2950 \n",
       "Q 2300 3350 2112 3675 \n",
       "Q 1925 4000 1612 4012 \n",
       "Q 1300 4025 1062 3700 \n",
       "Q 825 3375 750 2687 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbd924f7c3b\" x=\"102.578104\" y=\"147.402389\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(97.578104 161.277389) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-32\" d=\"M 300 250 \n",
       "Q 325 625 650 925 \n",
       "Q 975 1225 1475 1862 \n",
       "Q 1975 2500 2125 2850 \n",
       "Q 2275 3200 2237 3450 \n",
       "Q 2200 3700 2000 3862 \n",
       "Q 1800 4025 1537 4000 \n",
       "Q 1275 3975 1037 3800 \n",
       "Q 800 3625 675 3275 \n",
       "L 200 3350 \n",
       "Q 400 3925 712 4187 \n",
       "Q 1025 4450 1450 4475 \n",
       "Q 1700 4500 1900 4462 \n",
       "Q 2100 4425 2312 4287 \n",
       "Q 2525 4150 2662 3875 \n",
       "Q 2800 3600 2762 3212 \n",
       "Q 2725 2825 2375 2287 \n",
       "Q 2025 1750 1025 600 \n",
       "L 2825 600 \n",
       "L 2825 150 \n",
       "L 300 150 \n",
       "L 300 250 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbd924f7c3b\" x=\"146.765624\" y=\"147.402389\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(141.765624 161.277389) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-34\" d=\"M 2000 1100 \n",
       "L 75 1100 \n",
       "L 75 1525 \n",
       "L 2100 4450 \n",
       "L 2475 4450 \n",
       "L 2475 1525 \n",
       "L 3075 1525 \n",
       "L 3075 1100 \n",
       "L 2475 1100 \n",
       "L 2475 150 \n",
       "L 2000 150 \n",
       "L 2000 1100 \n",
       "z\n",
       "M 2000 1525 \n",
       "L 2000 3500 \n",
       "L 600 1525 \n",
       "L 2000 1525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-34\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbd924f7c3b\" x=\"190.953144\" y=\"147.402389\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(185.953144 161.277389) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-36\" d=\"M 250 1612 \n",
       "Q 275 1975 387 2225 \n",
       "Q 500 2475 725 2850 \n",
       "L 1750 4450 \n",
       "L 2325 4450 \n",
       "L 1275 2800 \n",
       "Q 1950 2975 2350 2750 \n",
       "Q 2750 2525 2887 2237 \n",
       "Q 3025 1950 3037 1612 \n",
       "Q 3050 1275 2937 950 \n",
       "Q 2825 625 2537 362 \n",
       "Q 2250 100 1737 75 \n",
       "Q 1225 50 862 262 \n",
       "Q 500 475 362 862 \n",
       "Q 225 1250 250 1612 \n",
       "z\n",
       "M 1025 787 \n",
       "Q 1250 550 1625 525 \n",
       "Q 2000 500 2250 775 \n",
       "Q 2500 1050 2500 1575 \n",
       "Q 2500 2100 2187 2300 \n",
       "Q 1875 2500 1487 2450 \n",
       "Q 1100 2400 925 2075 \n",
       "Q 750 1750 775 1387 \n",
       "Q 800 1025 1025 787 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-36\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbd924f7c3b\" x=\"235.140664\" y=\"147.402389\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(230.140664 161.277389) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-38\" d=\"M 175 1375 \n",
       "Q 175 1675 325 1962 \n",
       "Q 475 2250 825 2425 \n",
       "Q 525 2600 425 2812 \n",
       "Q 325 3025 312 3300 \n",
       "Q 300 3575 387 3775 \n",
       "Q 475 3975 650 4150 \n",
       "Q 825 4325 1037 4387 \n",
       "Q 1250 4450 1500 4450 \n",
       "Q 1750 4450 1950 4400 \n",
       "Q 2150 4350 2375 4187 \n",
       "Q 2600 4025 2700 3725 \n",
       "Q 2800 3425 2687 3025 \n",
       "Q 2575 2625 2100 2400 \n",
       "Q 2525 2275 2700 2012 \n",
       "Q 2875 1750 2875 1375 \n",
       "Q 2875 1000 2762 775 \n",
       "Q 2650 550 2512 400 \n",
       "Q 2375 250 2137 162 \n",
       "Q 1900 75 1537 75 \n",
       "Q 1175 75 912 162 \n",
       "Q 650 250 475 425 \n",
       "Q 300 600 237 837 \n",
       "Q 175 1075 175 1375 \n",
       "z\n",
       "M 687 1400 \n",
       "Q 675 1100 787 875 \n",
       "Q 900 650 1200 587 \n",
       "Q 1500 525 1825 600 \n",
       "Q 2150 675 2275 950 \n",
       "Q 2400 1225 2362 1500 \n",
       "Q 2325 1775 2050 1962 \n",
       "Q 1775 2150 1450 2125 \n",
       "Q 1125 2100 912 1900 \n",
       "Q 700 1700 687 1400 \n",
       "z\n",
       "M 775 3350 \n",
       "Q 775 3100 950 2875 \n",
       "Q 1125 2650 1500 2650 \n",
       "Q 1875 2650 2062 2875 \n",
       "Q 2250 3100 2237 3412 \n",
       "Q 2225 3725 2012 3875 \n",
       "Q 1800 4025 1437 4000 \n",
       "Q 1075 3975 925 3787 \n",
       "Q 775 3600 775 3350 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-38\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- # tokens per sentence -->\n",
       "     <g transform=\"translate(96.475 173.402389) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-23\" d=\"M 3000 1275 \n",
       "L 2250 1275 \n",
       "L 2100 125 \n",
       "L 1700 125 \n",
       "L 1850 1275 \n",
       "L 1025 1275 \n",
       "L 875 125 \n",
       "L 475 125 \n",
       "L 625 1275 \n",
       "L 125 1275 \n",
       "L 125 1750 \n",
       "L 675 1750 \n",
       "L 825 2800 \n",
       "L 125 2800 \n",
       "L 125 3275 \n",
       "L 875 3275 \n",
       "L 1025 4400 \n",
       "L 1425 4400 \n",
       "L 1275 3275 \n",
       "L 2100 3275 \n",
       "L 2250 4400 \n",
       "L 2650 4400 \n",
       "L 2500 3275 \n",
       "L 3000 3275 \n",
       "L 3000 2800 \n",
       "L 2450 2800 \n",
       "L 2300 1750 \n",
       "L 3000 1750 \n",
       "L 3000 1275 \n",
       "z\n",
       "M 2050 2800 \n",
       "L 1225 2800 \n",
       "L 1075 1750 \n",
       "L 1900 1750 \n",
       "L 2050 2800 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-74\" d=\"M 2750 200 \n",
       "Q 2625 150 2462 112 \n",
       "Q 2300 75 2025 75 \n",
       "Q 1575 75 1300 325 \n",
       "Q 1025 575 1025 1025 \n",
       "L 1025 2525 \n",
       "L 175 2525 \n",
       "L 175 2925 \n",
       "L 1025 2925 \n",
       "L 1025 3900 \n",
       "L 1525 3900 \n",
       "L 1525 2925 \n",
       "L 2550 2925 \n",
       "L 2550 2525 \n",
       "L 1525 2525 \n",
       "L 1525 1000 \n",
       "Q 1525 800 1625 662 \n",
       "Q 1725 525 2000 525 \n",
       "Q 2275 525 2450 575 \n",
       "Q 2625 625 2750 700 \n",
       "L 2750 200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6f\" d=\"M 2925 1525 \n",
       "Q 2925 875 2525 475 \n",
       "Q 2125 75 1575 75 \n",
       "Q 1025 75 625 475 \n",
       "Q 225 875 225 1525 \n",
       "Q 225 2175 625 2575 \n",
       "Q 1025 2975 1575 2975 \n",
       "Q 2125 2975 2525 2575 \n",
       "Q 2925 2175 2925 1525 \n",
       "z\n",
       "M 2375 1525 \n",
       "Q 2375 2025 2125 2275 \n",
       "Q 1875 2525 1575 2525 \n",
       "Q 1275 2525 1025 2275 \n",
       "Q 775 2025 775 1525 \n",
       "Q 775 1025 1025 775 \n",
       "Q 1275 525 1575 525 \n",
       "Q 1875 525 2125 775 \n",
       "Q 2375 1025 2375 1525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6b\" d=\"M 2925 125 \n",
       "L 2350 125 \n",
       "L 1450 1650 \n",
       "L 875 1100 \n",
       "L 875 125 \n",
       "L 375 125 \n",
       "L 375 4400 \n",
       "L 875 4400 \n",
       "L 875 1675 \n",
       "L 2125 2925 \n",
       "L 2750 2925 \n",
       "L 1775 1975 \n",
       "L 2925 125 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-65\" d=\"M 2850 1075 \n",
       "Q 2800 625 2450 350 \n",
       "Q 2100 75 1625 75 \n",
       "Q 1025 75 637 462 \n",
       "Q 250 850 250 1525 \n",
       "Q 250 2200 637 2587 \n",
       "Q 1025 2975 1625 2975 \n",
       "Q 2150 2975 2487 2637 \n",
       "Q 2825 2300 2825 1525 \n",
       "L 800 1525 \n",
       "Q 800 975 1037 750 \n",
       "Q 1275 525 1625 525 \n",
       "Q 1900 525 2075 662 \n",
       "Q 2250 800 2300 1075 \n",
       "L 2850 1075 \n",
       "z\n",
       "M 2250 1925 \n",
       "Q 2200 2275 2025 2412 \n",
       "Q 1850 2550 1575 2550 \n",
       "Q 1325 2550 1125 2412 \n",
       "Q 925 2275 825 1925 \n",
       "L 2250 1925 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6e\" d=\"M 2800 125 \n",
       "L 2300 125 \n",
       "L 2300 1925 \n",
       "Q 2300 2225 2150 2400 \n",
       "Q 2000 2575 1750 2575 \n",
       "Q 1425 2575 1137 2237 \n",
       "Q 850 1900 850 1400 \n",
       "L 850 125 \n",
       "L 350 125 \n",
       "L 350 2925 \n",
       "L 850 2925 \n",
       "L 850 2400 \n",
       "Q 1050 2675 1287 2825 \n",
       "Q 1525 2975 1900 2975 \n",
       "Q 2350 2975 2575 2725 \n",
       "Q 2800 2475 2800 2100 \n",
       "L 2800 125 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-73\" d=\"M 2750 900 \n",
       "Q 2750 500 2437 287 \n",
       "Q 2125 75 1650 75 \n",
       "Q 1050 75 725 312 \n",
       "Q 400 550 400 1000 \n",
       "L 900 1000 \n",
       "Q 900 700 1112 600 \n",
       "Q 1325 500 1625 500 \n",
       "Q 1925 500 2075 612 \n",
       "Q 2225 725 2225 900 \n",
       "Q 2225 1025 2100 1150 \n",
       "Q 1975 1275 1475 1350 \n",
       "Q 900 1425 687 1637 \n",
       "Q 475 1850 475 2200 \n",
       "Q 475 2500 762 2737 \n",
       "Q 1050 2975 1600 2975 \n",
       "Q 2100 2975 2387 2750 \n",
       "Q 2675 2525 2675 2150 \n",
       "L 2175 2150 \n",
       "Q 2175 2375 2012 2462 \n",
       "Q 1850 2550 1600 2550 \n",
       "Q 1275 2550 1137 2437 \n",
       "Q 1000 2325 1000 2175 \n",
       "Q 1000 2000 1125 1900 \n",
       "Q 1250 1800 1650 1750 \n",
       "Q 2300 1650 2525 1437 \n",
       "Q 2750 1225 2750 900 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-70\" d=\"M 2825 1525 \n",
       "Q 2825 800 2475 425 \n",
       "Q 2125 50 1625 50 \n",
       "Q 1350 50 1150 162 \n",
       "Q 950 275 800 500 \n",
       "L 800 -800 \n",
       "L 300 -800 \n",
       "L 300 2925 \n",
       "L 800 2925 \n",
       "L 800 2550 \n",
       "Q 950 2775 1150 2875 \n",
       "Q 1350 2975 1625 2975 \n",
       "Q 2125 2975 2475 2612 \n",
       "Q 2825 2250 2825 1525 \n",
       "z\n",
       "M 2275 1525 \n",
       "Q 2275 2000 2087 2262 \n",
       "Q 1900 2525 1525 2525 \n",
       "Q 1225 2525 1012 2262 \n",
       "Q 800 2000 800 1525 \n",
       "Q 800 1050 1012 775 \n",
       "Q 1225 500 1525 500 \n",
       "Q 1900 500 2087 775 \n",
       "Q 2275 1050 2275 1525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-72\" d=\"M 2500 2425 \n",
       "Q 2025 2500 1700 2287 \n",
       "Q 1375 2075 1150 1550 \n",
       "L 1150 125 \n",
       "L 650 125 \n",
       "L 650 2925 \n",
       "L 1150 2925 \n",
       "L 1150 2200 \n",
       "Q 1375 2600 1712 2787 \n",
       "Q 2050 2975 2500 2975 \n",
       "L 2500 2425 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-63\" d=\"M 2850 1250 \n",
       "Q 2850 725 2487 400 \n",
       "Q 2125 75 1575 75 \n",
       "Q 1025 75 625 462 \n",
       "Q 225 850 225 1525 \n",
       "Q 225 2200 625 2587 \n",
       "Q 1025 2975 1575 2975 \n",
       "Q 2125 2975 2450 2687 \n",
       "Q 2775 2400 2775 2000 \n",
       "L 2225 2000 \n",
       "Q 2200 2300 2012 2412 \n",
       "Q 1825 2525 1575 2525 \n",
       "Q 1275 2525 1025 2287 \n",
       "Q 775 2050 775 1525 \n",
       "Q 775 1000 1025 762 \n",
       "Q 1275 525 1575 525 \n",
       "Q 1900 525 2100 700 \n",
       "Q 2300 875 2300 1250 \n",
       "L 2850 1250 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-23\"/>\n",
       "      <use xlink:href=\"#SimHei-20\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-74\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-6f\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-6b\" x=\"200\"/>\n",
       "      <use xlink:href=\"#SimHei-65\" x=\"250\"/>\n",
       "      <use xlink:href=\"#SimHei-6e\" x=\"300\"/>\n",
       "      <use xlink:href=\"#SimHei-73\" x=\"350\"/>\n",
       "      <use xlink:href=\"#SimHei-20\" x=\"400\"/>\n",
       "      <use xlink:href=\"#SimHei-70\" x=\"450\"/>\n",
       "      <use xlink:href=\"#SimHei-65\" x=\"500\"/>\n",
       "      <use xlink:href=\"#SimHei-72\" x=\"550\"/>\n",
       "      <use xlink:href=\"#SimHei-20\" x=\"600\"/>\n",
       "      <use xlink:href=\"#SimHei-73\" x=\"650\"/>\n",
       "      <use xlink:href=\"#SimHei-65\" x=\"700\"/>\n",
       "      <use xlink:href=\"#SimHei-6e\" x=\"750\"/>\n",
       "      <use xlink:href=\"#SimHei-74\" x=\"800\"/>\n",
       "      <use xlink:href=\"#SimHei-65\" x=\"850\"/>\n",
       "      <use xlink:href=\"#SimHei-6e\" x=\"900\"/>\n",
       "      <use xlink:href=\"#SimHei-63\" x=\"950\"/>\n",
       "      <use xlink:href=\"#SimHei-65\" x=\"1000\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <defs>\n",
       "       <path id=\"m8b2ee1d3d9\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b2ee1d3d9\" x=\"51.325\" y=\"147.402389\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(39.325 150.839889) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b2ee1d3d9\" x=\"51.325\" y=\"120.049411\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5000 -->\n",
       "      <g transform=\"translate(24.325 123.486911) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-35\" d=\"M 550 1325 \n",
       "Q 725 650 1150 575 \n",
       "Q 1575 500 1837 662 \n",
       "Q 2100 825 2212 1087 \n",
       "Q 2325 1350 2312 1675 \n",
       "Q 2300 2000 2137 2225 \n",
       "Q 1975 2450 1725 2525 \n",
       "Q 1475 2600 1162 2525 \n",
       "Q 850 2450 650 2175 \n",
       "L 225 2225 \n",
       "Q 275 2375 700 4375 \n",
       "L 2675 4375 \n",
       "L 2675 3925 \n",
       "L 1075 3925 \n",
       "Q 950 3250 825 2850 \n",
       "Q 1200 3025 1525 3012 \n",
       "Q 1850 3000 2150 2862 \n",
       "Q 2450 2725 2587 2487 \n",
       "Q 2725 2250 2787 2012 \n",
       "Q 2850 1775 2837 1500 \n",
       "Q 2825 1225 2725 937 \n",
       "Q 2625 650 2425 462 \n",
       "Q 2225 275 1937 162 \n",
       "Q 1650 50 1275 75 \n",
       "Q 900 100 562 350 \n",
       "Q 225 600 100 1200 \n",
       "L 550 1325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-35\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b2ee1d3d9\" x=\"51.325\" y=\"92.696433\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10000 -->\n",
       "      <g transform=\"translate(19.325 96.133933) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"SimHei-31\" d=\"M 1400 3600 \n",
       "Q 1075 3275 575 2975 \n",
       "L 575 3450 \n",
       "Q 1200 3875 1600 4450 \n",
       "L 1900 4450 \n",
       "L 1900 150 \n",
       "L 1400 150 \n",
       "L 1400 3600 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"200\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b2ee1d3d9\" x=\"51.325\" y=\"65.343455\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15000 -->\n",
       "      <g transform=\"translate(19.325 68.780955) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-31\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"200\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b2ee1d3d9\" x=\"51.325\" y=\"37.990478\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20000 -->\n",
       "      <g transform=\"translate(19.325 41.427978) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"200\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8b2ee1d3d9\" x=\"51.325\" y=\"10.6375\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25000 -->\n",
       "      <g transform=\"translate(19.325 14.075) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#SimHei-32\"/>\n",
       "       <use xlink:href=\"#SimHei-35\" x=\"50\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"100\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"150\"/>\n",
       "       <use xlink:href=\"#SimHei-30\" x=\"200\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- count -->\n",
       "     <g transform=\"translate(14.075 90.602389) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-75\" d=\"M 2800 125 \n",
       "L 2300 125 \n",
       "L 2300 650 \n",
       "Q 2100 375 1862 225 \n",
       "Q 1625 75 1250 75 \n",
       "Q 800 75 575 325 \n",
       "Q 350 575 350 950 \n",
       "L 350 2925 \n",
       "L 850 2925 \n",
       "L 850 1125 \n",
       "Q 850 825 1000 650 \n",
       "Q 1150 475 1400 475 \n",
       "Q 1725 475 2012 812 \n",
       "Q 2300 1150 2300 1650 \n",
       "L 2300 2925 \n",
       "L 2800 2925 \n",
       "L 2800 125 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-63\"/>\n",
       "      <use xlink:href=\"#SimHei-6f\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-75\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-6e\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-74\" x=\"200\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 51.325 147.402389 \n",
       "L 51.325 8.802389 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 246.625 147.402389 \n",
       "L 246.625 8.802389 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 51.325 147.402389 \n",
       "L 246.625 147.402389 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 51.325 8.802389 \n",
       "L 246.625 8.802389 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_27\">\n",
       "     <path d=\"M 157.625 43.302389 \n",
       "L 239.625 43.302389 \n",
       "Q 241.625 43.302389 241.625 41.302389 \n",
       "L 241.625 15.802389 \n",
       "Q 241.625 13.802389 239.625 13.802389 \n",
       "L 157.625 13.802389 \n",
       "Q 155.625 13.802389 155.625 15.802389 \n",
       "L 155.625 41.302389 \n",
       "Q 155.625 43.302389 157.625 43.302389 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"patch_28\">\n",
       "     <path d=\"M 159.625 24.802389 \n",
       "L 179.625 24.802389 \n",
       "L 179.625 17.802389 \n",
       "L 159.625 17.802389 \n",
       "z\n",
       "\" style=\"fill: #1f77b4\"/>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- origin -->\n",
       "     <g transform=\"translate(187.625 24.802389) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-69\" d=\"M 1800 3725 \n",
       "L 1300 3725 \n",
       "L 1300 4375 \n",
       "L 1800 4375 \n",
       "L 1800 3725 \n",
       "z\n",
       "M 1800 125 \n",
       "L 1300 125 \n",
       "L 1300 2925 \n",
       "L 1800 2925 \n",
       "L 1800 125 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-67\" d=\"M 2975 2500 \n",
       "Q 2800 2550 2637 2562 \n",
       "Q 2475 2575 2300 2525 \n",
       "Q 2375 2450 2425 2337 \n",
       "Q 2475 2225 2475 2000 \n",
       "Q 2475 1575 2187 1300 \n",
       "Q 1900 1025 1475 1025 \n",
       "Q 1375 1025 1212 1062 \n",
       "Q 1050 1100 950 1150 \n",
       "Q 875 1100 850 1050 \n",
       "Q 825 1000 825 925 \n",
       "Q 825 800 1000 737 \n",
       "Q 1175 675 1625 675 \n",
       "Q 2350 675 2612 475 \n",
       "Q 2875 275 2875 -25 \n",
       "Q 2875 -425 2487 -612 \n",
       "Q 2100 -800 1575 -800 \n",
       "Q 900 -800 575 -625 \n",
       "Q 250 -450 250 -150 \n",
       "Q 250 0 375 150 \n",
       "Q 500 300 700 400 \n",
       "Q 550 475 462 587 \n",
       "Q 375 700 375 875 \n",
       "Q 375 1025 487 1137 \n",
       "Q 600 1250 750 1325 \n",
       "Q 625 1450 550 1625 \n",
       "Q 475 1800 475 2000 \n",
       "Q 475 2425 762 2700 \n",
       "Q 1050 2975 1475 2975 \n",
       "Q 1700 2975 1862 2912 \n",
       "Q 2025 2850 2150 2725 \n",
       "Q 2350 2875 2550 2937 \n",
       "Q 2750 3000 2975 2975 \n",
       "L 2975 2500 \n",
       "z\n",
       "M 1975 2000 \n",
       "Q 1975 2250 1850 2400 \n",
       "Q 1725 2550 1475 2550 \n",
       "Q 1225 2550 1100 2400 \n",
       "Q 975 2250 975 2000 \n",
       "Q 975 1750 1100 1600 \n",
       "Q 1225 1450 1475 1450 \n",
       "Q 1725 1450 1850 1600 \n",
       "Q 1975 1750 1975 2000 \n",
       "z\n",
       "M 2400 -75 \n",
       "Q 2400 25 2287 125 \n",
       "Q 2175 225 1725 225 \n",
       "Q 1625 225 1450 237 \n",
       "Q 1275 250 1050 275 \n",
       "Q 850 200 775 100 \n",
       "Q 700 0 700 -100 \n",
       "Q 700 -250 900 -350 \n",
       "Q 1100 -450 1600 -450 \n",
       "Q 2025 -450 2212 -337 \n",
       "Q 2400 -225 2400 -75 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-6f\"/>\n",
       "      <use xlink:href=\"#SimHei-72\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-69\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-67\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-69\" x=\"200\"/>\n",
       "      <use xlink:href=\"#SimHei-6e\" x=\"250\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_29\">\n",
       "     <path d=\"M 159.625 38.052389 \n",
       "L 179.625 38.052389 \n",
       "L 179.625 31.052389 \n",
       "L 159.625 31.052389 \n",
       "z\n",
       "\" style=\"fill: url(#h7485e9e876)\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- subsampled -->\n",
       "     <g transform=\"translate(187.625 38.052389) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"SimHei-62\" d=\"M 2825 1525 \n",
       "Q 2825 800 2475 437 \n",
       "Q 2125 75 1625 75 \n",
       "Q 1350 75 1150 175 \n",
       "Q 950 275 800 500 \n",
       "L 800 125 \n",
       "L 300 125 \n",
       "L 300 4400 \n",
       "L 800 4400 \n",
       "L 800 2550 \n",
       "Q 950 2775 1150 2887 \n",
       "Q 1350 3000 1625 3000 \n",
       "Q 2125 3000 2475 2625 \n",
       "Q 2825 2250 2825 1525 \n",
       "z\n",
       "M 2275 1525 \n",
       "Q 2275 2000 2087 2275 \n",
       "Q 1900 2550 1525 2550 \n",
       "Q 1225 2550 1012 2275 \n",
       "Q 800 2000 800 1525 \n",
       "Q 800 1050 1012 787 \n",
       "Q 1225 525 1525 525 \n",
       "Q 1900 525 2087 787 \n",
       "Q 2275 1050 2275 1525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-61\" d=\"M 2875 125 \n",
       "L 2275 125 \n",
       "Q 2225 175 2200 262 \n",
       "Q 2175 350 2175 475 \n",
       "Q 2000 275 1750 175 \n",
       "Q 1500 75 1225 75 \n",
       "Q 825 75 550 275 \n",
       "Q 275 475 275 850 \n",
       "Q 275 1225 525 1450 \n",
       "Q 775 1675 1300 1750 \n",
       "Q 1650 1800 1912 1875 \n",
       "Q 2175 1950 2175 2075 \n",
       "Q 2175 2225 2062 2375 \n",
       "Q 1950 2525 1575 2525 \n",
       "Q 1275 2525 1137 2412 \n",
       "Q 1000 2300 950 2100 \n",
       "L 400 2100 \n",
       "Q 450 2500 762 2737 \n",
       "Q 1075 2975 1575 2975 \n",
       "Q 2125 2975 2400 2725 \n",
       "Q 2675 2475 2675 2025 \n",
       "L 2675 650 \n",
       "Q 2675 500 2725 375 \n",
       "Q 2775 250 2875 125 \n",
       "z\n",
       "M 2175 1050 \n",
       "L 2175 1550 \n",
       "Q 2025 1500 1887 1462 \n",
       "Q 1750 1425 1425 1375 \n",
       "Q 1050 1325 937 1200 \n",
       "Q 825 1075 825 900 \n",
       "Q 825 750 937 637 \n",
       "Q 1050 525 1275 525 \n",
       "Q 1500 525 1762 650 \n",
       "Q 2025 775 2175 1050 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6d\" d=\"M 3050 125 \n",
       "L 2550 125 \n",
       "L 2550 2150 \n",
       "Q 2550 2300 2500 2400 \n",
       "Q 2450 2500 2300 2500 \n",
       "Q 2125 2500 1975 2312 \n",
       "Q 1825 2125 1825 1825 \n",
       "L 1825 125 \n",
       "L 1325 125 \n",
       "L 1325 2150 \n",
       "Q 1325 2300 1275 2400 \n",
       "Q 1225 2500 1075 2500 \n",
       "Q 900 2500 750 2312 \n",
       "Q 600 2125 600 1825 \n",
       "L 600 125 \n",
       "L 100 125 \n",
       "L 100 2925 \n",
       "L 600 2925 \n",
       "L 600 2550 \n",
       "Q 725 2750 900 2862 \n",
       "Q 1075 2975 1275 2975 \n",
       "Q 1475 2975 1612 2862 \n",
       "Q 1750 2750 1800 2550 \n",
       "Q 1925 2750 2087 2862 \n",
       "Q 2250 2975 2450 2975 \n",
       "Q 2750 2975 2900 2812 \n",
       "Q 3050 2650 3050 2350 \n",
       "L 3050 125 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-6c\" d=\"M 1825 125 \n",
       "L 1325 125 \n",
       "L 1325 4400 \n",
       "L 1825 4400 \n",
       "L 1825 125 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"SimHei-64\" d=\"M 2750 125 \n",
       "L 2250 125 \n",
       "L 2250 500 \n",
       "Q 2100 275 1900 175 \n",
       "Q 1700 75 1425 75 \n",
       "Q 925 75 575 437 \n",
       "Q 225 800 225 1525 \n",
       "Q 225 2250 575 2625 \n",
       "Q 925 3000 1425 3000 \n",
       "Q 1700 3000 1900 2887 \n",
       "Q 2100 2775 2250 2550 \n",
       "L 2250 4400 \n",
       "L 2750 4400 \n",
       "L 2750 125 \n",
       "z\n",
       "M 2250 1525 \n",
       "Q 2250 2000 2037 2275 \n",
       "Q 1825 2550 1525 2550 \n",
       "Q 1150 2550 962 2275 \n",
       "Q 775 2000 775 1525 \n",
       "Q 775 1050 962 787 \n",
       "Q 1150 525 1525 525 \n",
       "Q 1825 525 2037 787 \n",
       "Q 2250 1050 2250 1525 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-73\"/>\n",
       "      <use xlink:href=\"#SimHei-75\" x=\"50\"/>\n",
       "      <use xlink:href=\"#SimHei-62\" x=\"100\"/>\n",
       "      <use xlink:href=\"#SimHei-73\" x=\"150\"/>\n",
       "      <use xlink:href=\"#SimHei-61\" x=\"200\"/>\n",
       "      <use xlink:href=\"#SimHei-6d\" x=\"250\"/>\n",
       "      <use xlink:href=\"#SimHei-70\" x=\"300\"/>\n",
       "      <use xlink:href=\"#SimHei-6c\" x=\"350\"/>\n",
       "      <use xlink:href=\"#SimHei-65\" x=\"400\"/>\n",
       "      <use xlink:href=\"#SimHei-64\" x=\"450\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pdf0dbe4508\">\n",
       "   <rect x=\"51.325\" y=\"8.802389\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       " <defs>\n",
       "  <pattern id=\"h7485e9e876\" patternUnits=\"userSpaceOnUse\" x=\"0\" y=\"0\" width=\"72\" height=\"72\">\n",
       "   <rect x=\"0\" y=\"0\" width=\"73\" height=\"73\" fill=\"#ff7f0e\"/>\n",
       "   <path d=\"M -36 36 \n",
       "L 36 -36 \n",
       "M -24 48 \n",
       "L 48 -24 \n",
       "M -12 60 \n",
       "L 60 -12 \n",
       "M 0 72 \n",
       "L 72 0 \n",
       "M 12 84 \n",
       "L 84 12 \n",
       "M 24 96 \n",
       "L 96 24 \n",
       "M 36 108 \n",
       "L 108 36 \n",
       "\" style=\"fill: #000000; stroke: #000000; stroke-width: 1.0; stroke-linecap: butt; stroke-linejoin: miter\"/>\n",
       "  </pattern>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2l.show_list_len_pair_hist(\n",
    "    ['origin', 'subsampled'], '# tokens per sentence',\n",
    "    'count', sentences, subsampled);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 11
   },
   "source": [
    "- 对于单个词元，高频词“the”的采样率不到1/20。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"the\"的数量：之前=50770, 之后=2092'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'\"{token}\"的数量：'\n",
    "            f'之前={sum([l.count(token) for l in sentences])}, '\n",
    "            f'之后={sum([l.count(token) for l in subsampled])}')\n",
    "\n",
    "compare_counts('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 13
   },
   "source": [
    "- 相比之下，低频词“join”则被完全保留。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"join\"的数量：之前=45, 之后=45'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "- 在下采样之后，我们将词元映射到它们在语料库中的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [2, 2115, 145], [140, 5277, 3054, 1580]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 17
   },
   "source": [
    "## 14.3.3 中心词和上下文词的提取\n",
    "\n",
    "- 下面的`get_centers_and_contexts`函数从`corpus`中提取所有中心词及其上下文词。\n",
    "- 它随机采样1到`max_window_size`之间的整数作为上下文窗口。\n",
    "- 对于任一中心词，与其距离不超过采样上下文窗口大小的词为其上下文词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    \"\"\"返回跳元模型中的中心词和上下文词\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # 要形成“中心词-上下文词”对，每个句子至少需要有2个词\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # 上下文窗口中间i\n",
    "            ## 窗口大小是从1到max_window_size之间的一个随机整数\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size)))\n",
    "            # 从上下文词中排除中心词\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "- 接下来创建一个人工数据集，分别包含7个和3个单词的两个句子。\n",
    "- 设置最大上下文窗口大小为2，并打印所有中心词及其上下文词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 20,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集 [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "中心词 0 的上下文词是 [1]\n",
      "中心词 1 的上下文词是 [0, 2, 3]\n",
      "中心词 2 的上下文词是 [0, 1, 3, 4]\n",
      "中心词 3 的上下文词是 [1, 2, 4, 5]\n",
      "中心词 4 的上下文词是 [3, 5]\n",
      "中心词 5 的上下文词是 [3, 4, 6]\n",
      "中心词 6 的上下文词是 [4, 5]\n",
      "中心词 7 的上下文词是 [8, 9]\n",
      "中心词 8 的上下文词是 [7, 9]\n",
      "中心词 9 的上下文词是 [7, 8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('数据集', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('中心词', center, '的上下文词是', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [[1, 2],\n",
       "  [0, 2, 3],\n",
       "  [0, 1, 3, 4],\n",
       "  [2, 4],\n",
       "  [3, 5],\n",
       "  [4, 6],\n",
       "  [5],\n",
       "  [8],\n",
       "  [7, 9],\n",
       "  [8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_centers_and_contexts(tiny_dataset, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 21
   },
   "source": [
    "- 在PTB数据集上进行训练时，此处将最大上下文窗口大小设置为5。\n",
    "- 下面提取数据集中的所有中心词及其上下文词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# “中心词-上下文词对”的数量: 1503668'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# “中心词-上下文词对”的数量: {sum([len(contexts) for contexts in all_contexts])}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "## 14.3.4 词嵌入负采样\n",
    "\n",
    "- 此处使用负采样进行近似训练。\n",
    "- 为了根据预定义的分布对噪声词进行采样，定义以下`RandomGenerator`类，其中（可能未规范化的）采样分布通过变量`sampling_weights`传递。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class RandomGenerator:\n",
    "    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            # 缓存k个随机采样结果\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomGenerator详细注释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "预生成负采样的词元索引，减少random.choices的调用次数。\n",
    "通过空间换时间（缓存），解决高频采样时的性能瓶颈。\n",
    "'''\n",
    "class RandomGenerator:\n",
    "    \"\"\"根据n个采样权重在{1,...,n}中随机抽取\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        # Exclude\n",
    "        '''\n",
    "        候选索引列表 [1, 2, ..., n]，n为权重列表长度。\n",
    "        population属性保存的索引值是由权重列表的长度生成。\n",
    "        注意索引列表起始是1而不是0,是为排除掉词表中的第一个词元<unk>，即未知词元，\n",
    "        也是为了和权重对齐。\n",
    "        '''\n",
    "        self.population = list(range(1, len(sampling_weights) + 1))\n",
    "        '''\n",
    "        sampling_weights是负采样词元的权重。\n",
    "        根据后面的代码，权重值是每个词元的词频的3/4次方。\n",
    "        该权重在调用choice方法时作为随机抽取噪声词的概率计算依据。\n",
    "        '''\n",
    "        self.sampling_weights = sampling_weights\n",
    "        '''\n",
    "        缓存从 population 中按权重抽样的结果（存储索引值）。\n",
    "        '''\n",
    "        self.candidates = []\n",
    "        '''\n",
    "        i是从candidates缓存中抽取噪声词索引时的标记，类似数据库的游标，\n",
    "        表示上次负采样后的candidates所在位置，本次负采样返回i当前位置的噪声词，\n",
    "        然后+1，将游标往后移动一个单元。\n",
    "        当i等于candidates的长度(本类该缓存长度为10000)时，\n",
    "        表示candidates缓存的噪声词已经全部被使抽取过，需要生成新candidates缓存了。\n",
    "        '''\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        '''\n",
    "        当i等于candidates的长度(此处为10000)时，表示candidates缓存的负噪声词\n",
    "        已经全部被使抽取过，需要生成新candidates缓存了。\n",
    "        '''\n",
    "        if self.i == len(self.candidates):\n",
    "            # 缓存k个随机采样结果\n",
    "            '''\n",
    "            按照权重随机抽取噪声词的索引缓存。注意choice方法的用法。\n",
    "            每次生成缓存为10000个样本索引。\n",
    "            choices方法第一个参数是被采样的对象，第二个参数是权重，k表示采样的样本数量。\n",
    "            random.choices方法是有放回抽样。\n",
    "            '''\n",
    "            self.candidates = random.choices(\n",
    "                self.population, self.sampling_weights, k=10000)\n",
    "            # 重新生成缓存之后将游标标记重新设置为0，即从头开始从缓存中返回噪声词索引\n",
    "            self.i = 0\n",
    "        # 将游标往后移动一个单元，注意：draw方法将返回当前位置即移动前所在位置的负采样索引\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1] # 注意此处将i-1，即移动前位置保存的候选噪声词索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.choices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "- 例如可以在索引1、2和3中绘制10个随机变量$X$，采样概率为$P(X=1)=2/9, P(X=2)=3/9$和$P(X=3)=4/9$，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 2, 2, 1, 3, 3, 3, 2, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 27
   },
   "source": [
    "- 对于一对中心词和上下文词，我们随机抽取了`K`个（实验中为5个）噪声词。\n",
    "- 根据word2vec论文中的建议，将噪声词$w$的采样概率$P(w)$设置为其在字典中的相对频率，其幂为0.75。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "origin_pos": 28,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"返回负采样中的噪声词\"\"\"\n",
    "    # 索引为1、2、...（索引0是词表中排除的未知标记）\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(1, len(vocab))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # 噪声词不能是上下文词\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get_negatives详细注释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "为每个中心词的所有上下文词的条件概率计算获取负采样噪声词。\n",
    "可参考14.2节的公式14.2.5和14.2.6。\n",
    "根据上述两个公式，每个中心词元有2m个上下文词，m为窗口大小；\n",
    "每个上线文词与中心词计算条件概率时，\n",
    "有k个噪声词参与条件概率与负对数损失函数的计算。\n",
    "all_contexts是一个嵌套列表，每个子列表保存每个中心词所对应的所有上下文词。\n",
    "注意根据前述中心词上下文词对获取函数get_centers_and_contexts的算法，\n",
    "每个中心词的上下文词的数量是一个随机数，即从1到max_window_size之间随机生成的一个整数。\n",
    "因此对于所有中心词来说，最终生成负采样的数量也是不同的。\n",
    "'''\n",
    "def get_negatives(all_contexts, vocab, counter, K):\n",
    "    \"\"\"返回负采样中的噪声词\"\"\"\n",
    "    # 索引为1、2、...（索引0是词表中排除的未知标记）\n",
    "    '''\n",
    "    从词表中取出除了<unk>未知标记之外的所有词元，然后计算每个词元的词频，并计算词频的0.75次方。\n",
    "    基本步骤：从词表中取出词元索引，通过索引提取词元，根据词元在文本序列或语料数据中统计词频，最后计算词频的0.75次方。\n",
    "    最后保存在列表中。\n",
    "    '''\n",
    "    sampling_weights = [counter[vocab.to_tokens(i)]**0.75\n",
    "                        for i in range(1, len(vocab))]\n",
    "    '''\n",
    "    初始化保存所有负采样的变量all_negatives，是一个列表，而且最终是一个嵌套列表。\n",
    "    每个子列表保存某个中心词所有上下文词各自对应的负采样。\n",
    "    生成RandomGenerator对象generator，用于负采样。\n",
    "    '''\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    '''\n",
    "    根据上下文词获取噪声词。\n",
    "    all_contexts是一个嵌套列表，其子列表保存每个中心词的上下文词。\n",
    "    contexts是保存某个中心词的上下文词(每个子列表有2m个上下文词)的列表。\n",
    "    '''\n",
    "    for contexts in all_contexts:\n",
    "        '''\n",
    "        初始化负采样列表，保存某个中心词所对应的所有上下文词的噪声词。\n",
    "        按照顺序每个上下文词对应K个噪声词，一共有len(contexts) * K个噪声词。\n",
    "        '''\n",
    "        negatives = []\n",
    "        '''\n",
    "        negatives的长度等于某个中心词对应的上下文词个数乘以K。\n",
    "        其含义为每个上下文词抽取K个噪声词。\n",
    "        注意噪声词不能是该中心词的上下文词。\n",
    "        \n",
    "        '''\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # 噪声词不能是上下文词\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        # 将某个中心词的所有上下文词对应的全部噪声词作为一个列表添加到all_negatives\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, vocab, counter, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 999, 4646, 134, 66, 1250, 53, 4639, 808, 340],\n",
       " [328, 4, 123, 6, 30, 16, 333, 172, 106, 7],\n",
       " [2524, 5, 9, 4595, 102, 3237, 985, 2837, 127, 3274]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_negatives是一个嵌套列表，子列表存储每个中心词-上下文词对的噪声词索引\n",
    "all_negatives[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[392, 2115],\n",
       " [71, 2115],\n",
       " [71, 392, 145, 274],\n",
       " [392, 2115, 274, 406],\n",
       " [392, 2115, 145, 406],\n",
       " [392, 2115, 145, 274],\n",
       " [3054, 1580, 95],\n",
       " [5277, 1580, 95],\n",
       " [5277, 3054, 95],\n",
       " [3054, 1580],\n",
       " [2467, 656, 2157, 948, 274],\n",
       " [392, 656, 2157]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每个中心词的上下文词个数不完全相同\n",
    "all_contexts[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 29
   },
   "source": [
    "## 14.3.5 小批量加载词嵌入训练数据实例\n",
    "- 在提取所有中心词及其上下文词和采样噪声词后，将它们转换成小批量的样本，在训练过程中可以迭代加载。\n",
    "- 在小批量中，$i^\\mathrm{th}$个样本包括中心词及其$n_i$个上下文词和$m_i$个噪声词。\n",
    "  - 由于上下文窗口大小不同，$n_i+m_i$对于不同的$i$是不同的。\n",
    "  - 因此，对于每个样本，我们在`contexts_negatives`个变量中将其上下文词和噪声词连结起来，并填充零，直到连结长度达到$\\max_i n_i+m_i$(`max_len`)。\n",
    "- 为了在计算损失时排除填充，我们定义了掩码变量`masks`。\n",
    "  - 在`masks`中的元素和`contexts_negatives`中的元素之间存在一一对应关系，其中`masks`中的0（否则为1）对应于`contexts_negatives`中的填充。\n",
    "- 为了区分正反例，我们在`contexts_negatives`中通过一个`labels`变量将上下文词与噪声词分开。\n",
    "  - 类似于`masks`，在`labels`中的元素和`contexts_negatives`中的元素之间也存在一一对应关系，其中`labels`中的1（否则为0）对应于`contexts_negatives`中的上下文词的正例。\n",
    "- 上述思想在下面的`batchify`函数中实现。\n",
    "  - 其输入`data`是长度等于批量大小的列表，其中每个元素是由中心词`center`、其上下文词`context`和其噪声词`negative`组成的样本。\n",
    "  - 此函数返回一个可以在训练期间加载用于计算的小批量，例如包括掩码变量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def batchify(data):\n",
    "    \"\"\"返回带有负采样的跳元模型的小批量样本\"\"\"\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += \\\n",
    "            [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts_negatives), torch.tensor(masks), torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batchify详细注释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对中心词、上下文词、噪声词等数据进行批量化处理。\n",
    "以下述示例中的x_1：(1, [2, 2], [3, 3, 3, 3])为例，data参数的各个部分分别表示：\n",
    "(1)第一个元素 1：中心词在词汇表中的索引（例如词汇表中 1 可能对应单词 \"apple\"）。\n",
    "(2)第二个元素 [2, 2]：该中心词的上下文词索引列表（例如 2 可能对应 \"fruit\"，重复表示多次共现）。\n",
    "(3)第三个元素 [3, 3, 3, 3]：负采样得到的噪声词索引列表（例如 3 可能对应无关词 \"car\"）。\n",
    "\n",
    "'''\n",
    "def batchify(data):\n",
    "    \"\"\"返回带有负采样的跳元模型的小批量样本\"\"\"\n",
    "    '''\n",
    "    取出上下文词列表的最大长度和噪声词列表的最大长度，然后将二者相加。\n",
    "    data的第一个元素是中心词索引。\n",
    "    然后通过上下文词列表的最大长度和噪声词列表的最大长度之和获得最大长度max_len，\n",
    "    该变量用于形成批量数据中向量的最大长度，达不到该最大长度则填充0.\n",
    "    '''\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    # 初始化中心词、上下文-噪声词(负样本)对，掩码以及标签列表\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    # 取出每个中心词、中心词所对应的上下文词以及上下文词所对应的噪声词\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)# 上下文词列表与对应噪声词列表的实际长度之和\n",
    "        # 在每条样本数据中，中心词索引是一个标量，将其拼接成一个列表，后面还要将其转换成列向量\n",
    "        centers += [center]\n",
    "        '''\n",
    "        将上下文词列表和中心词列表拼接成一个列表。\n",
    "        如何拼接后的列表长度小于max_len，后面不足的部分则填充为0.\n",
    "        '''\n",
    "        contexts_negatives += \\\n",
    "            [context + negative + [0] * (max_len - cur_len)]\n",
    "        '''\n",
    "        掩码用于区分拼接列表中的有效索引和填充。\n",
    "        1表示有效词索引（上下文词与噪声词索引），0表示填充。\n",
    "        '''\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        '''\n",
    "        标签列表用于区分列表中的上下文词与噪声词。\n",
    "        1表示上下文词；0表示其他(噪声词与填充都使用0标记)。\n",
    "        注意labels也是一个嵌套列表，每个子列表表示某个中心词的上下文词。\n",
    "        注意此处+=的用法，仍然是列表的拼接，此处是将列表中的子列表拼接成一个嵌套列表。\n",
    "        '''\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    '''\n",
    "    将上述变量全部转换成张量类型。\n",
    "    centers中心词索引转换成列向量，也是一个二维数组，只不过列数等于1。\n",
    "    contexts_negatives上下文词-噪声词索引转换成二维数组，列数等于max_len。\n",
    "    masks和labels都是二维数组，列数等于max_len。\n",
    "    上述各张量的行数皆等于数据的条数。\n",
    "    下述示例中使用tuple的元素表示一条数据。\n",
    "    '''    \n",
    "    return (torch.tensor(centers).reshape((-1, 1)), torch.tensor(\n",
    "        contexts_negatives), torch.tensor(masks), torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 31
   },
   "source": [
    "- 现在使用一个小批量的两个样本来测试此函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 33
   },
   "source": [
    "## 14.3.6 整合词嵌入数据集代码\n",
    "\n",
    "- 最后定义了读取PTB数据集并返回数据迭代器和词表的`load_data_ptb`函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "origin_pos": 35,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    \"\"\"下载PTB数据集，然后将其加载到内存中\"\"\"\n",
    "    \n",
    "    ## 原代码在windows环境下运行会发生异常，因此将num_workers改为0，则可消除异常\n",
    "    #num_workers = d2l.get_dataloader_workers()\n",
    "    num_workers=0\n",
    "    sentences = read_ptb()\n",
    "    vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "    subsampled, counter = subsample(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(\n",
    "        all_contexts, vocab, counter, num_noise_words)\n",
    "\n",
    "    class PTBDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, centers, contexts, negatives):\n",
    "            assert len(centers) == len(contexts) == len(negatives)\n",
    "            self.centers = centers\n",
    "            self.contexts = contexts\n",
    "            self.negatives = negatives\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return (self.centers[index], self.contexts[index],\n",
    "                    self.negatives[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size, shuffle=True,\n",
    "        collate_fn=batchify, num_workers=num_workers)\n",
    "    return data_iter, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "- 现在打印数据迭代器的第一个小批量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers shape: torch.Size([512, 1])\n",
      "contexts_negatives shape: torch.Size([512, 60])\n",
      "masks shape: torch.Size([512, 60])\n",
      "labels shape: torch.Size([512, 60])\n"
     ]
    }
   ],
   "source": [
    "data_iter, vocab = load_data_ptb(512, 5, 5)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 38
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 高频词在训练中可能不是那么有用。我们可以对他们进行下采样，以便在训练中加快速度。\n",
    "* 为了提高计算效率，我们以小批量方式加载样本。我们可以定义其他变量来区分填充标记和非填充标记，以及正例和负例。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
