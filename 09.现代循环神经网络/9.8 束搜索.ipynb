{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 9.8 束搜索\n",
    "- **目录**\n",
    "  - 9.8.1 两种常用搜索算法：贪心搜索与穷举搜索\n",
    "  - 9.8.2 束搜索基本原理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 在9.7节中，我们逐个预测输出序列，\n",
    "直到预测序列中出现特定的序列结束词元“&lt;eos&gt;”。\n",
    "- 在本节中，我们将首先介绍**贪心搜索（greedy search）** 策略，\n",
    "并探讨其存在的问题，然后对比其他替代策略：\n",
    "**穷举搜索（exhaustive search）** 和**束搜索（beam search）** 。\n",
    "- 定义搜索问题的数学符号：\n",
    "  - 在任意时间步$t'$，解码器输出$y_{t'}$的概率取决于\n",
    "时间步$t'$之前的输出子序列$y_1, \\ldots, y_{t'-1}$\n",
    "和对输入序列的信息进行编码得到的上下文变量$\\mathbf{c}$。\n",
    "  - 为了量化计算代价，用$\\mathcal{Y}$表示输出词表，其中包含“&lt;eos&gt;”，所以这个词汇集合的基数$\\left|\\mathcal{Y}\\right|$就是词表的大小。\n",
    "  - 将输出序列的最大词元数指定为$T'$。\n",
    "  - 目标是从所有$\\mathcal{O}(\\left|\\mathcal{Y}\\right|^{T'})$个\n",
    "可能的输出序列中寻找理想的输出。\n",
    "  - 对于所有输出序列，在“&lt;eos&gt;”之后的部分（非本句）\n",
    "将在实际输出中丢弃。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参考书籍\n",
    "\n",
    "<img src='../img/9_8_1.png' width=300px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 9.8.1 两种常用搜索算法：贪心搜索与穷举搜索\n",
    "首先，让我们看看一个简单的策略：**贪心搜索**，\n",
    "该策略已用于 9.7节的序列预测。\n",
    "对于输出序列的每一时间步$t'$，\n",
    "我们都将基于贪心搜索从$\\mathcal{Y}$中找到具有最高条件概率的词元，即：\n",
    "\n",
    "$$y_{t'} = \\operatorname*{argmax}_{y \\in \\mathcal{Y}} P(y \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c}) \\tag{9.8.1}$$\n",
    "\n",
    "一旦输出序列包含了“&lt;eos&gt;”或者达到其最大长度$T'$，则输出完成。\n",
    "\n",
    "<center> <img src ='../img/s2s-prob1.svg'/></center>\n",
    "<center>图9.8.1 在每个时间步，贪心搜索选择具有最高条件概率的词元</center></br>\n",
    "\n",
    "如图9.8.1中，假设输出中有四个词元“A”、“B”、“C”和“&lt;eos&gt;”。\n",
    "每个时间步下的四个数字分别表示在该时间步\n",
    "生成“A”、“B”、“C”和“&lt;eos&gt;”的条件概率。\n",
    "在每个时间步，贪心搜索选择具有最高条件概率的词元。\n",
    "因此，将在图9.8.1中\n",
    "预测输出序列“A”、“B”、“C”和“&lt;eos&gt;”。\n",
    "这个输出序列的条件概率是\n",
    "$0.5\\times0.4\\times0.4\\times0.6 = 0.048$。\n",
    "\n",
    "那么贪心搜索存在的问题是什么呢？\n",
    "现实中，**最优序列（optimal sequence）** 应该是最大化\n",
    "$\\prod_{t'=1}^{T'} P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$\n",
    "值的输出序列，这是基于输入序列生成输出序列的条件概率。\n",
    "然而，贪心搜索无法保证得到最优序列。\n",
    "\n",
    "<center><img src='../img/s2s-prob2.svg'/></center>\n",
    "<center>图9.8.2 在时间步2，选择具有第二高条件概率的词元“C”（而非最高条件概率的词元）</center>\n",
    "\n",
    " 图9.8.2中的另一个例子阐述了这个问题。\n",
    "与图9.8.1不同，在时间步$2$中，\n",
    "我们选择图9.8.2中的词元“C”，\n",
    "它具有**第二**高的条件概率。\n",
    "由于时间步$3$所基于的时间步$1$和$2$处的输出子序列已从\n",
    "图9.8.1中的“A”和“B”改变为\n",
    "图9.8.2中的“A”和“C”，\n",
    "因此时间步$3$处的每个词元的条件概率也在图9.8.2中改变。\n",
    "假设我们在时间步$3$选择词元“B”，\n",
    "于是当前的时间步$4$基于前三个时间步的输出子序列“A”、“C”和“B”为条件，\n",
    "这与图9.8.1中的“A”、“B”和“C”不同。\n",
    "因此，在图9.8.2中的时间步$4$生成\n",
    "每个词元的条件概率也不同于图9.8.1中的条件概率。\n",
    "结果， 图9.8.2中的输出序列\n",
    "“A”、“C”、“B”和“&lt;eos&gt;”的条件概率为\n",
    "$0.5\\times0.3 \\times0.6\\times0.6=0.054$，\n",
    "这大于图9.8.1中的贪心搜索的条件概率。\n",
    "这个例子说明：贪心搜索获得的输出序列\n",
    "“A”、“B”、“C”和“&lt;eos&gt;”\n",
    "不一定是最佳序列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- **要点：**\n",
    "  -  **贪心搜索**：在输出序列的每一时间步$t'$，我们都将基于贪心搜索从$\\mathcal{Y}$中找到具有最高条件概率的词元，即$y_{t'} = \\operatorname*{argmax}_{y \\in \\mathcal{Y}} P(y \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$。\n",
    "  - **结束条件**：一旦输出序列包含了“&lt;eos&gt;”或者达到其最大长度$T'$，则输出完成。\n",
    "  - **贪心搜索示例**：在每个时间步，贪心搜索选择具有最高条件概率的词元。比如在一个输出序列“A”、“B”、“C”和“&lt;eos&gt;”，每个时间步下的四个数字分别表示在该时间步生成“A”、“B”、“C”和“&lt;eos&gt;”的条件概率。\n",
    "  - **贪心搜索的问题**：贪心搜索无法保证得到最优序列。最优序列应该是最大化$\\prod_{t'=1}^{T'} P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$值的输出序列，这是基于输入序列生成输出序列的条件概率。\n",
    "  - **不是最优的例子**：在某些情况下，选择第二高的条件概率的词元也可能导致最终的序列的条件概率大于贪心搜索的序列的条件概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "另一种常有搜索算法是穷举搜索。如果目标是获得最优序列，\n",
    "我们可以考虑使用**穷举搜索（exhaustive search）**：\n",
    "穷举地列举所有可能的输出序列及其条件概率，\n",
    "然后计算输出条件概率最高的一个。\n",
    "\n",
    "虽然我们可以使用穷举搜索来获得最优序列，\n",
    "但其计算量$\\mathcal{O}(\\left|\\mathcal{Y}\\right|^{T'})$可能高的惊人。\n",
    "例如，当$|\\mathcal{Y}|=10000$和$T'=10$时，\n",
    "我们需要评估$10000^{10} = 10^{40}$序列，\n",
    "这是一个极大的数，现有的计算机几乎不可能计算它。\n",
    "然而，贪心搜索的计算量\n",
    "$\\mathcal{O}(\\left|\\mathcal{Y}\\right|T')$\n",
    "要显著地小于穷举搜索。\n",
    "例如，当$|\\mathcal{Y}|=10000$和$T'=10$时，\n",
    "我们只需要评估$10000\\times10=10^5$个序列。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 9.8.2 束搜索基本原理\n",
    "\n",
    "那么该选取哪种序列搜索策略呢？\n",
    "如果精度最重要，则显然是穷举搜索。\n",
    "如果计算成本最重要，则显然是贪心搜索。\n",
    "而束搜索的实际应用则**介于这两个极端之间**。\n",
    "\n",
    "**束搜索（beam search）** 是贪心搜索的一个改进版本。\n",
    "它有一个超参数，名为<b>束宽（beam size）$k$ </b>。\n",
    "在时间步$1$，我们选择具有最高条件概率的$k$个词元。\n",
    "这$k$个词元将分别是$k$个候选输出序列的第一个词元。\n",
    "在随后的每个时间步，基于上一时间步的$k$个候选输出序列，\n",
    "我们将继续从$k\\left|\\mathcal{Y}\\right|$个可能的选择中\n",
    "挑出具有最高条件概率的$k$个候选输出序列。\n",
    "\n",
    "<center><img src='../img/beam-search.svg'/></center>\n",
    "<center> 图 9.8.3束搜索过程（束宽：2，输出序列的最大长度：3）。候选输出序列是$A$、$C$、$AB$、$CE$、$ABD$和$CED$</center><br>\n",
    "\n",
    "\n",
    "图9.8.3演示了束搜索的过程。\n",
    "假设输出的词表只包含五个元素：\n",
    "$\\mathcal{Y} = \\{A, B, C, D, E\\}$，\n",
    "其中有一个是“&lt;eos&gt;”。\n",
    "设置束宽为$2$，输出序列的最大长度为$3$。\n",
    "在时间步$1$，假设具有最高条件概率\n",
    "$P(y_1 \\mid \\mathbf{c})$的词元是$A$和$C$。\n",
    "在时间步$2$，我们计算所有$y_2 \\in \\mathcal{Y}$为：\n",
    "\n",
    "$$\\begin{aligned}P(A, y_2 \\mid \\mathbf{c}) = P(A \\mid \\mathbf{c})P(y_2 \\mid A, \\mathbf{c}),\\\\ P(C, y_2 \\mid \\mathbf{c}) = P(C \\mid \\mathbf{c})P(y_2 \\mid C, \\mathbf{c}),\\end{aligned}  \\tag{9.8.2}$$  \n",
    "\n",
    "从这十个值中选择最大的两个，\n",
    "比如$P(A, B \\mid \\mathbf{c})$和$P(C, E \\mid \\mathbf{c})$。\n",
    "然后在时间步$3$，我们计算所有$y_3 \\in \\mathcal{Y}$为：\n",
    "\n",
    "$$\\begin{aligned}P(A, B, y_3 \\mid \\mathbf{c}) = P(A, B \\mid \\mathbf{c})P(y_3 \\mid A, B, \\mathbf{c}),\\\\P(C, E, y_3 \\mid \\mathbf{c}) = P(C, E \\mid \\mathbf{c})P(y_3 \\mid C, E, \\mathbf{c}),\\end{aligned}  \\tag{9.8.3}$$ \n",
    "\n",
    "从这十个值中选择最大的两个，\n",
    "即$P(A, B, D \\mid \\mathbf{c})$和$P(C, E, D \\mid  \\mathbf{c})$，\n",
    "我们会得到六个候选输出序列：\n",
    "（1）$A$；（2）$C$；（3）$A,B$；（4）$C,E$；（5）$A,B,D$；（6）$C,E,D$。\n",
    "\n",
    "最后，基于这六个序列（例如，丢弃包括“&lt;eos&gt;”和之后的部分），\n",
    "我们获得最终候选输出序列集合。\n",
    "然后我们选择其中条件概率乘积最高的序列作为输出序列：\n",
    "\n",
    "$$ \\frac{1}{L^\\alpha} \\log P(y_1, \\ldots, y_{L}\\mid \\mathbf{c}) = \\frac{1}{L^\\alpha} \\sum_{t'=1}^L \\log P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c}), \\tag{9.8.4}$$\n",
    "\n",
    "\n",
    "其中$L$是最终候选序列的长度，\n",
    "$\\alpha$通常设置为$0.75$。\n",
    "因为一个较长的序列在公式9.8.4\n",
    "的求和中会有更多的对数项，\n",
    "因此分母中的$L^\\alpha$用于惩罚长序列。\n",
    "\n",
    "束搜索的计算量为$\\mathcal{O}(k\\left|\\mathcal{Y}\\right|T')$，\n",
    "这个结果介于贪心搜索和穷举搜索之间。\n",
    "实际上，贪心搜索可以看作是一种束宽为$1$的特殊类型的束搜索。\n",
    "通过灵活地选择束宽，束搜索可以在正确率和计算代价之间进行权衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- **要点：**\n",
    "  - **束搜索介绍**：束搜索（beam search）是贪心搜索的一个改进版本，其实际应用介于穷举搜索和贪心搜索之间。\n",
    "  - **束宽**：束搜索有一个超参数，称为束宽（beam size）$k$。\n",
    "    - 在时间步$1$，选择具有最高条件概率的$k$个词元。\n",
    "    - 在后续的每个时间步，基于上一时间步的$k$个候选输出序列，继续从$k\\left|\\mathcal{Y}\\right|$个可能的选择中挑出具有最高条件概率的$k$个候选输出序列。\n",
    "  - **束搜索过程**：在每个时间步，都会计算所有可能的候选序列并从中选择条件概率最大的$k$个。\n",
    "  - **最终候选输出序列**：在所有时间步完成后，我们获得最终候选输出序列集合。然后我们选择其中条件概率乘积最高的序列作为输出序列。\n",
    "  - **长度惩罚**：因为一个较长的序列在公式9.8.4的求和中会有更多的对数项，因此分母中的$L^\\alpha$用于惩罚长序列。\n",
    "  - **计算量**：束搜索的计算量为$\\mathcal{O}(k\\left|\\mathcal{Y}\\right|T')$，这个结果介于贪心搜索和穷举搜索之间。实际上，贪心搜索可以看作是一种束宽为$1$的特殊类型的束搜索。通过灵活地选择束宽，束搜索可以在正确率和计算代价之间进行权衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 序列搜索策略包括贪心搜索、穷举搜索和束搜索。\n",
    "* 贪心搜索所选取序列的计算量最小，但精度相对较低。\n",
    "* 穷举搜索所选取序列的精度最高，但计算量最大。\n",
    "* 束搜索通过灵活选择束宽，在正确率和计算代价之间进行权衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "- **附录：束搜索实例代码**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始束搜索 (beam_width=2, max_length=3):\n",
      "----------------------------------------\n",
      "\n",
      "时间步 1:\n",
      "候选序列: ('A',), log概率: -0.5108\n",
      "候选序列: ('B',), log概率: -2.3026\n",
      "候选序列: ('C',), log概率: -1.6094\n",
      "候选序列: ('D',), log概率: -2.9957\n",
      "候选序列: ('E',), log概率: -2.9957\n",
      "\n",
      "保留的top 2 候选:\n",
      "序列: ('A',), log概率: -0.5108\n",
      "序列: ('C',), log概率: -1.6094\n",
      "\n",
      "时间步 2:\n",
      "候选序列: ('A', 'A'), log概率: -2.8134\n",
      "候选序列: ('A', 'B'), log概率: -1.2040\n",
      "候选序列: ('A', 'C'), log概率: -2.8134\n",
      "候选序列: ('A', 'D'), log概率: -2.1203\n",
      "候选序列: ('A', 'E'), log概率: -2.8134\n",
      "候选序列: ('C', 'A'), log概率: -3.9120\n",
      "候选序列: ('C', 'B'), log概率: -3.2189\n",
      "候选序列: ('C', 'C'), log概率: -3.9120\n",
      "候选序列: ('C', 'D'), log概率: -3.9120\n",
      "候选序列: ('C', 'E'), log概率: -2.3026\n",
      "\n",
      "保留的top 2 候选:\n",
      "序列: ('A', 'B'), log概率: -1.2040\n",
      "序列: ('A', 'D'), log概率: -2.1203\n",
      "\n",
      "时间步 3:\n",
      "候选序列: ('A', 'B', 'A'), log概率: -3.5066\n",
      "候选序列: ('A', 'B', 'B'), log概率: -3.5066\n",
      "候选序列: ('A', 'B', 'C'), log概率: -3.5066\n",
      "候选序列: ('A', 'B', 'D'), log概率: -1.7148\n",
      "候选序列: ('A', 'B', 'E'), log概率: -3.5066\n",
      "候选序列: ('A', 'D', 'A'), log概率: -3.7297\n",
      "候选序列: ('A', 'D', 'B'), log概率: -3.7297\n",
      "候选序列: ('A', 'D', 'C'), log概率: -3.7297\n",
      "候选序列: ('A', 'D', 'D'), log概率: -3.7297\n",
      "候选序列: ('A', 'D', 'E'), log概率: -3.7297\n",
      "\n",
      "保留的top 2 候选:\n",
      "序列: ('A', 'B', 'D'), log概率: -1.7148\n",
      "序列: ('A', 'B', 'A'), log概率: -3.5066\n",
      "\n",
      "归一化分数计算:\n",
      "序列: ('A',), 原始分数: -0.5108, 长度: 1, 归一化分数: -0.5108\n",
      "序列: ('C',), 原始分数: -1.6094, 长度: 1, 归一化分数: -1.6094\n",
      "序列: ('A', 'B'), 原始分数: -1.2040, 长度: 2, 归一化分数: -0.7159\n",
      "序列: ('A', 'D'), 原始分数: -2.1203, 长度: 2, 归一化分数: -1.2607\n",
      "序列: ('A', 'B', 'D'), 原始分数: -1.7148, 长度: 3, 归一化分数: -0.7523\n",
      "序列: ('A', 'B', 'A'), 原始分数: -3.5066, 长度: 3, 归一化分数: -1.5383\n",
      "\n",
      "所有候选序列的最终得分:\n",
      "序列: ('A',), 归一化得分: -0.5108, 原始log概率: -0.5108\n",
      "序列: ('A', 'B'), 归一化得分: -0.7159, 原始log概率: -1.2040\n",
      "序列: ('A', 'B', 'D'), 归一化得分: -0.7523, 原始log概率: -1.7148\n",
      "序列: ('A', 'D'), 归一化得分: -1.2607, 原始log概率: -2.1203\n",
      "序列: ('A', 'B', 'A'), 归一化得分: -1.5383, 原始log概率: -3.5066\n",
      "序列: ('C',), 归一化得分: -1.6094, 原始log概率: -1.6094\n",
      "\n",
      "最终结果:\n",
      "----------------------------------------\n",
      "最佳序列: ('A', 'B', 'D')\n",
      "归一化得分: -0.7523\n",
      "原始log概率: -1.7148\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class BeamSearch:\n",
    "    def __init__(self, beam_width=2, max_length=3, alpha=0.75):\n",
    "        self.beam_width = beam_width\n",
    "        self.max_length = max_length\n",
    "        self.alpha = alpha\n",
    "        # 定义词表\n",
    "        self.vocab = ['A', 'B', 'C', 'D', 'E']\n",
    "        \n",
    "    def get_conditional_prob(self, prev_tokens=None):\n",
    "        \"\"\"模拟获取条件概率的函数\"\"\"\n",
    "        # 这里使用一个简单的概率分布作为示例\n",
    "        probs = defaultdict(float)\n",
    "        if prev_tokens is None or len(prev_tokens) == 0:  # 第一步\n",
    "            probs = {'A': 0.6, 'B': 0.1, 'C': 0.2, 'D': 0.05, 'E': 0.05}\n",
    "        elif prev_tokens == ('A',):  # A后面的概率\n",
    "            probs = {'A': 0.1, 'B': 0.5, 'C': 0.1, 'D': 0.2, 'E': 0.1}\n",
    "        elif prev_tokens == ('C',):  # C后面的概率\n",
    "            probs = {'A': 0.1, 'B': 0.2, 'C': 0.1, 'D': 0.1, 'E': 0.5}\n",
    "        elif prev_tokens == ('A', 'B'):  # AB后面的概率\n",
    "            probs = {'A': 0.1, 'B': 0.1, 'C': 0.1, 'D': 0.6, 'E': 0.1}\n",
    "        elif prev_tokens == ('C', 'E'):  # CE后面的概率\n",
    "            probs = {'A': 0.1, 'B': 0.1, 'C': 0.1, 'D': 0.5, 'E': 0.2}\n",
    "        else:  # 默认概率分布\n",
    "            probs = {token: 0.2 for token in self.vocab}\n",
    "        return probs\n",
    "\n",
    "    def search(self):\n",
    "        # 初始化候选序列\n",
    "        candidates = [((), 0.0)]  # (序列, log概率)\n",
    "        final_candidates = []\n",
    "\n",
    "        # 对每个时间步进行搜索\n",
    "        for step in range(self.max_length):\n",
    "            print(f\"\\n时间步 {step + 1}:\")\n",
    "            all_next_candidates = []\n",
    "            \n",
    "            # 对当前的每个候选序列进行扩展\n",
    "            for seq, score in candidates:\n",
    "                probs = self.get_conditional_prob(seq)\n",
    "                \n",
    "                # 计算所有可能的下一个词元\n",
    "                for next_token, prob in probs.items():\n",
    "                    new_seq = seq + (next_token,)\n",
    "                    new_score = score + math.log(prob)\n",
    "                    all_next_candidates.append((new_seq, new_score))\n",
    "                    print(f\"候选序列: {new_seq}, log概率: {new_score:.4f}\")\n",
    "\n",
    "            # 选择前beam_width个最佳候选\n",
    "            candidates = sorted(all_next_candidates, \n",
    "                             key=lambda x: x[1], \n",
    "                             reverse=True)[:self.beam_width]\n",
    "            print(f\"\\n保留的top {self.beam_width} 候选:\")\n",
    "            for seq, score in candidates:\n",
    "                print(f\"序列: {seq}, log概率: {score:.4f}\")\n",
    "                final_candidates.append((seq, score))\n",
    "\n",
    "        # 计算归一化分数\n",
    "        print(\"\\n归一化分数计算:\")\n",
    "        final_scores = []\n",
    "        for seq, score in final_candidates:\n",
    "            length = len(seq)\n",
    "            if length > 0:\n",
    "                normalized_score = score / (length ** self.alpha)\n",
    "                final_scores.append((seq, normalized_score, score))\n",
    "                print(f\"序列: {seq}, 原始分数: {score:.4f}, \"\n",
    "                      f\"长度: {length}, 归一化分数: {normalized_score:.4f}\")\n",
    "        \n",
    "        if not final_scores:\n",
    "            return None, None, None\n",
    "        \n",
    "        # 选择得分最高的序列\n",
    "        best = []\n",
    "        for score in final_scores:\n",
    "            if len(score[0])==self.max_length:\n",
    "                best.append(score)\n",
    "        best_seq, best_norm_score, best_raw_score = max(best, key=lambda x: x[0])\n",
    "        \n",
    "        # 打印所有候选序列的最终得分\n",
    "        print(\"\\n所有候选序列的最终得分:\")\n",
    "        for seq, norm_score, raw_score in sorted(final_scores, \n",
    "                                               key=lambda x: x[1], \n",
    "                                               reverse=True):\n",
    "            print(f\"序列: {seq}, 归一化得分: {norm_score:.4f}, \"\n",
    "                  f\"原始log概率: {raw_score:.4f}\")\n",
    "        \n",
    "        return best_seq, best_norm_score, best_raw_score\n",
    "\n",
    "# 运行束搜索\n",
    "print(\"开始束搜索 (beam_width=2, max_length=3):\")\n",
    "print(\"----------------------------------------\")\n",
    "beam_search = BeamSearch(beam_width=2, max_length=3)\n",
    "best_sequence, best_norm_score, best_raw_score = beam_search.search()\n",
    "\n",
    "print(\"\\n最终结果:\")\n",
    "print(\"----------------------------------------\")\n",
    "if best_sequence is not None:\n",
    "    print(f\"最佳序列: {best_sequence}\")\n",
    "    print(f\"归一化得分: {best_norm_score:.4f}\")\n",
    "    print(f\"原始log概率: {best_raw_score:.4f}\")\n",
    "else:\n",
    "    print(\"未找到有效序列\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
