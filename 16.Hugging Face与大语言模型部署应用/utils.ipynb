{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a597ad3-93cb-455d-9c40-efdb80ef5450",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c366aef497f647e18634a2cf4dfdf4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad57268be22c417dbab98f131dd2986a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/603 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6342b59b322749058abb9416adb02c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/146 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91600f72c345429daeff8b44b84f2e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/11.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f8e77766644e5caeea60bf844be99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4611e128f944eb4bab9396b063d18be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading Notice:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c7560bde23494bb7dbd48962412d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading LICENSE:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e31b34695441738523be78e2de6510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62b76b151f54426af9aa8e8f41a05e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00006.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b547e1e7ea4f4f39a3181109ff3fc488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/29.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d300e68f014b9797a5b3b4dec8049d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00006.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb1afe0c7c94d588c4a007733a6133e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00003-of-00006.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b815c8519a54456abe0c3a0dd65fb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00004-of-00006.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3699acde046a43ef99f86ceb7e4766fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdca9419be24d44a5516463fa5b8ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00005-of-00006.bin:   0%|          | 0.00/9.87G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3faf22a16e4d5a9c6c183310ffd516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00006-of-00006.bin:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ea47fd7e5142ec87a7b6ad84ce98fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061a5d544118451b841b6249f0f90816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "repo_id = \"microsoft/Orca-2-13b\"\n",
    "snapshot_download(repo_id,cache_dir=r'D:\\Download\\huggingface',\n",
    "                  local_dir=r'D:\\Download\\huggingface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b027f79d-9bde-4719-893c-9820ff4cd236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0msnapshot_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrepo_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrepo_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrevision\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mendpoint\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache_dir\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlocal_dir\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlocal_dir_use_symlinks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlibrary_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlibrary_version\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muser_agent\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mproxies\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0metag_timeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mresume_download\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mforce_download\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtoken\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mallow_patterns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mignore_patterns\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_workers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtqdm_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Download repo files.\n",
       "\n",
       "Download a whole snapshot of a repo's files at the specified revision. This is useful when you want all files from\n",
       "a repo, because you don't know which ones you will need a priori. All files are nested inside a folder in order\n",
       "to keep their actual filename relative to that folder. You can also filter which files to download using\n",
       "`allow_patterns` and `ignore_patterns`.\n",
       "\n",
       "If `local_dir` is provided, the file structure from the repo will be replicated in this location. You can configure\n",
       "how you want to move those files:\n",
       "  - If `local_dir_use_symlinks=\"auto\"` (default), files are downloaded and stored in the cache directory as blob\n",
       "    files. Small files (<5MB) are duplicated in `local_dir` while a symlink is created for bigger files. The goal\n",
       "    is to be able to manually edit and save small files without corrupting the cache while saving disk space for\n",
       "    binary files. The 5MB threshold can be configured with the `HF_HUB_LOCAL_DIR_AUTO_SYMLINK_THRESHOLD`\n",
       "    environment variable.\n",
       "  - If `local_dir_use_symlinks=True`, files are downloaded, stored in the cache directory and symlinked in `local_dir`.\n",
       "    This is optimal in term of disk usage but files must not be manually edited.\n",
       "  - If `local_dir_use_symlinks=False` and the blob files exist in the cache directory, they are duplicated in the\n",
       "    local dir. This means disk usage is not optimized.\n",
       "  - Finally, if `local_dir_use_symlinks=False` and the blob files do not exist in the cache directory, then the\n",
       "    files are downloaded and directly placed under `local_dir`. This means if you need to download them again later,\n",
       "    they will be re-downloaded entirely.\n",
       "\n",
       "An alternative would be to clone the repo but this requires git and git-lfs to be installed and properly\n",
       "configured. It is also not possible to filter which files to download when cloning a repository using git.\n",
       "\n",
       "Args:\n",
       "    repo_id (`str`):\n",
       "        A user or an organization name and a repo name separated by a `/`.\n",
       "    repo_type (`str`, *optional*):\n",
       "        Set to `\"dataset\"` or `\"space\"` if downloading from a dataset or space,\n",
       "        `None` or `\"model\"` if downloading from a model. Default is `None`.\n",
       "    revision (`str`, *optional*):\n",
       "        An optional Git revision id which can be a branch name, a tag, or a\n",
       "        commit hash.\n",
       "    endpoint (`str`, *optional*):\n",
       "        Hugging Face Hub base url. Will default to https://huggingface.co/. Otherwise, one can set the `HF_ENDPOINT`\n",
       "        environment variable.\n",
       "    cache_dir (`str`, `Path`, *optional*):\n",
       "        Path to the folder where cached files are stored.\n",
       "    local_dir (`str` or `Path`, *optional*):\n",
       "        If provided, the downloaded files will be placed under this directory, either as symlinks (default) or\n",
       "        regular files (see description for more details).\n",
       "    local_dir_use_symlinks (`\"auto\"` or `bool`, defaults to `\"auto\"`):\n",
       "        To be used with `local_dir`. If set to \"auto\", the cache directory will be used and the file will be either\n",
       "        duplicated or symlinked to the local directory depending on its size. It set to `True`, a symlink will be\n",
       "        created, no matter the file size. If set to `False`, the file will either be duplicated from cache (if\n",
       "        already exists) or downloaded from the Hub and not cached. See description for more details.\n",
       "    library_name (`str`, *optional*):\n",
       "        The name of the library to which the object corresponds.\n",
       "    library_version (`str`, *optional*):\n",
       "        The version of the library.\n",
       "    user_agent (`str`, `dict`, *optional*):\n",
       "        The user-agent info in the form of a dictionary or a string.\n",
       "    proxies (`dict`, *optional*):\n",
       "        Dictionary mapping protocol to the URL of the proxy passed to\n",
       "        `requests.request`.\n",
       "    etag_timeout (`float`, *optional*, defaults to `10`):\n",
       "        When fetching ETag, how many seconds to wait for the server to send\n",
       "        data before giving up which is passed to `requests.request`.\n",
       "    resume_download (`bool`, *optional*, defaults to `False):\n",
       "        If `True`, resume a previously interrupted download.\n",
       "    force_download (`bool`, *optional*, defaults to `False`):\n",
       "        Whether the file should be downloaded even if it already exists in the local cache.\n",
       "    token (`str`, `bool`, *optional*):\n",
       "        A token to be used for the download.\n",
       "            - If `True`, the token is read from the HuggingFace config\n",
       "              folder.\n",
       "            - If a string, it's used as the authentication token.\n",
       "    local_files_only (`bool`, *optional*, defaults to `False`):\n",
       "        If `True`, avoid downloading the file and return the path to the\n",
       "        local cached file if it exists.\n",
       "    allow_patterns (`List[str]` or `str`, *optional*):\n",
       "        If provided, only files matching at least one pattern are downloaded.\n",
       "    ignore_patterns (`List[str]` or `str`, *optional*):\n",
       "        If provided, files matching any of the patterns are not downloaded.\n",
       "    max_workers (`int`, *optional*):\n",
       "        Number of concurrent threads to download files (1 thread = 1 file download).\n",
       "        Defaults to 8.\n",
       "    tqdm_class (`tqdm`, *optional*):\n",
       "        If provided, overwrites the default behavior for the progress bar. Passed\n",
       "        argument must inherit from `tqdm.auto.tqdm` or at least mimic its behavior.\n",
       "        Note that the `tqdm_class` is not passed to each individual download.\n",
       "        Defaults to the custom HF progress bar that can be disabled by setting\n",
       "        `HF_HUB_DISABLE_PROGRESS_BARS` environment variable.\n",
       "\n",
       "Returns:\n",
       "    Local folder path (string) of repo snapshot\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Raises the following errors:\n",
       "\n",
       "- [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)\n",
       "  if `token=True` and the token cannot be found.\n",
       "- [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError) if\n",
       "  ETag cannot be determined.\n",
       "- [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\n",
       "  if some parameter value is invalid\n",
       "\n",
       "</Tip>\n",
       "\u001b[1;31mFile:\u001b[0m      f:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\huggingface_hub\\_snapshot_download.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5288d8-cef3-4b82-ae4c-3e0ddac1fd72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ALIGN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALIGN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALTCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALTCLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ASTConfig',\n",
       " 'ASTFeatureExtractor',\n",
       " 'ASTForAudioClassification',\n",
       " 'ASTModel',\n",
       " 'ASTPreTrainedModel',\n",
       " 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'AUTOFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'AUTOFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'Adafactor',\n",
       " 'AdamW',\n",
       " 'AdamWeightDecay',\n",
       " 'AdaptiveEmbedding',\n",
       " 'AddedToken',\n",
       " 'Agent',\n",
       " 'AlbertConfig',\n",
       " 'AlbertForMaskedLM',\n",
       " 'AlbertForMultipleChoice',\n",
       " 'AlbertForPreTraining',\n",
       " 'AlbertForQuestionAnswering',\n",
       " 'AlbertForSequenceClassification',\n",
       " 'AlbertForTokenClassification',\n",
       " 'AlbertModel',\n",
       " 'AlbertPreTrainedModel',\n",
       " 'AlbertTokenizer',\n",
       " 'AlbertTokenizerFast',\n",
       " 'AlignConfig',\n",
       " 'AlignModel',\n",
       " 'AlignPreTrainedModel',\n",
       " 'AlignProcessor',\n",
       " 'AlignTextConfig',\n",
       " 'AlignTextModel',\n",
       " 'AlignVisionConfig',\n",
       " 'AlignVisionModel',\n",
       " 'AltCLIPConfig',\n",
       " 'AltCLIPModel',\n",
       " 'AltCLIPPreTrainedModel',\n",
       " 'AltCLIPProcessor',\n",
       " 'AltCLIPTextConfig',\n",
       " 'AltCLIPTextModel',\n",
       " 'AltCLIPVisionConfig',\n",
       " 'AltCLIPVisionModel',\n",
       " 'AlternatingCodebooksLogitsProcessor',\n",
       " 'AudioClassificationPipeline',\n",
       " 'AutoBackbone',\n",
       " 'AutoConfig',\n",
       " 'AutoFeatureExtractor',\n",
       " 'AutoImageProcessor',\n",
       " 'AutoModel',\n",
       " 'AutoModelForAudioClassification',\n",
       " 'AutoModelForAudioFrameClassification',\n",
       " 'AutoModelForAudioXVector',\n",
       " 'AutoModelForCTC',\n",
       " 'AutoModelForCausalLM',\n",
       " 'AutoModelForDepthEstimation',\n",
       " 'AutoModelForDocumentQuestionAnswering',\n",
       " 'AutoModelForImageClassification',\n",
       " 'AutoModelForImageSegmentation',\n",
       " 'AutoModelForInstanceSegmentation',\n",
       " 'AutoModelForMaskGeneration',\n",
       " 'AutoModelForMaskedImageModeling',\n",
       " 'AutoModelForMaskedLM',\n",
       " 'AutoModelForMultipleChoice',\n",
       " 'AutoModelForNextSentencePrediction',\n",
       " 'AutoModelForObjectDetection',\n",
       " 'AutoModelForPreTraining',\n",
       " 'AutoModelForQuestionAnswering',\n",
       " 'AutoModelForSemanticSegmentation',\n",
       " 'AutoModelForSeq2SeqLM',\n",
       " 'AutoModelForSequenceClassification',\n",
       " 'AutoModelForSpeechSeq2Seq',\n",
       " 'AutoModelForTableQuestionAnswering',\n",
       " 'AutoModelForTextEncoding',\n",
       " 'AutoModelForTextToSpectrogram',\n",
       " 'AutoModelForTextToWaveform',\n",
       " 'AutoModelForTokenClassification',\n",
       " 'AutoModelForUniversalSegmentation',\n",
       " 'AutoModelForVideoClassification',\n",
       " 'AutoModelForVision2Seq',\n",
       " 'AutoModelForVisualQuestionAnswering',\n",
       " 'AutoModelForZeroShotImageClassification',\n",
       " 'AutoModelForZeroShotObjectDetection',\n",
       " 'AutoModelWithLMHead',\n",
       " 'AutoProcessor',\n",
       " 'AutoTokenizer',\n",
       " 'AutoformerConfig',\n",
       " 'AutoformerForPrediction',\n",
       " 'AutoformerModel',\n",
       " 'AutoformerPreTrainedModel',\n",
       " 'AutomaticSpeechRecognitionPipeline',\n",
       " 'AzureOpenAiAgent',\n",
       " 'BARK_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BART_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIGBIRD_PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIOGPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIOGPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLENDERBOT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLENDERBOT_SMALL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLIP_2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLIP_2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLOOM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BRIDGETOWER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BRIDGETOWER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BarkCausalModel',\n",
       " 'BarkCoarseConfig',\n",
       " 'BarkCoarseModel',\n",
       " 'BarkConfig',\n",
       " 'BarkFineConfig',\n",
       " 'BarkFineModel',\n",
       " 'BarkModel',\n",
       " 'BarkPreTrainedModel',\n",
       " 'BarkProcessor',\n",
       " 'BarkSemanticConfig',\n",
       " 'BarkSemanticModel',\n",
       " 'BartConfig',\n",
       " 'BartForCausalLM',\n",
       " 'BartForConditionalGeneration',\n",
       " 'BartForQuestionAnswering',\n",
       " 'BartForSequenceClassification',\n",
       " 'BartModel',\n",
       " 'BartPreTrainedModel',\n",
       " 'BartPretrainedModel',\n",
       " 'BartTokenizer',\n",
       " 'BartTokenizerFast',\n",
       " 'BarthezTokenizer',\n",
       " 'BarthezTokenizerFast',\n",
       " 'BartphoTokenizer',\n",
       " 'BasicTokenizer',\n",
       " 'BatchEncoding',\n",
       " 'BatchFeature',\n",
       " 'BeamScorer',\n",
       " 'BeamSearchScorer',\n",
       " 'BeitConfig',\n",
       " 'BeitFeatureExtractor',\n",
       " 'BeitForImageClassification',\n",
       " 'BeitForMaskedImageModeling',\n",
       " 'BeitForSemanticSegmentation',\n",
       " 'BeitImageProcessor',\n",
       " 'BeitModel',\n",
       " 'BeitPreTrainedModel',\n",
       " 'BertConfig',\n",
       " 'BertForMaskedLM',\n",
       " 'BertForMultipleChoice',\n",
       " 'BertForNextSentencePrediction',\n",
       " 'BertForPreTraining',\n",
       " 'BertForQuestionAnswering',\n",
       " 'BertForSequenceClassification',\n",
       " 'BertForTokenClassification',\n",
       " 'BertGenerationConfig',\n",
       " 'BertGenerationDecoder',\n",
       " 'BertGenerationEncoder',\n",
       " 'BertGenerationPreTrainedModel',\n",
       " 'BertGenerationTokenizer',\n",
       " 'BertJapaneseTokenizer',\n",
       " 'BertLMHeadModel',\n",
       " 'BertLayer',\n",
       " 'BertModel',\n",
       " 'BertPreTrainedModel',\n",
       " 'BertTokenizer',\n",
       " 'BertTokenizerFast',\n",
       " 'BertweetTokenizer',\n",
       " 'BigBirdConfig',\n",
       " 'BigBirdForCausalLM',\n",
       " 'BigBirdForMaskedLM',\n",
       " 'BigBirdForMultipleChoice',\n",
       " 'BigBirdForPreTraining',\n",
       " 'BigBirdForQuestionAnswering',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdForTokenClassification',\n",
       " 'BigBirdLayer',\n",
       " 'BigBirdModel',\n",
       " 'BigBirdPegasusConfig',\n",
       " 'BigBirdPegasusForCausalLM',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BigBirdPegasusForQuestionAnswering',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'BigBirdPegasusModel',\n",
       " 'BigBirdPegasusPreTrainedModel',\n",
       " 'BigBirdPreTrainedModel',\n",
       " 'BigBirdTokenizer',\n",
       " 'BigBirdTokenizerFast',\n",
       " 'BioGptConfig',\n",
       " 'BioGptForCausalLM',\n",
       " 'BioGptForSequenceClassification',\n",
       " 'BioGptForTokenClassification',\n",
       " 'BioGptModel',\n",
       " 'BioGptPreTrainedModel',\n",
       " 'BioGptTokenizer',\n",
       " 'BitBackbone',\n",
       " 'BitConfig',\n",
       " 'BitForImageClassification',\n",
       " 'BitImageProcessor',\n",
       " 'BitModel',\n",
       " 'BitPreTrainedModel',\n",
       " 'BitsAndBytesConfig',\n",
       " 'BlenderbotConfig',\n",
       " 'BlenderbotForCausalLM',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotModel',\n",
       " 'BlenderbotPreTrainedModel',\n",
       " 'BlenderbotSmallConfig',\n",
       " 'BlenderbotSmallForCausalLM',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'BlenderbotSmallModel',\n",
       " 'BlenderbotSmallPreTrainedModel',\n",
       " 'BlenderbotSmallTokenizer',\n",
       " 'BlenderbotSmallTokenizerFast',\n",
       " 'BlenderbotTokenizer',\n",
       " 'BlenderbotTokenizerFast',\n",
       " 'Blip2Config',\n",
       " 'Blip2ForConditionalGeneration',\n",
       " 'Blip2Model',\n",
       " 'Blip2PreTrainedModel',\n",
       " 'Blip2Processor',\n",
       " 'Blip2QFormerConfig',\n",
       " 'Blip2QFormerModel',\n",
       " 'Blip2VisionConfig',\n",
       " 'Blip2VisionModel',\n",
       " 'BlipConfig',\n",
       " 'BlipForConditionalGeneration',\n",
       " 'BlipForImageTextRetrieval',\n",
       " 'BlipForQuestionAnswering',\n",
       " 'BlipImageProcessor',\n",
       " 'BlipModel',\n",
       " 'BlipPreTrainedModel',\n",
       " 'BlipProcessor',\n",
       " 'BlipTextConfig',\n",
       " 'BlipTextModel',\n",
       " 'BlipVisionConfig',\n",
       " 'BlipVisionModel',\n",
       " 'BloomConfig',\n",
       " 'BloomForCausalLM',\n",
       " 'BloomForQuestionAnswering',\n",
       " 'BloomForSequenceClassification',\n",
       " 'BloomForTokenClassification',\n",
       " 'BloomModel',\n",
       " 'BloomPreTrainedModel',\n",
       " 'BloomTokenizerFast',\n",
       " 'BridgeTowerConfig',\n",
       " 'BridgeTowerForContrastiveLearning',\n",
       " 'BridgeTowerForImageAndTextRetrieval',\n",
       " 'BridgeTowerForMaskedLM',\n",
       " 'BridgeTowerImageProcessor',\n",
       " 'BridgeTowerModel',\n",
       " 'BridgeTowerPreTrainedModel',\n",
       " 'BridgeTowerProcessor',\n",
       " 'BridgeTowerTextConfig',\n",
       " 'BridgeTowerVisionConfig',\n",
       " 'ByT5Tokenizer',\n",
       " 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CANINE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CANINE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CHINESE_CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CHINESE_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLAP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPConfig',\n",
       " 'CLIPFeatureExtractor',\n",
       " 'CLIPImageProcessor',\n",
       " 'CLIPModel',\n",
       " 'CLIPPreTrainedModel',\n",
       " 'CLIPProcessor',\n",
       " 'CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPSegConfig',\n",
       " 'CLIPSegForImageSegmentation',\n",
       " 'CLIPSegModel',\n",
       " 'CLIPSegPreTrainedModel',\n",
       " 'CLIPSegProcessor',\n",
       " 'CLIPSegTextConfig',\n",
       " 'CLIPSegTextModel',\n",
       " 'CLIPSegVisionConfig',\n",
       " 'CLIPSegVisionModel',\n",
       " 'CLIPTextConfig',\n",
       " 'CLIPTextModel',\n",
       " 'CLIPTextModelWithProjection',\n",
       " 'CLIPTokenizer',\n",
       " 'CLIPTokenizerFast',\n",
       " 'CLIPVisionConfig',\n",
       " 'CLIPVisionModel',\n",
       " 'CLIPVisionModelWithProjection',\n",
       " 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CODEGEN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONDITIONAL_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONDITIONAL_DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONFIG_MAPPING',\n",
       " 'CONFIG_NAME',\n",
       " 'CONVBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONVNEXTV2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVNEXTV2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONVNEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVNEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CPMANT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CPMANT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CTRLConfig',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CTRLLMHeadModel',\n",
       " 'CTRLModel',\n",
       " 'CTRLPreTrainedModel',\n",
       " 'CTRLTokenizer',\n",
       " 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CVT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CVT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CamembertConfig',\n",
       " 'CamembertForCausalLM',\n",
       " 'CamembertForMaskedLM',\n",
       " 'CamembertForMultipleChoice',\n",
       " 'CamembertForQuestionAnswering',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CamembertForTokenClassification',\n",
       " 'CamembertModel',\n",
       " 'CamembertPreTrainedModel',\n",
       " 'CamembertTokenizer',\n",
       " 'CamembertTokenizerFast',\n",
       " 'CanineConfig',\n",
       " 'CanineForMultipleChoice',\n",
       " 'CanineForQuestionAnswering',\n",
       " 'CanineForSequenceClassification',\n",
       " 'CanineForTokenClassification',\n",
       " 'CanineLayer',\n",
       " 'CanineModel',\n",
       " 'CaninePreTrainedModel',\n",
       " 'CanineTokenizer',\n",
       " 'CharSpan',\n",
       " 'CharacterTokenizer',\n",
       " 'ChineseCLIPConfig',\n",
       " 'ChineseCLIPFeatureExtractor',\n",
       " 'ChineseCLIPImageProcessor',\n",
       " 'ChineseCLIPModel',\n",
       " 'ChineseCLIPPreTrainedModel',\n",
       " 'ChineseCLIPProcessor',\n",
       " 'ChineseCLIPTextConfig',\n",
       " 'ChineseCLIPTextModel',\n",
       " 'ChineseCLIPVisionConfig',\n",
       " 'ChineseCLIPVisionModel',\n",
       " 'ClapAudioConfig',\n",
       " 'ClapAudioModel',\n",
       " 'ClapAudioModelWithProjection',\n",
       " 'ClapConfig',\n",
       " 'ClapFeatureExtractor',\n",
       " 'ClapModel',\n",
       " 'ClapPreTrainedModel',\n",
       " 'ClapProcessor',\n",
       " 'ClapTextConfig',\n",
       " 'ClapTextModel',\n",
       " 'ClapTextModelWithProjection',\n",
       " 'ClassifierFreeGuidanceLogitsProcessor',\n",
       " 'CodeGenConfig',\n",
       " 'CodeGenForCausalLM',\n",
       " 'CodeGenModel',\n",
       " 'CodeGenPreTrainedModel',\n",
       " 'CodeGenTokenizer',\n",
       " 'CodeGenTokenizerFast',\n",
       " 'CodeLlamaTokenizer',\n",
       " 'CodeLlamaTokenizerFast',\n",
       " 'ConditionalDetrConfig',\n",
       " 'ConditionalDetrFeatureExtractor',\n",
       " 'ConditionalDetrForObjectDetection',\n",
       " 'ConditionalDetrForSegmentation',\n",
       " 'ConditionalDetrImageProcessor',\n",
       " 'ConditionalDetrModel',\n",
       " 'ConditionalDetrPreTrainedModel',\n",
       " 'ConstrainedBeamSearchScorer',\n",
       " 'Constraint',\n",
       " 'ConstraintListState',\n",
       " 'Conv1D',\n",
       " 'ConvBertConfig',\n",
       " 'ConvBertForMaskedLM',\n",
       " 'ConvBertForMultipleChoice',\n",
       " 'ConvBertForQuestionAnswering',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'ConvBertForTokenClassification',\n",
       " 'ConvBertLayer',\n",
       " 'ConvBertModel',\n",
       " 'ConvBertPreTrainedModel',\n",
       " 'ConvBertTokenizer',\n",
       " 'ConvBertTokenizerFast',\n",
       " 'ConvNextBackbone',\n",
       " 'ConvNextConfig',\n",
       " 'ConvNextFeatureExtractor',\n",
       " 'ConvNextForImageClassification',\n",
       " 'ConvNextImageProcessor',\n",
       " 'ConvNextModel',\n",
       " 'ConvNextPreTrainedModel',\n",
       " 'ConvNextV2Backbone',\n",
       " 'ConvNextV2Config',\n",
       " 'ConvNextV2ForImageClassification',\n",
       " 'ConvNextV2Model',\n",
       " 'ConvNextV2PreTrainedModel',\n",
       " 'Conversation',\n",
       " 'ConversationalPipeline',\n",
       " 'CpmAntConfig',\n",
       " 'CpmAntForCausalLM',\n",
       " 'CpmAntModel',\n",
       " 'CpmAntPreTrainedModel',\n",
       " 'CpmAntTokenizer',\n",
       " 'CpmTokenizer',\n",
       " 'CpmTokenizerFast',\n",
       " 'CsvPipelineDataFormat',\n",
       " 'CvtConfig',\n",
       " 'CvtForImageClassification',\n",
       " 'CvtModel',\n",
       " 'CvtPreTrainedModel',\n",
       " 'DATA2VEC_AUDIO_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DATA2VEC_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DATA2VEC_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DATA2VEC_VISION_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DATA2VEC_VISION_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEBERTA_V2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DECISION_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DECISION_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEFORMABLE_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEFORMABLE_DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DETA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DETA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DINAT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DINAT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DINOV2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DINOV2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DONUT_SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DONUT_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPRConfig',\n",
       " 'DPRContextEncoder',\n",
       " 'DPRContextEncoderTokenizer',\n",
       " 'DPRContextEncoderTokenizerFast',\n",
       " 'DPRPreTrainedModel',\n",
       " 'DPRPretrainedContextEncoder',\n",
       " 'DPRPretrainedQuestionEncoder',\n",
       " 'DPRPretrainedReader',\n",
       " 'DPRQuestionEncoder',\n",
       " 'DPRQuestionEncoderTokenizer',\n",
       " 'DPRQuestionEncoderTokenizerFast',\n",
       " 'DPRReader',\n",
       " 'DPRReaderOutput',\n",
       " 'DPRReaderTokenizer',\n",
       " 'DPRReaderTokenizerFast',\n",
       " 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPTConfig',\n",
       " 'DPTFeatureExtractor',\n",
       " 'DPTForDepthEstimation',\n",
       " 'DPTForSemanticSegmentation',\n",
       " 'DPTImageProcessor',\n",
       " 'DPTModel',\n",
       " 'DPTPreTrainedModel',\n",
       " 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'Data2VecAudioConfig',\n",
       " 'Data2VecAudioForAudioFrameClassification',\n",
       " 'Data2VecAudioForCTC',\n",
       " 'Data2VecAudioForSequenceClassification',\n",
       " 'Data2VecAudioForXVector',\n",
       " 'Data2VecAudioModel',\n",
       " 'Data2VecAudioPreTrainedModel',\n",
       " 'Data2VecTextConfig',\n",
       " 'Data2VecTextForCausalLM',\n",
       " 'Data2VecTextForMaskedLM',\n",
       " 'Data2VecTextForMultipleChoice',\n",
       " 'Data2VecTextForQuestionAnswering',\n",
       " 'Data2VecTextForSequenceClassification',\n",
       " 'Data2VecTextForTokenClassification',\n",
       " 'Data2VecTextModel',\n",
       " 'Data2VecTextPreTrainedModel',\n",
       " 'Data2VecVisionConfig',\n",
       " 'Data2VecVisionForImageClassification',\n",
       " 'Data2VecVisionForSemanticSegmentation',\n",
       " 'Data2VecVisionModel',\n",
       " 'Data2VecVisionPreTrainedModel',\n",
       " 'DataCollator',\n",
       " 'DataCollatorForLanguageModeling',\n",
       " 'DataCollatorForPermutationLanguageModeling',\n",
       " 'DataCollatorForSOP',\n",
       " 'DataCollatorForSeq2Seq',\n",
       " 'DataCollatorForTokenClassification',\n",
       " 'DataCollatorForWholeWordMask',\n",
       " 'DataCollatorWithPadding',\n",
       " 'DataProcessor',\n",
       " 'DebertaConfig',\n",
       " 'DebertaForMaskedLM',\n",
       " 'DebertaForQuestionAnswering',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaForTokenClassification',\n",
       " 'DebertaModel',\n",
       " 'DebertaPreTrainedModel',\n",
       " 'DebertaTokenizer',\n",
       " 'DebertaTokenizerFast',\n",
       " 'DebertaV2Config',\n",
       " 'DebertaV2ForMaskedLM',\n",
       " 'DebertaV2ForMultipleChoice',\n",
       " 'DebertaV2ForQuestionAnswering',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DebertaV2Model',\n",
       " 'DebertaV2PreTrainedModel',\n",
       " 'DebertaV2Tokenizer',\n",
       " 'DebertaV2TokenizerFast',\n",
       " 'DecisionTransformerConfig',\n",
       " 'DecisionTransformerGPT2Model',\n",
       " 'DecisionTransformerGPT2PreTrainedModel',\n",
       " 'DecisionTransformerModel',\n",
       " 'DecisionTransformerPreTrainedModel',\n",
       " 'DefaultDataCollator',\n",
       " 'DefaultFlowCallback',\n",
       " 'DeformableDetrConfig',\n",
       " 'DeformableDetrFeatureExtractor',\n",
       " 'DeformableDetrForObjectDetection',\n",
       " 'DeformableDetrImageProcessor',\n",
       " 'DeformableDetrModel',\n",
       " 'DeformableDetrPreTrainedModel',\n",
       " 'DeiTConfig',\n",
       " 'DeiTFeatureExtractor',\n",
       " 'DeiTForImageClassification',\n",
       " 'DeiTForImageClassificationWithTeacher',\n",
       " 'DeiTForMaskedImageModeling',\n",
       " 'DeiTImageProcessor',\n",
       " 'DeiTModel',\n",
       " 'DeiTPreTrainedModel',\n",
       " 'DepthEstimationPipeline',\n",
       " 'DetaConfig',\n",
       " 'DetaForObjectDetection',\n",
       " 'DetaImageProcessor',\n",
       " 'DetaModel',\n",
       " 'DetaPreTrainedModel',\n",
       " 'DetrConfig',\n",
       " 'DetrFeatureExtractor',\n",
       " 'DetrForObjectDetection',\n",
       " 'DetrForSegmentation',\n",
       " 'DetrImageProcessor',\n",
       " 'DetrModel',\n",
       " 'DetrPreTrainedModel',\n",
       " 'DinatBackbone',\n",
       " 'DinatConfig',\n",
       " 'DinatForImageClassification',\n",
       " 'DinatModel',\n",
       " 'DinatPreTrainedModel',\n",
       " 'Dinov2Backbone',\n",
       " 'Dinov2Config',\n",
       " 'Dinov2ForImageClassification',\n",
       " 'Dinov2Model',\n",
       " 'Dinov2PreTrainedModel',\n",
       " 'DisjunctiveConstraint',\n",
       " 'DistilBertConfig',\n",
       " 'DistilBertForMaskedLM',\n",
       " 'DistilBertForMultipleChoice',\n",
       " 'DistilBertForQuestionAnswering',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'DistilBertForTokenClassification',\n",
       " 'DistilBertModel',\n",
       " 'DistilBertPreTrainedModel',\n",
       " 'DistilBertTokenizer',\n",
       " 'DistilBertTokenizerFast',\n",
       " 'DocumentQuestionAnsweringPipeline',\n",
       " 'DonutFeatureExtractor',\n",
       " 'DonutImageProcessor',\n",
       " 'DonutProcessor',\n",
       " 'DonutSwinConfig',\n",
       " 'DonutSwinModel',\n",
       " 'DonutSwinPreTrainedModel',\n",
       " 'DummyObject',\n",
       " 'EFFICIENTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'EFFICIENTNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'EFFICIENTNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ENCODEC_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ENCODEC_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ERNIE_M_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ERNIE_M_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ERNIE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ERNIE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ESM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ESM_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'EarlyStoppingCallback',\n",
       " 'EfficientFormerConfig',\n",
       " 'EfficientFormerForImageClassification',\n",
       " 'EfficientFormerForImageClassificationWithTeacher',\n",
       " 'EfficientFormerImageProcessor',\n",
       " 'EfficientFormerModel',\n",
       " 'EfficientFormerPreTrainedModel',\n",
       " 'EfficientNetConfig',\n",
       " 'EfficientNetForImageClassification',\n",
       " 'EfficientNetImageProcessor',\n",
       " 'EfficientNetModel',\n",
       " 'EfficientNetPreTrainedModel',\n",
       " 'ElectraConfig',\n",
       " 'ElectraForCausalLM',\n",
       " 'ElectraForMaskedLM',\n",
       " 'ElectraForMultipleChoice',\n",
       " 'ElectraForPreTraining',\n",
       " 'ElectraForQuestionAnswering',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'ElectraForTokenClassification',\n",
       " 'ElectraModel',\n",
       " 'ElectraPreTrainedModel',\n",
       " 'ElectraTokenizer',\n",
       " 'ElectraTokenizerFast',\n",
       " 'EncodecConfig',\n",
       " 'EncodecFeatureExtractor',\n",
       " 'EncodecModel',\n",
       " 'EncodecPreTrainedModel',\n",
       " 'EncoderDecoderConfig',\n",
       " 'EncoderDecoderModel',\n",
       " 'EncoderNoRepeatNGramLogitsProcessor',\n",
       " 'EncoderRepetitionPenaltyLogitsProcessor',\n",
       " 'EpsilonLogitsWarper',\n",
       " 'ErnieConfig',\n",
       " 'ErnieForCausalLM',\n",
       " 'ErnieForMaskedLM',\n",
       " 'ErnieForMultipleChoice',\n",
       " 'ErnieForNextSentencePrediction',\n",
       " 'ErnieForPreTraining',\n",
       " 'ErnieForQuestionAnswering',\n",
       " 'ErnieForSequenceClassification',\n",
       " 'ErnieForTokenClassification',\n",
       " 'ErnieMConfig',\n",
       " 'ErnieMForInformationExtraction',\n",
       " 'ErnieMForMultipleChoice',\n",
       " 'ErnieMForQuestionAnswering',\n",
       " 'ErnieMForSequenceClassification',\n",
       " 'ErnieMForTokenClassification',\n",
       " 'ErnieMModel',\n",
       " 'ErnieMPreTrainedModel',\n",
       " 'ErnieMTokenizer',\n",
       " 'ErnieModel',\n",
       " 'ErniePreTrainedModel',\n",
       " 'EsmConfig',\n",
       " 'EsmFoldPreTrainedModel',\n",
       " 'EsmForMaskedLM',\n",
       " 'EsmForProteinFolding',\n",
       " 'EsmForSequenceClassification',\n",
       " 'EsmForTokenClassification',\n",
       " 'EsmModel',\n",
       " 'EsmPreTrainedModel',\n",
       " 'EsmTokenizer',\n",
       " 'EtaLogitsWarper',\n",
       " 'EvalPrediction',\n",
       " 'ExponentialDecayLengthPenalty',\n",
       " 'FALCON_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FALCON_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FEATURE_EXTRACTOR_MAPPING',\n",
       " 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FLAVA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MASKED_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING',\n",
       " 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_PRETRAINING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_MAPPING',\n",
       " 'FLAX_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FNetConfig',\n",
       " 'FNetForMaskedLM',\n",
       " 'FNetForMultipleChoice',\n",
       " 'FNetForNextSentencePrediction',\n",
       " 'FNetForPreTraining',\n",
       " 'FNetForQuestionAnswering',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FNetForTokenClassification',\n",
       " 'FNetLayer',\n",
       " 'FNetModel',\n",
       " 'FNetPreTrainedModel',\n",
       " 'FNetTokenizer',\n",
       " 'FNetTokenizerFast',\n",
       " 'FOCALNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FOCALNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FSMTConfig',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'FSMTModel',\n",
       " 'FSMTTokenizer',\n",
       " 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FUNNEL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FalconConfig',\n",
       " 'FalconForCausalLM',\n",
       " 'FalconForQuestionAnswering',\n",
       " 'FalconForSequenceClassification',\n",
       " 'FalconForTokenClassification',\n",
       " 'FalconModel',\n",
       " 'FalconPreTrainedModel',\n",
       " 'FeatureExtractionMixin',\n",
       " 'FeatureExtractionPipeline',\n",
       " 'FillMaskPipeline',\n",
       " 'FlaubertConfig',\n",
       " 'FlaubertForMultipleChoice',\n",
       " 'FlaubertForQuestionAnswering',\n",
       " 'FlaubertForQuestionAnsweringSimple',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FlaubertForTokenClassification',\n",
       " 'FlaubertModel',\n",
       " 'FlaubertPreTrainedModel',\n",
       " 'FlaubertTokenizer',\n",
       " 'FlaubertWithLMHeadModel',\n",
       " 'FlavaConfig',\n",
       " 'FlavaFeatureExtractor',\n",
       " 'FlavaForPreTraining',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageConfig',\n",
       " 'FlavaImageModel',\n",
       " 'FlavaImageProcessor',\n",
       " 'FlavaModel',\n",
       " 'FlavaMultimodalConfig',\n",
       " 'FlavaMultimodalModel',\n",
       " 'FlavaPreTrainedModel',\n",
       " 'FlavaProcessor',\n",
       " 'FlavaTextConfig',\n",
       " 'FlavaTextModel',\n",
       " 'FlaxAlbertForMaskedLM',\n",
       " 'FlaxAlbertForMultipleChoice',\n",
       " 'FlaxAlbertForPreTraining',\n",
       " 'FlaxAlbertForQuestionAnswering',\n",
       " 'FlaxAlbertForSequenceClassification',\n",
       " 'FlaxAlbertForTokenClassification',\n",
       " 'FlaxAlbertModel',\n",
       " 'FlaxAlbertPreTrainedModel',\n",
       " 'FlaxAutoModel',\n",
       " 'FlaxAutoModelForCausalLM',\n",
       " 'FlaxAutoModelForImageClassification',\n",
       " 'FlaxAutoModelForMaskedLM',\n",
       " 'FlaxAutoModelForMultipleChoice',\n",
       " 'FlaxAutoModelForNextSentencePrediction',\n",
       " 'FlaxAutoModelForPreTraining',\n",
       " 'FlaxAutoModelForQuestionAnswering',\n",
       " 'FlaxAutoModelForSeq2SeqLM',\n",
       " 'FlaxAutoModelForSequenceClassification',\n",
       " 'FlaxAutoModelForSpeechSeq2Seq',\n",
       " 'FlaxAutoModelForTokenClassification',\n",
       " 'FlaxAutoModelForVision2Seq',\n",
       " 'FlaxBartDecoderPreTrainedModel',\n",
       " 'FlaxBartForCausalLM',\n",
       " 'FlaxBartForConditionalGeneration',\n",
       " 'FlaxBartForQuestionAnswering',\n",
       " 'FlaxBartForSequenceClassification',\n",
       " 'FlaxBartModel',\n",
       " 'FlaxBartPreTrainedModel',\n",
       " 'FlaxBeitForImageClassification',\n",
       " 'FlaxBeitForMaskedImageModeling',\n",
       " 'FlaxBeitModel',\n",
       " 'FlaxBeitPreTrainedModel',\n",
       " 'FlaxBertForCausalLM',\n",
       " 'FlaxBertForMaskedLM',\n",
       " 'FlaxBertForMultipleChoice',\n",
       " 'FlaxBertForNextSentencePrediction',\n",
       " 'FlaxBertForPreTraining',\n",
       " 'FlaxBertForQuestionAnswering',\n",
       " 'FlaxBertForSequenceClassification',\n",
       " 'FlaxBertForTokenClassification',\n",
       " 'FlaxBertModel',\n",
       " 'FlaxBertPreTrainedModel',\n",
       " 'FlaxBigBirdForCausalLM',\n",
       " 'FlaxBigBirdForMaskedLM',\n",
       " 'FlaxBigBirdForMultipleChoice',\n",
       " 'FlaxBigBirdForPreTraining',\n",
       " 'FlaxBigBirdForQuestionAnswering',\n",
       " 'FlaxBigBirdForSequenceClassification',\n",
       " 'FlaxBigBirdForTokenClassification',\n",
       " 'FlaxBigBirdModel',\n",
       " 'FlaxBigBirdPreTrainedModel',\n",
       " 'FlaxBlenderbotForConditionalGeneration',\n",
       " 'FlaxBlenderbotModel',\n",
       " 'FlaxBlenderbotPreTrainedModel',\n",
       " 'FlaxBlenderbotSmallForConditionalGeneration',\n",
       " 'FlaxBlenderbotSmallModel',\n",
       " 'FlaxBlenderbotSmallPreTrainedModel',\n",
       " 'FlaxBloomForCausalLM',\n",
       " 'FlaxBloomModel',\n",
       " 'FlaxBloomPreTrainedModel',\n",
       " 'FlaxCLIPModel',\n",
       " 'FlaxCLIPPreTrainedModel',\n",
       " 'FlaxCLIPTextModel',\n",
       " 'FlaxCLIPTextModelWithProjection',\n",
       " 'FlaxCLIPTextPreTrainedModel',\n",
       " 'FlaxCLIPVisionModel',\n",
       " 'FlaxCLIPVisionPreTrainedModel',\n",
       " 'FlaxDistilBertForMaskedLM',\n",
       " 'FlaxDistilBertForMultipleChoice',\n",
       " 'FlaxDistilBertForQuestionAnswering',\n",
       " 'FlaxDistilBertForSequenceClassification',\n",
       " 'FlaxDistilBertForTokenClassification',\n",
       " 'FlaxDistilBertModel',\n",
       " 'FlaxDistilBertPreTrainedModel',\n",
       " 'FlaxElectraForCausalLM',\n",
       " 'FlaxElectraForMaskedLM',\n",
       " 'FlaxElectraForMultipleChoice',\n",
       " 'FlaxElectraForPreTraining',\n",
       " 'FlaxElectraForQuestionAnswering',\n",
       " 'FlaxElectraForSequenceClassification',\n",
       " 'FlaxElectraForTokenClassification',\n",
       " 'FlaxElectraModel',\n",
       " 'FlaxElectraPreTrainedModel',\n",
       " 'FlaxEncoderDecoderModel',\n",
       " 'FlaxForceTokensLogitsProcessor',\n",
       " 'FlaxForcedBOSTokenLogitsProcessor',\n",
       " 'FlaxForcedEOSTokenLogitsProcessor',\n",
       " 'FlaxGPT2LMHeadModel',\n",
       " 'FlaxGPT2Model',\n",
       " 'FlaxGPT2PreTrainedModel',\n",
       " 'FlaxGPTJForCausalLM',\n",
       " 'FlaxGPTJModel',\n",
       " 'FlaxGPTJPreTrainedModel',\n",
       " 'FlaxGPTNeoForCausalLM',\n",
       " 'FlaxGPTNeoModel',\n",
       " 'FlaxGPTNeoPreTrainedModel',\n",
       " 'FlaxGenerationMixin',\n",
       " 'FlaxLogitsProcessor',\n",
       " 'FlaxLogitsProcessorList',\n",
       " 'FlaxLogitsWarper',\n",
       " 'FlaxLongT5ForConditionalGeneration',\n",
       " 'FlaxLongT5Model',\n",
       " 'FlaxLongT5PreTrainedModel',\n",
       " 'FlaxMBartForConditionalGeneration',\n",
       " 'FlaxMBartForQuestionAnswering',\n",
       " 'FlaxMBartForSequenceClassification',\n",
       " 'FlaxMBartModel',\n",
       " 'FlaxMBartPreTrainedModel',\n",
       " 'FlaxMT5EncoderModel',\n",
       " 'FlaxMT5ForConditionalGeneration',\n",
       " 'FlaxMT5Model',\n",
       " 'FlaxMarianMTModel',\n",
       " 'FlaxMarianModel',\n",
       " 'FlaxMarianPreTrainedModel',\n",
       " 'FlaxMinLengthLogitsProcessor',\n",
       " 'FlaxOPTForCausalLM',\n",
       " 'FlaxOPTModel',\n",
       " 'FlaxOPTPreTrainedModel',\n",
       " 'FlaxPegasusForConditionalGeneration',\n",
       " 'FlaxPegasusModel',\n",
       " 'FlaxPegasusPreTrainedModel',\n",
       " 'FlaxPreTrainedModel',\n",
       " 'FlaxRegNetForImageClassification',\n",
       " 'FlaxRegNetModel',\n",
       " 'FlaxRegNetPreTrainedModel',\n",
       " 'FlaxResNetForImageClassification',\n",
       " 'FlaxResNetModel',\n",
       " 'FlaxResNetPreTrainedModel',\n",
       " 'FlaxRoFormerForMaskedLM',\n",
       " 'FlaxRoFormerForMultipleChoice',\n",
       " 'FlaxRoFormerForQuestionAnswering',\n",
       " 'FlaxRoFormerForSequenceClassification',\n",
       " 'FlaxRoFormerForTokenClassification',\n",
       " 'FlaxRoFormerModel',\n",
       " 'FlaxRoFormerPreTrainedModel',\n",
       " 'FlaxRobertaForCausalLM',\n",
       " 'FlaxRobertaForMaskedLM',\n",
       " 'FlaxRobertaForMultipleChoice',\n",
       " 'FlaxRobertaForQuestionAnswering',\n",
       " 'FlaxRobertaForSequenceClassification',\n",
       " 'FlaxRobertaForTokenClassification',\n",
       " 'FlaxRobertaModel',\n",
       " 'FlaxRobertaPreLayerNormForCausalLM',\n",
       " 'FlaxRobertaPreLayerNormForMaskedLM',\n",
       " 'FlaxRobertaPreLayerNormForMultipleChoice',\n",
       " 'FlaxRobertaPreLayerNormForQuestionAnswering',\n",
       " 'FlaxRobertaPreLayerNormForSequenceClassification',\n",
       " 'FlaxRobertaPreLayerNormForTokenClassification',\n",
       " 'FlaxRobertaPreLayerNormModel',\n",
       " 'FlaxRobertaPreLayerNormPreTrainedModel',\n",
       " 'FlaxRobertaPreTrainedModel',\n",
       " 'FlaxSpeechEncoderDecoderModel',\n",
       " 'FlaxSuppressTokensAtBeginLogitsProcessor',\n",
       " 'FlaxSuppressTokensLogitsProcessor',\n",
       " 'FlaxT5EncoderModel',\n",
       " 'FlaxT5ForConditionalGeneration',\n",
       " 'FlaxT5Model',\n",
       " 'FlaxT5PreTrainedModel',\n",
       " 'FlaxTemperatureLogitsWarper',\n",
       " 'FlaxTopKLogitsWarper',\n",
       " 'FlaxTopPLogitsWarper',\n",
       " 'FlaxViTForImageClassification',\n",
       " 'FlaxViTModel',\n",
       " 'FlaxViTPreTrainedModel',\n",
       " 'FlaxVisionEncoderDecoderModel',\n",
       " 'FlaxVisionTextDualEncoderModel',\n",
       " 'FlaxWav2Vec2ForCTC',\n",
       " 'FlaxWav2Vec2ForPreTraining',\n",
       " 'FlaxWav2Vec2Model',\n",
       " 'FlaxWav2Vec2PreTrainedModel',\n",
       " 'FlaxWhisperForAudioClassification',\n",
       " 'FlaxWhisperForConditionalGeneration',\n",
       " 'FlaxWhisperModel',\n",
       " 'FlaxWhisperPreTrainedModel',\n",
       " 'FlaxWhisperTimeStampLogitsProcessor',\n",
       " 'FlaxXGLMForCausalLM',\n",
       " 'FlaxXGLMModel',\n",
       " 'FlaxXGLMPreTrainedModel',\n",
       " 'FlaxXLMRobertaForCausalLM',\n",
       " 'FlaxXLMRobertaForMaskedLM',\n",
       " 'FlaxXLMRobertaForMultipleChoice',\n",
       " 'FlaxXLMRobertaForQuestionAnswering',\n",
       " 'FlaxXLMRobertaForSequenceClassification',\n",
       " 'FlaxXLMRobertaForTokenClassification',\n",
       " 'FlaxXLMRobertaModel',\n",
       " 'FlaxXLMRobertaPreTrainedModel',\n",
       " 'FocalNetBackbone',\n",
       " 'FocalNetConfig',\n",
       " 'FocalNetForImageClassification',\n",
       " 'FocalNetForMaskedImageModeling',\n",
       " 'FocalNetModel',\n",
       " 'FocalNetPreTrainedModel',\n",
       " 'ForceTokensLogitsProcessor',\n",
       " 'ForcedBOSTokenLogitsProcessor',\n",
       " 'ForcedEOSTokenLogitsProcessor',\n",
       " 'FunnelBaseModel',\n",
       " 'FunnelConfig',\n",
       " 'FunnelForMaskedLM',\n",
       " 'FunnelForMultipleChoice',\n",
       " 'FunnelForPreTraining',\n",
       " 'FunnelForQuestionAnswering',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'FunnelForTokenClassification',\n",
       " 'FunnelModel',\n",
       " 'FunnelPreTrainedModel',\n",
       " 'FunnelTokenizer',\n",
       " 'FunnelTokenizerFast',\n",
       " 'GIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GLPNConfig',\n",
       " 'GLPNFeatureExtractor',\n",
       " 'GLPNForDepthEstimation',\n",
       " 'GLPNImageProcessor',\n",
       " 'GLPNModel',\n",
       " 'GLPNPreTrainedModel',\n",
       " 'GLPN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GLPN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT2Config',\n",
       " 'GPT2DoubleHeadsModel',\n",
       " 'GPT2ForQuestionAnswering',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPT2ForTokenClassification',\n",
       " 'GPT2LMHeadModel',\n",
       " 'GPT2Model',\n",
       " 'GPT2PreTrainedModel',\n",
       " 'GPT2Tokenizer',\n",
       " 'GPT2TokenizerFast',\n",
       " 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTBigCodeConfig',\n",
       " 'GPTBigCodeForCausalLM',\n",
       " 'GPTBigCodeForSequenceClassification',\n",
       " 'GPTBigCodeForTokenClassification',\n",
       " 'GPTBigCodeModel',\n",
       " 'GPTBigCodePreTrainedModel',\n",
       " 'GPTJConfig',\n",
       " 'GPTJForCausalLM',\n",
       " 'GPTJForQuestionAnswering',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTJModel',\n",
       " 'GPTJPreTrainedModel',\n",
       " 'GPTJ_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPTJ_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTNeoConfig',\n",
       " 'GPTNeoForCausalLM',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "dir(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f12d6fc-e76b-42f8-98b1-05ff9f03be9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "This is a generic model class that will be instantiated as one of the base model classes of the library when created\n",
       "with the [`~AutoModel.from_pretrained`] class method or the [`~AutoModel.from_config`] class\n",
       "method.\n",
       "\n",
       "This class cannot be instantiated directly using `__init__()` (throws an error).\n",
       "\u001b[1;31mFile:\u001b[0m           f:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformers.AutoModel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798956e3-58d6-4fd8-aca4-d412f20a9f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m     food \u001b[38;5;241m=\u001b[39m Food()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[43msnake\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# 绘制屏幕\u001b[39;00m\n\u001b[0;32m     83\u001b[0m screen\u001b[38;5;241m.\u001b[39mfill(BLACK)\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "\n",
    "# 初始化pygame\n",
    "pygame.init()\n",
    "\n",
    "# 设置屏幕大小\n",
    "SCREEN_WIDTH = 640\n",
    "SCREEN_HEIGHT = 480\n",
    "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "\n",
    "# 设置标题\n",
    "pygame.display.set_caption(\"贪吃蛇\")\n",
    "\n",
    "# 定义颜色\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "\n",
    "# 定义游戏对象\n",
    "class Snake:\n",
    "    def __init__(self):\n",
    "        self.x = SCREEN_WIDTH // 2\n",
    "        self.y = SCREEN_HEIGHT // 2\n",
    "        self.direction = \"right\"\n",
    "        self.body = [(self.x, self.y)]\n",
    "\n",
    "    def move(self):\n",
    "        if self.direction == \"right\":\n",
    "            self.x += 10\n",
    "        elif self.direction == \"left\":\n",
    "            self.x -= 10\n",
    "        elif self.direction == \"up\":\n",
    "            self.y -= 10\n",
    "        elif self.direction == \"down\":\n",
    "            self.y += 10\n",
    "\n",
    "        self.body.insert(0, (self.x, self.y))\n",
    "\n",
    "    def eat(self, food):\n",
    "        if self.body[0] == food:\n",
    "            return True\n",
    "        else:\n",
    "            self.body.pop()\n",
    "            return False\n",
    "\n",
    "class Food:\n",
    "    def __init__(self):\n",
    "        self.x = random.randint(0, SCREEN_WIDTH - 10)\n",
    "        self.y = random.randint(0, SCREEN_HEIGHT - 10)\n",
    "\n",
    "# 创建游戏对象\n",
    "snake = Snake()\n",
    "food = Food()\n",
    "\n",
    "# 游戏主循环\n",
    "while True:\n",
    "    # 处理事件\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "        elif event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_UP and snake.direction != \"down\":\n",
    "                snake.direction = \"up\"\n",
    "            elif event.key == pygame.K_DOWN and snake.direction != \"up\":\n",
    "                snake.direction = \"down\"\n",
    "            elif event.key == pygame.K_LEFT and snake.direction != \"right\":\n",
    "                snake.direction = \"left\"\n",
    "            elif event.key == pygame.K_RIGHT and snake.direction != \"left\":\n",
    "                snake.direction = \"right\"\n",
    "\n",
    "    # 移动蛇\n",
    "    snake.move()\n",
    "\n",
    "    # 检查是否吃到食物\n",
    "    if snake.eat((food.x, food.y)):\n",
    "        food = Food()\n",
    "    else:\n",
    "        snake.body.pop()\n",
    "\n",
    "    # 绘制屏幕\n",
    "    screen.fill(BLACK)\n",
    "    for x, y in snake.body:\n",
    "        pygame.draw.rect(screen, WHITE, (x, y, 10, 10))\n",
    "    pygame.draw.rect(screen, RED, (food.x, food.y, 10, 10))\n",
    "\n",
    "    # 更新屏幕\n",
    "    pygame.display.flip()\n",
    "    pygame.time.Clock().tick(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
