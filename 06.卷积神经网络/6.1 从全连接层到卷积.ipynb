{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 6.1 从全连接层到卷积\n",
    "- **目录**\n",
    "  - 6.1.1 不变性\n",
    "  - 6.1.2 多层感知机的限制\n",
    "    - 6.1.2.1 平移不变性\n",
    "    - 6.1.2.2 局部性\n",
    "  - 6.1.3 卷积\n",
    "  - 6.1.4 “沃尔多在哪里”回顾\n",
    "    - 6.1.4.1 通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "我们之前讨论的多层感知机十分适合处理表格数据，其中行对应样本，列对应特征。\n",
    "对于表格数据，我们寻找的模式可能涉及特征之间的交互，但是我们**不能预先假设任何与特征交互相关的先验结构**。\n",
    "此时，多层感知机可能是最好的选择，然而对于高维感知数据，这种**缺少结构的网络**可能会变得不实用。\n",
    "\n",
    "例如，在之前猫狗分类的例子中：假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。\n",
    "即使将隐藏层维度降低到1000，这个全连接层也将有$10^6 \\times 10^3 = 10^9$个参数。\n",
    "想要训练这个模型将不可实现，因为需要有大量的GPU、分布式优化训练的经验和超乎常人的耐心。\n",
    "\n",
    "有些读者可能会反对这个观点，认为要求百万像素的分辨率可能不是必要的。\n",
    "然而，即使分辨率减小为十万像素，使用1000个隐藏单元的隐藏层也可能不足以学习到**良好的图像特征**，在真实的系统中我们仍然需要数十亿个参数。\n",
    "此外，拟合如此多的参数还需要收集大量的数据。\n",
    "然而，如今人类和机器都能很好地区分猫和狗：这是因为图像中本就拥有丰富的结构，而这些结构可以被人类和机器学习模型使用。\n",
    "**卷积神经网络（convolutional neural networks，CNN）** 是机器学习利用自然图像中一些已知结构的创造性方法。\n",
    "\n",
    "- **要点：**\n",
    "  - 多层感知机适合处理表格数据，但对于高维感知数据（如图像），缺乏结构的网络可能不够实用。\n",
    "  - 高分辨率图像输入导致全连接层参数数量巨大，训练这些模型需要大量的计算资源、专业知识和耐心。\n",
    "  - 即使降低分辨率，全连接网络可能仍然无法学习到良好的图像特征，而且需要数十亿个参数。\n",
    "  - 图像中本身包含丰富的结构信息，可以被人类或机器学习模型利用。\n",
    "  - 卷积神经网络（CNN）是一种创造性的方法，可以充分利用自然图像中的已知结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 6.1.1 不变性\n",
    "\n",
    "想象一下，假设你想从一张图片中找到某个物体。\n",
    "**合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。**\n",
    "理想情况下，我们的系统应该能够利用常识：猪通常不在天上飞，飞机通常不在水里游泳。\n",
    "但是，如果一只猪出现在图片顶部，我们还是应该认出它。\n",
    "我们可以从儿童游戏”沃尔多在哪里”（图6.1.1）中得到灵感：\n",
    "在这个游戏中包含了许多充斥着活动的混乱场景，而沃尔多通常潜伏在一些不太可能的位置，读者的目标就是找出他。\n",
    "尽管沃尔多的装扮很有特点，但是在眼花缭乱的场景中找到他也如大海捞针。\n",
    "然而沃尔多的样子并不取决于他潜藏的地方，因此我们可以使用一个“沃尔多检测器”扫描图像。\n",
    "该检测器将图像分割成多个区域，并为每个区域包含沃尔多的可能性打分。\n",
    "卷积神经网络正是将**空间不变性（spatial invariance）** 的这一概念系统化，从而基于这个模型使用较少的参数来学习有用的表示。\n",
    "\n",
    "![沃尔多游戏示例图。](../img/where-wally-walker-books.jpg)\n",
    "\n",
    "<center>图6.1.1 沃尔多游戏示例图</center>\n",
    "\n",
    "现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络架构：\n",
    "\n",
    "1. **平移不变性（translation invariance）**：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。\n",
    "1. **局部性（locality）**：神经网络的前面几层应该只探索输入图像中的局部区域(比如卷积神经网络会**优先考虑图像中相邻像素之间的关联性**)，而**不过度在意图像中相隔较远区域的关系**，这就是“局部性”原则。最终，可以**聚合这些局部特征**（比如**纹理**、**边缘**、**形状**等），以在整个图像级别进行预测。\n",
    "\n",
    "让我们看看这些原则是如何转化为数学表示的。\n",
    "\n",
    "- **要点：**\n",
    "  - 空间不变性：卷积神经网络利用空间不变性原则，使用较少的参数学习有用表示。\n",
    "  - 平移不变性：神经网络应对图像中相同区域具有相似反应，无论检测对象出现在何处，而CNN具备此能力。\n",
    "  - 局部性：神经网络应关注输入图像的局部区域，而非过度考虑相隔较远的区域关系。\n",
    "  - 通过聚合局部特征，在整个图像级别进行预测。\n",
    "  - 上述原则有助于设计适用于计算机视觉任务的神经网络架构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "- **说明：**\n",
    "- **（1）何为空间不变性和平移不变性？**\n",
    "  - 空间不变性（Spatial Invariance）和平移不变性（Translation Invariance）在深度学习尤其是在计算机视觉中是非常重要的概念。它们**描述了一种能力**，即无论目标物体在图像中的位置如何变化，模型都能够识别出该物体。\n",
    "  - 空间不变性（Spatial Invariance）：\n",
    "    - 定义：空间不变性是指模型对输入数据中物体的**位置变化具有不变性或鲁棒性**。\n",
    "    - 直观理解：无论物体在输入图像中的位置如何，模型都应该能够识别出它，就像在“沃尔多在哪里”游戏中，沃尔多的外观不会因为他所在的位置不同而改变。\n",
    "    - 深度学习启示：**模型应该能够从图像中提取特征，并对这些特征的位置变化保持不敏感。**\n",
    "  - 平移不变性（Translation Invariance）\n",
    "    - 定义：平移不变性是空间不变性的一种形式，特指模型对目标物体在图像中的平移（左右、上下移动）保持不变性。\n",
    "    - 直观理解：如果将图像中的猪向上移动，即使它现在出现在图像的顶部，仍然能够识别它是猪。\n",
    "    - 深度学习启示：模型应该有机制来**检测图像的相同部分**，即使这部分在图像中移动到了不同的位置。\n",
    "  - 对深度学习的启示和作用\n",
    "    - 模型设计：上述两种不变性指导设计出能够识别并处理图像中目标物体位置变化的模型，比如卷积神经网络（CNN）。\n",
    "    - 权重共享： CNN通过**共享权重机制**（相同的卷积核在整个图像上移动）来实现平移不变性，这样可以大大减少模型参数的数量。\n",
    "    - 局部感受野：CNN的卷积层具有局部连接的特点，每个神经元只与输入图像的一个小的局部区域相连接，这体现了局部性原则。\n",
    "    - 分层特征提取：CNN通过多个卷积层和池化层逐层提取图像特征，从简单的边缘和纹理特征到复杂的形状和对象表示，这样的分层结构能够有效地聚合局部特征并逐步建立起全局的图像理解。\n",
    "    - 计算效率：由于权重共享和局部连接，CNN在处理图像数据时比全连接网络更加高效，这使得它们在处理大规模图像数据集时更加实用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **（2）平移不变性和局部性**\n",
    "  - 在计算机视觉任务中，理解图像中的对象和场景通常依赖于图像的空间结构。为了设计有效的神经网络架构，尤其是针对图像数据的卷积神经网络（CNN），我们需要考虑两个重要的概念：**平移不变性**和**局部性**。这两个概念帮助我们构建能够高效处理图像数据的模型，减少参数数量，并提高训练和推理的效率。\n",
    "  - **平移不变性（Translation Invariance）**\n",
    "    - **定义**：平移不变性是指，如果图像中的某个物体在空间上发生了平移（即位置变化），那么神经网络应该仍然能够识别出这个物体。换句话说，无论物体出现在图像的哪个位置，神经网络的输出结果都应该是相似的。\n",
    "    - **例子**：想象你有一张图片，里面有一只猫。如果猫的位置从图片的左上角移动到右下角，理想情况下，神经网络应该依然能够正确识别出这是一只猫。换句话说，猫的位置不应该影响网络的识别能力。\n",
    "    - **为什么重要**：在自然图像中，物体可以出现在图像的任何位置。如果我们的神经网络不能处理这种位置变化，那么我们就需要为每种可能的位置训练一个不同的网络，显然这是不现实的。所以，我们希望构建的模型能够自动处理物体的平移，从而对物体的位置不敏感。\n",
    "    - **如何实现**：卷积神经网络通过使用**卷积操作**实现了平移不变性。卷积操作通过使用相同的卷积核在整个图像上滑动（应用），从而使得相同的特征可以在不同的位置被检测到。这种机制在很大程度上增强了网络的平移不变性。\n",
    "  - **局部性（Locality）**\n",
    "    - **定义**：局部性是指神经网络的前几层只关注输入图像中的局部区域，而不考虑整个图像的全局信息。局部性假设图像中相邻像素之间的关系比远离的像素之间的关系更加紧密。\n",
    "    - **例子**：在图像中，识别一个物体的边缘、纹理或形状通常只需要关注图像中的一小块区域。例如，要检测出一张人脸的眼睛，网络只需要检查局部区域的像素，而不需要考虑远处的背景信息。\n",
    "    - **为什么重要**：图像中的信息通常是局部相关的，即相邻像素之间的关系比远处像素之间的关系更为重要。通过只关注局部区域，我们可以减少模型的复杂度，降低计算量，并提高学习效率。同时，局部特征可以逐步组合成更高级别的特征，如边缘、纹理、再到特定的形状和物体。\n",
    "    - **如何实现**：在卷积神经网络中，局部性是通过**卷积核**实现的。卷积核的大小决定了网络在每次卷积操作中关注的像素区域。例如，3x3 的卷积核每次只作用于3x3的局部区域，提取该区域的特征。通过多层卷积，局部特征可以逐渐被组合成更大的特征，从而捕捉到图像的全局信息。\n",
    "  - 结合平移不变性和局部性。卷积神经网络通过结合平移不变性和局部性，能够高效地处理图像数据：\n",
    "    - **平移不变性**保证了网络对物体位置的鲁棒性，使得网络可以在不同位置上检测同样的特征。\n",
    "    - **局部性**允许网络专注于图像中的局部信息，减少了需要学习的参数数量，并提高了训练效率。\n",
    "    - 通过多层卷积操作，网络逐步从局部特征构建出全局特征，从而能够进行复杂的图像分类、检测等任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **（3）如何理解“不能预先假设任何与特征交互相关的先验结构”？**\n",
    "  - 在使用多层感知机（MLP）处理数据时，没有对数据中的特征之间的关系做任何特别的假设或结构化的假定。换句话说，MLP 是一种“通用”模型，它可以处理任何形式的输入数据，而不需要事先知道数据中可能存在的任何特定模式或结构。\n",
    "  - 具体来说：\n",
    "    - **无结构假设**：在 MLP 中，每个输入特征（例如图像中的每个像素）都是相互独立地连接到下一层的神经元。也就是说，MLP 没有利用输入特征之间的潜在联系或空间结构。每个输入特征都被视为独立的，网络没有做任何假设，认为某些特征可能有更紧密的联系，或位于输入的特定位置上。\n",
    "    - **与特征交互相关的先验结构**：当处理图像数据时，**像素之间存在空间关系**。例如，相邻的像素很可能有相似的颜色或亮度，图像中的局部区域可能包含有意义的模式（如边缘、角点等）。这些空间关系是图像的内在结构。如果不利用这些结构，而是像在 MLP 中那样，将每个像素都视为独立的特征，网络就需要通过训练数据自己去学习这些关系，而这通常是低效的。\n",
    "    - **缺乏结构的网络的局限性**：在高维度数据（如图像）中，MLP 的这种“无结构”特性导致参数数量急剧增加。例如，对于一张百万像素的图像，即使隐藏层有 1000 个神经元，网络也会有十亿个参数。这不仅会导致计算资源的极大消耗，还会使得模型容易过拟合，因为它需要大量的训练数据才能学到有效的特征表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 6.1.2 多层感知机的限制\n",
    "首先，多层感知机的输入是二维图像$\\mathbf{X}$，其隐藏表示$\\mathbf{H}$在数学上是一个矩阵，在代码中表示为二维张量。\n",
    "其中$\\mathbf{X}$和$\\mathbf{H}$具有相同的形状。\n",
    "为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。\n",
    "使用$[\\mathbf{X}]_{i, j}$和$[\\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置（$i$,$j$）处的像素。\n",
    "为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵（如同我们先前在多层感知机中所做的那样）替换为**四阶权重张量$\\mathsf{W}$** 。假设$\\mathbf{U}$包含偏置参数，我们可以将全连接层形式化地表示为\n",
    "$$\\begin{aligned} \\left[\\mathbf{H}\\right]_{i, j} &= [\\mathbf{U}]_{i, j} + \\sum_k \\sum_l[\\mathsf{W}]_{i, j, k, l}  [\\mathbf{X}]_{k, l}\\\\ &=  [\\mathbf{U}]_{i, j} +\n",
    "\\sum_a \\sum_b [\\mathsf{V}]_{i, j, a, b}  [\\mathbf{X}]_{i+a, j+b}.\\end{aligned} \\tag{6.1.1}$$\n",
    "其中，从$\\mathsf{W}$到$\\mathsf{V}$的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系。\n",
    "我们只需重新索引下标$(k, l)$，使$k = i+a$、$l = j+b$，由此可得$[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$。\n",
    "索引$a$和$b$通过在正偏移和负偏移之间移动覆盖了整个图像。\n",
    "对于隐藏表示中任意给定位置（$i$,$j$）处的像素值$[\\mathbf{H}]_{i, j}$，可以通过在$x$中**以$(i, j)$为中心**对像素进行加权求和得到，加权使用的权重为$[\\mathsf{V}]_{i, j, a, b}$。\n",
    "- **说明：公式6.1.1**\n",
    "  - 公式（6.1.1）表示了一个全连接层的计算过程，其中输入是一个二维图像$\\mathbf{X}$，隐藏表示是$\\mathbf{H}$。权重张量为$\\mathsf{W}$，偏置参数为$\\mathbf{U}$。\n",
    "  - 输入图像和隐藏表示：图像$\\mathbf{X}$和隐藏表示$\\mathbf{H}$都是二维矩阵，具有相同的形状。它们都可以看作具有空间结构的数据。在这里，$[\\mathbf{X}]_{i, j}$表示输入图像中位置$(i, j)$处的像素值；$[\\mathbf{H}]_{i, j}$表示隐藏表示中位置$(i, j)$处的像素值。\n",
    "  - 权重张量和偏置参数：四阶权重张量$\\mathsf{W}$包含了从输入到隐藏表示的连接权重。$\\mathbf{U}$是偏置参数矩阵，与隐藏表示$\\mathbf{H}$具有相同的形状。\n",
    "  - 全连接层计算：公式（6.1.1）描述了如何计算隐藏表示中位置$(i, j)$处的像素值$[\\mathbf{H}]_{i, j}$。通过遍历输入图像$\\mathbf{X}$中的所有像素，使用权重张量$\\mathsf{W}$对应的元素对输入像素进行加权求和，然后加上偏置参数$[\\mathbf{U}]_{i, j}$，即可得到隐藏表示中位置$(i, j)$处的像素值。\n",
    "  - 从$\\mathsf{W}$到$\\mathsf{V}$的转换：权重张量$\\mathsf{W}$和$\\mathsf{V}$之间存在一一对应关系。我们可以通过重新索引下标$(k, l)$为$(i+a, j+b)$将$\\mathsf{W}$转换为$\\mathsf{V}$，具体来说，有$[\\mathsf{V}]_{i, j, a, b} = [\\mathsf{W}]_{i, j, i+a, j+b}$。四阶张量$\\mathsf{V}$与$\\mathsf{W}$在计算上是等价的，但在结构上更便于理解。\n",
    "  - 以$(i, j)$为中心的加权求和：公式（6.1.1）中的求和部分表示了在输入图像$x$中以$(i, j)$为中心对像素进行加权求和。这里的权重为$[\\mathsf{V}]_{i, j, a, b}$，它对应于以$(i, j)$为中心的一个局部区域内的像素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 四阶权重张量 $\\mathsf{W}$ 的通俗解释：\n",
    "  - **二阶张量（矩阵）**：在传统的多层感知机（MLP）中，权重通常是一个二阶张量（即矩阵），其中每个元素表示输入向量中某个单独特征与输出神经元之间的连接权重。这种表示方式只关注输入向量中的每个单独特征，而没有考虑这些特征之间的位置关系或结构。\n",
    "  - **四阶张量**：当输入是二维图像时，使用四阶张量作为权重矩阵意味着考虑了以下两点：\n",
    "    - 1. **每个像素的特征**：权重的某些维度与输入图像中的像素位置相关联（即，像素的坐标）。\n",
    "    - 2. **像素之间的位置关系**：额外的维度允许我们在捕捉像素特征的同时，也能够捕捉和表示像素之间的相对位置关系。\n",
    "  - 位置关系的捕捉。在一个四阶权重张量 $\\mathsf{W}$ 中：\n",
    "    - 前两个维度通常对应于隐藏层中某个神经元的位置 (i, j)，即这个神经元的位置在隐藏层（或特征图）中的坐标。\n",
    "    - 后两个维度则对应于输入图像中的某个像素的位置 (k, l)，即这个像素在输入图像中的坐标。\n",
    "    - 这种结构允许网络在计算隐藏层中某个神经元的输出时，不仅仅考虑单个像素的特征，还可以考虑这个像素与其他像素之间的空间关系。换句话说，网络能够通过权重张量的结构捕捉输入图像中像素之间的相对位置关系。\n",
    "  - 从全连接到卷积的过渡\n",
    "    - 四阶权重张量可以捕捉图像中的像素与像素之间的相对位置关系，但实际应用中直接使用这种全连接的方式通常会导致过多的参数，计算量非常大。通常采用**卷积神经网络（CNN）** 来简化这个过程。\n",
    "    - 在卷积网络中：\n",
    "      - **卷积核** 通过局部权重共享的方式在图像上滑动，捕捉局部区域的特征。\n",
    "      - **权重共享**减少了参数量，同时保留了对于局部像素之间位置关系的捕捉能力。\n",
    "      - **局部感受野**确保网络关注的是二维图像中像素的局部相对位置，而不是全局的全连接。\n",
    "- 四阶权重的可视化示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成随机的4维张量\n",
    "W = np.random.randn(3, 3, 3, 3)\n",
    "\n",
    "# 可视化每个二维切片\n",
    "fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axs[i, j].imshow(W[i, j], cmap='viridis')\n",
    "        axs[i, j].set_title(f\"W[{i}, {j}, :, :]\")\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 6.1.2.1 平移不变性\n",
    "\n",
    "现在引用上述的第一个原则：平移不变性。\n",
    "这意味着检测对象在输入$\\mathbf{X}$中的平移，应该仅导致隐藏表示$\\mathbf{H}$中的平移。也就是说，$\\mathsf{V}$和$\\mathbf{U}$实际上**不依赖于$(i, j)$的值**，即$[\\mathsf{V}]_{i, j, a, b} = [\\mathbf{V}]_{a, b}$。并且$\\mathbf{U}$是一个常数，比如$u$。因此，我们可以简化$\\mathbf{H}$定义为：\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b} [\\mathbf{X}]_{i+a, j+b} \\tag{6.1.2}$$\n",
    "这就是**卷积（convolution）**。我们是在使用系数$[\\mathbf{V}]_{a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\\mathbf{H}]_{i, j}$。\n",
    "注意，$[\\mathbf{V}]_{a, b}$的系数比$[\\mathsf{V}]_{i, j, a, b}$少很多，因为前者不再依赖于图像中的位置。这就是显著的进步！\n",
    "\n",
    "- **示例：公式6.1.2计算，局部性与平移不变性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入图像 X:\n",
      "[[1 2 3 0]\n",
      " [4 5 6 1]\n",
      " [7 8 9 0]\n",
      " [0 1 0 1]]\n",
      "\n",
      "卷积核 V:\n",
      "[[ 1  0]\n",
      " [ 0 -1]]\n",
      "\n",
      "偏置参数 u: 1\n",
      "\n",
      "隐藏表示 H:\n",
      "[[-3. -3.  3.]\n",
      " [-3. -3.  7.]\n",
      " [ 7.  9.  9.]]\n",
      "\n",
      "平移后的输入图像 X_shifted:\n",
      "[[7 8 9 0]\n",
      " [0 1 0 1]\n",
      " [1 2 3 0]\n",
      " [4 5 6 1]]\n",
      "\n",
      "平移后的隐藏表示 H_shifted:\n",
      "[[ 7.  9.  9.]\n",
      " [-1. -1.  1.]\n",
      " [-3. -3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolution2d(X, V, u):\n",
    "    \"\"\"\n",
    "    计算二维卷积，返回隐藏表示 H。\n",
    "\n",
    "    参数：\n",
    "    X (numpy.ndarray): 输入二维图像矩阵。\n",
    "    V (numpy.ndarray): 卷积核权重矩阵。\n",
    "    u (float): 偏置参数。\n",
    "\n",
    "    返回：\n",
    "    H (numpy.ndarray): 隐藏表示矩阵。\n",
    "    \"\"\"\n",
    "    # 获取输入图像和卷积核的形状\n",
    "    X_height, X_width = X.shape\n",
    "    V_height, V_width = V.shape\n",
    "    \n",
    "    # 计算输出图像的尺寸\n",
    "    H_height = X_height - V_height + 1\n",
    "    H_width = X_width - V_width + 1\n",
    "    \n",
    "    # 初始化输出图像\n",
    "    H = np.zeros((H_height, H_width))\n",
    "    \n",
    "    # 计算卷积操作\n",
    "    for i in range(H_height):\n",
    "        for j in range(H_width):\n",
    "            # 对应公式 (6.1.2)，计算隐藏表示 H 的每个元素\n",
    "            H[i, j] = u + np.sum(X[i:i+V_height, j:j+V_width] * V)\n",
    "            \n",
    "    return H\n",
    "\n",
    "# 示例输入\n",
    "X = np.array([[1, 2, 3, 0],\n",
    "              [4, 5, 6, 1],\n",
    "              [7, 8, 9, 0],\n",
    "              [0, 1, 0, 1]])\n",
    "\n",
    "V = np.array([[1, 0],\n",
    "              [0, -1]])\n",
    "\n",
    "u = 1  # 偏置参数\n",
    "\n",
    "# 计算卷积\n",
    "H = convolution2d(X, V, u)\n",
    "\n",
    "print(\"输入图像 X:\")\n",
    "print(X)\n",
    "print(\"\\n卷积核 V:\")\n",
    "print(V)\n",
    "print(\"\\n偏置参数 u:\", u)\n",
    "print(\"\\n隐藏表示 H:\")\n",
    "print(H)\n",
    "\n",
    "# 现在，我们通过平移输入图像来验证平移不变性\n",
    "X_shifted = np.roll(X, shift=2, axis=0)  # 在垂直方向上平移一行\n",
    "\n",
    "H_shifted = convolution2d(X_shifted, V, u)\n",
    "\n",
    "print(\"\\n平移后的输入图像 X_shifted:\")\n",
    "print(X_shifted)\n",
    "print(\"\\n平移后的隐藏表示 H_shifted:\")\n",
    "print(H_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 6.1.2.2 局部性\n",
    "\n",
    "现在引用上述的第二个原则：局部性。如上所述，为了收集用来训练参数$[\\mathbf{H}]_{i, j}$的相关信息，我们不应偏离到距$(i, j)$很远的地方。这意味着在$|a|> \\Delta$或$|b| > \\Delta$的范围之外，我们可以设置$[\\mathbf{V}]_{a, b} = 0$。因此，我们可以将$[\\mathbf{H}]_{i, j}$重写为\n",
    "\n",
    "$$[\\mathbf{H}]_{i, j} = u + \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}  \\tag{6.1.3}$$\n",
    "\n",
    "\n",
    "简而言之，公式6.1.3 是一个**卷积层（convolutional layer）**，而卷积神经网络是包含卷积层的一类特殊的神经网络。\n",
    "在深度学习研究社区中，$\\mathbf{V}$被称为**卷积核（convolution kernel）**或者**滤波器（filter）**，亦或简单地称之为该卷积层的**权重**，通常该权重是可学习的参数。\n",
    "当图像处理的局部区域很小时，卷积神经网络与多层感知机的训练差异可能是巨大的：以前，**多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数**，而且不需要改变输入或隐藏表示的维数。\n",
    "参数大幅减少的代价是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。\n",
    "以上所有的权重学习都将依赖于归纳偏置。当这种偏置与现实相符时，我们就能得到样本有效的模型，并且这些模型能很好地泛化到未知数据中。\n",
    "但如果这偏置与现实不符时，比如当图像不满足平移不变时，我们的模型可能难以拟合我们的训练数据。\n",
    "\n",
    "- **要点：**\n",
    "  - 公式6.1.3是一个卷积操作，它描述了如何通过将卷积核（或滤波器）$V$与输入数据$X$进行局部相关运算来计算输出的隐藏表示$H$。\n",
    "  - **局部性原则**：根据局部性原则，在计算隐藏表示$H$时，我们只关注距离$(i,j)$较近的区域，这意味着在$|a|>\\Delta$ 或 $|b|>\\Delta$ 的范围之外，我们可以设置$[V]_{a,b}=0$。这样，我们就可以在计算每个隐藏单元时仅考虑附近的输入信息。\n",
    "  - **卷积层**：公式6.1.3定义了一个卷积层，其中$V$是卷积核，$X$是输入数据，$H$是输出数据。卷积层是一种特殊的神经网络层，它利用局部性原则和权重共享来减少参数数量并捕捉图像等数据的平移不变特征。\n",
    "  - **参数数量显著减少**：与传统的多层感知机相比，卷积神经网络在处理图像等具有局部结构的数据时，参数数量可以大幅减少。这有助于降低过拟合风险，提高模型的泛化能力。\n",
    "  - **平移不变性**：卷积神经网络在训练过程中学习到的特征具有平移不变性，即使图像发生平移，这些特征也能被有效地检测出来。<br><br>\n",
    "\n",
    "- **说明：公式6.1.3**\n",
    "  - **初始化**：将输出矩阵$H$的元素$[H]_{i,j}$ 初始化为常数项$u$。\n",
    "  - **遍历卷积核**：对于卷积核$V$的每个元素$[V]_{a,b}$（其中$a$和$b$的范围是$-\\Delta$ 到$\\Delta$），执行以下步骤：\n",
    "     - **选择输入矩阵$X$的局部区域**：根据局部性原则，选取距离$(i,j)$较近的局部区域（索引为$(i+a,j+b)$）。\n",
    "     - **计算加权和**：将卷积核元素$[V]_{a,b}$ 与对应的输入矩阵元素$[X]_{i+a,j+b}$ 相乘，然后将结果累加到输出矩阵$[H]_{i,j}$\n",
    "  - **结果**：经过遍历卷积核后，我们得到了输出矩阵$H$。这个矩阵表示了通过卷积操作捕捉到的局部特征。\n",
    "\n",
    "- **示例：公式6.1.3计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出矩阵H：\n",
      "[[ 7. 13.]\n",
      " [15. 26.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 输入矩阵X (3x3)\n",
    "X = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# 卷积核V (2x2)\n",
    "V = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# 偏置项u\n",
    "u = 1\n",
    "\n",
    "# 初始化输出矩阵H (2x2)\n",
    "H = np.zeros((2, 2))\n",
    "\n",
    "# 根据公式6.1.3计算卷积操作\n",
    "delta = V.shape[0] // 2\n",
    "for i in range(H.shape[0]):\n",
    "    for j in range(H.shape[1]):\n",
    "        H[i, j] = u\n",
    "        for a in range(-delta, delta + 1):\n",
    "            for b in range(-delta, delta + 1):\n",
    "                if 0 <= i + a < X.shape[0] and 0 <= j + b < X.shape[1]:\n",
    "                    # 注意这里访问V矩阵的索引已经修改为a和b。\n",
    "                    H[i, j] += V[a, b] * X[i + a, j + b]\n",
    "\n",
    "print(\"输出矩阵H：\")\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 6.1.3 卷积\n",
    "\n",
    "- 在进一步讨论之前，我们先简要回顾一下为什么上面的操作被称为卷积。在数学中，两个函数（比如$f, g: \\mathbb{R}^d \\to \\mathbb{R}$）之间的“卷积”被定义为\n",
    "\n",
    "$$(f * g)(\\mathbf{x}) = \\int f(\\mathbf{z}) g(\\mathbf{x}-\\mathbf{z}) d\\mathbf{z}. \\tag{6.1.4}$$\n",
    "- 公式6.1.4中：\n",
    "   - $ \\mathbf{x} $ 是当前的输入位置（或者时间点，视具体问题而定）。\n",
    "   - $ \\mathbf{z} $ 是一个积分变量，表示在函数 $ f $ 上的所有可能的位置。\n",
    "   - $ g(\\mathbf{x}-\\mathbf{z}) $ 表示函数 $ g $ 的翻转和平移。\n",
    "也就是说，**卷积是当把一个函数“翻转”并移位$\\mathbf{x}$时，测量$f$和$g$之间的重叠**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 当为离散对象时，积分就变成求和。例如：对于由索引为$\\mathbb{Z}$的、平方可和的、无限维向量集合中抽取的向量，我们得到以下定义：\n",
    "\n",
    "  $$(f * g)(i) = \\sum_a f(a) g(i-a).\\tag{6.1.5}$$\n",
    "- 在公式6.1.5离散卷积的定义中：\n",
    "    - $ i $ 是当前的输入位置的索引。\n",
    "    - $ a $ 是遍历 $ f $ 的所有索引。\n",
    "    - $ g(i-a) $ 表示函数 $ g $ 的翻转和平移。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 对于二维张量，则为$f$的索引$(a, b)$和$g$的索引$(i-a, j-b)$上的对应加和：\n",
    "\n",
    "$$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b).\\tag{6.1.6}$$\n",
    "- 在公式6.1.6二维卷积中：\n",
    "    - $ (i, j) $ 是输入图像的位置索引。\n",
    "    - $ (a, b) $ 是 $ f $ 的索引。\n",
    "    - $ g(i-a, j-b) $ 表示二维卷积核 $ g $ 的翻转和平移。\n",
    "- 这看起来类似于公式6.1.3，但有一个主要区别：这里不是使用$(i+a, j+b)$，而是使用差值。\n",
    "- 然而，这种区别是表面的，因为我们总是可以匹配公式6.1.3 和公式6.1.6之间的符号。\n",
    "- 我们在公式6.1.3中的原始定义更正确地描述了**互相关（cross-correlation）**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 卷积与互相关。在卷积神经网络中，卷积操作通常被实现为互相关（cross-correlation），其定义是：\n",
    "  $$\n",
    "  (f * g)(i, j) = \\sum_a \\sum_b f(i+a, j+b) g(a, b). \\tag{6.1.7}\n",
    "  $$\n",
    "  - 注意到，这里的索引是 $ g(a, b) $ 而不是 $ g(i-a, j-b) $，这意味着**没有对卷积核进行翻转**。\n",
    "  - 因此严格来说，卷积神经网络中的“卷积”操作更准确地描述为互相关操作而非卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "- **说明：**\n",
    "- **（1）示例：公式6.1.6计算**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出矩阵h：\n",
      "[[1. 2.]\n",
      " [4. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 输入矩阵f (3x3)\n",
    "f = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# 输入矩阵g (2x2)\n",
    "g = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# 初始化输出矩阵h (2x2)\n",
    "h = np.zeros((2, 2))\n",
    "\n",
    "# 遍历结果矩阵h的每个元素(i, j)\n",
    "for i in range(h.shape[0]):\n",
    "    for j in range(h.shape[1]):\n",
    "        # 计算每个有效的a和b\n",
    "        for a in range(f.shape[0]):\n",
    "            for b in range(f.shape[1]):\n",
    "                if 0 <= i - a < g.shape[0] and 0 <= j - b < g.shape[1]:\n",
    "                    h[i, j] += f[a, b] * g[i - a, j - b]\n",
    "\n",
    "print(\"输出矩阵h：\")\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **（2）卷积运算的计算过程**\n",
    "  - 计算h(0,0)，遍历f矩阵的所有元素(a, b)，并执行以下操作：\n",
    "    - a. 对于a=0, b=0，计算f(0, 0)*g(0-0, 0-0) = f(0, 0)g(0, 0) = 1\\*1 = 1。\n",
    "    - b. 对于a=0, b=1，计算f(0, 1)*g(0-0, 0-1)。由于g(0, -1)超出了g矩阵的范围，因此跳过该项。\n",
    "    - c. 对于a=1, b=0，计算f(1, 0)*g(0-1, 0-0) = f(1, 0)*g(-1, 0)。由于g(-1, 0)超出了g矩阵的范围，因此跳过该项。 \n",
    "    - d. 其他所有组合的a和b都会导致访问g矩阵时越界，因此忽略它们。\n",
    "    - 将以上有效乘积相加得到：h(0,0) = 1。\n",
    "  - 类似地计算其他元素：\n",
    "    - a. h(0, 1) = f(0, 0)*g(0, -1) + f(0, 1)*g(0, 0) + f(1, 0)*g(-1, -1) + f(1, 1)*g(-1, 0) = 0 + 2\\*1 + 0 + 0 = 2。\n",
    "    - b. h(1, 0) = f(0, 0)*g(-1, 0) + f(0, 1)*g(-1, -1) + f(1, 0)*g(0, 0) + f(1, 1)*g(0, -1) = 0 + 0 + 4\\*1 + 0 = 4。\n",
    "    - c. h(1, 1) = f(0, 0)*g(1, 1) + f(1, 1)*g(0,1 ) + f(0, 1)*g(1, 0)  + f(1, 0)*g(0, 1) + f(1, 1)*g(0, 0) =1\\*1 + 5\\*0 + 2\\*0 + 5\\*0 + 5\\*1 = 6。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **（3）公式6.1.7互相关运算**\n",
    "  - $f$ 是输入数据（在这个例子中是一个3x3的矩阵），它代表了输入信号或图像。\n",
    "  - $g$ 是卷积核或滤波器（在这个例子中是一个2x2的矩阵），它在输入数据上滑动，以执行卷积或互相关操作。\n",
    "  - 代码的逻辑反映了互相关（cross-correlation）的过程，虽然在深度学习中这通常也被称为卷积：\n",
    "    - 卷积核 `g` 在输入 `f` 上滑动。\n",
    "    - 在每个位置，`g` 的元素与 `f` 中相应位置的元素相乘，然后这些乘积相加得到 `h` 的一个元素。\n",
    "  - 虽然理论上卷积要求对 `g` 进行翻转，但实际上如下代码实现的操作（`f[i + a, j + b] * g[a, b]`）是**互相关**，因为卷积核 `g` **没有被翻转**。\n",
    "  - 这在机器学习和图像处理中是很常见的做法，因为卷积核的权重是在训练过程中学习的，翻转的需求**通过学习过程隐式地被考虑**了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输出矩阵h：\n",
      "[[ 6.  8.]\n",
      " [12. 14.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 输入矩阵f (3x3)\n",
    "f = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# 输入矩阵g (2x2)\n",
    "g = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# 初始化输出矩阵h (2x2)\n",
    "h = np.zeros((2, 2))\n",
    "\n",
    "# 遍历结果矩阵h的每个元素(i, j)\n",
    "for i in range(h.shape[0]):\n",
    "    for j in range(h.shape[1]):\n",
    "        # 计算每个有效的a和b\n",
    "        for a in range(g.shape[0]):\n",
    "            for b in range(g.shape[1]):\n",
    "                if 0 <= i + a < f.shape[0] and 0 <= j + b < f.shape[1]:\n",
    "                    h[i, j] += f[i + a, j + b] * g[a, b]\n",
    "\n",
    "print(\"输出矩阵h：\")\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 6.1.4 “沃尔多在哪里”回顾\n",
    "\n",
    "回到上面的“沃尔多在哪里”游戏，让我们看看它到底是什么样子。卷积层根据滤波器$\\mathbf{V}$选取给定大小的窗口，并加权处理图片，如 图6.1.2中所示。我们的目标是学习一个模型，以便探测出在“沃尔多”最可能出现的地方。\n",
    "\n",
    "![发现沃尔多。](../img/waldo-mask.jpg)\n",
    "<center>图6.1.2 发现沃尔多</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 6.1.4.1 通道\n",
    "\n",
    "然而这种方法有一个问题：我们忽略了图像一般包含三个通道/三种原色（红色、绿色和蓝色）。\n",
    "实际上，图像不是二维张量，而是一个**由高度、宽度和颜色组成的三维张量**，比如包含$1024 \\times 1024 \\times 3$个像素。\n",
    "前两个轴与像素的空间位置有关，而第三个轴可以看作是每个像素的多维表示。\n",
    "因此，我们将$\\mathsf{X}$索引为$[\\mathsf{X}]_{i, j, k}$。由此卷积相应地调整为$[\\mathsf{V}]_{a,b,c}$，而不是$[\\mathbf{V}]_{a,b}$。\n",
    "\n",
    "**此外，由于输入图像是三维的，我们的隐藏表示$\\mathsf{H}$也最好采用三维张量。**\n",
    "换句话说，对于每一个空间位置，我们想要采用**一组**而**不是一个隐藏表示**。这样一组隐藏表示可以想象成一些**互相堆叠的二维网格。**\n",
    "因此，我们可以把隐藏表示想象为一系列具有二维张量的**通道**（channel）。\n",
    "这些通道有时也被称为**特征映射**（feature maps），因为每个通道都向后续层提供一组**空间化的学习特征**。\n",
    "直观上你可以想象在靠近输入的底层，一些通道专门识别边缘，而一些通道专门识别纹理。\n",
    "\n",
    "为了支持输入$\\mathsf{X}$和隐藏表示$\\mathsf{H}$中的多个通道，我们可以在$\\mathsf{V}$中添加第四个坐标，即$[\\mathsf{V}]_{a, b, c, d}$。综上所述，\n",
    "\n",
    "$$[\\mathsf{H}]_{i,j,d} = \\sum_{a = -\\Delta}^{\\Delta} \\sum_{b = -\\Delta}^{\\Delta} \\sum_c [\\mathsf{V}]_{a, b, c, d} [\\mathsf{X}]_{i+a, j+b, c},\\tag{6.1.7}$$\n",
    "\n",
    "\n",
    "其中隐藏表示$\\mathsf{H}$中的索引$d$表示输出通道，而随后的输出将继续以三维张量$\\mathsf{H}$作为输入进入下一个卷积层。\n",
    "所以，公式6.1.7可以定义具有多个通道的卷积层，而其中$\\mathsf{V}$是该卷积层的权重。\n",
    "\n",
    "然而，仍有许多问题亟待解决。\n",
    "例如，图像中是否到处都有存在沃尔多的可能？如何有效地计算输出层？如何选择适当的激活函数？为了训练有效的网络，如何做出合理的网络设计选择？我们将在本章的其它部分讨论这些问题。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -9.04839085  -6.76912689 -28.19314552 -27.52369053]\n",
      "  [-10.96430951  -6.33330347 -54.69633147 -52.10264428]]\n",
      "\n",
      " [[ -9.04839085  -6.76912689 -28.19314552 -27.52369053]\n",
      "  [-10.96430951  -6.33330347 -54.69633147 -52.10264428]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv_multi_channel(X, V):\n",
    "    # 获取输入图像、卷积核和输出图像的尺寸\n",
    "    input_height, input_width, input_channels = X.shape\n",
    "    kernel_height, kernel_width, _, output_channels = V.shape\n",
    "    \n",
    "    # 计算输出图像的尺寸\n",
    "    output_height = input_height - kernel_height + 1\n",
    "    output_width = input_width - kernel_width + 1\n",
    "\n",
    "    # 初始化输出特征映射张量 H\n",
    "    H = np.zeros((output_height, output_width, output_channels))\n",
    "\n",
    "    # 遍历输出特征映射的每个空间位置 (i, j) 和输出通道 d\n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            for d in range(output_channels):\n",
    "                # 对于给定的 (i, j, d)，计算卷积操作的结果\n",
    "                for a in range(kernel_height):\n",
    "                    for b in range(kernel_width):\n",
    "                        for c in range(input_channels):\n",
    "                            H[i, j, d] += V[a, b, c, d] * X[i + a, j + b, c]\n",
    "\n",
    "    return H\n",
    "\n",
    "# 示例输入图像\n",
    "X = np.array([\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "])\n",
    "\n",
    "# 示例权重张量\n",
    "V = np.random.randn(2, 2, 3, 4)\n",
    "\n",
    "# 计算卷积操作的结果\n",
    "H = conv_multi_channel(X, V)\n",
    "\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 小结\n",
    "\n",
    "- 图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。\n",
    "- 局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。\n",
    "- 在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。\n",
    "- 卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。\n",
    "- 多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
