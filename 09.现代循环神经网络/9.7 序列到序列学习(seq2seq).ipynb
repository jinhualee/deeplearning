{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "#  9.7 序列到序列学习（seq2seq）\n",
    "- **目录**\n",
    "  - 9.7.1 seq2seq编码器\n",
    "  - 9.7.2 seq2seq解码器\n",
    "  - 9.7.3 seq2seq模型损失函数\n",
    "  - 9.7.4 seq2seq模型训练\n",
    "  - 9.7.5 seq2seq模型预测\n",
    "  - 9.7.6 seq2seq模型预测序列的评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "正如我们在9.5节中看到的，\n",
    "机器翻译中的输入序列和输出序列都是长度可变的。\n",
    "为了解决这类问题，我们在9.6节\n",
    "设计了一个通用的”编码器－解码器“架构。\n",
    "本节，我们将使用两个循环神经网络的编码器和解码器，\n",
    "并将其应用于**序列到序列（sequence to sequence，seq2seq）** 类的学习任务。\n",
    "\n",
    "遵循编码器－解码器架构的设计原则，\n",
    "循环神经网络编码器使用**长度可变的序列**作为输入，\n",
    "将其转换为**固定形状的隐状态**。\n",
    "换言之，**输入序列的信息被*编码*到循环神经网络编码器的隐状态中**。\n",
    "为了连续生成输出序列的词元，\n",
    "独立的循环神经网络解码器是基于输入序列的**编码信息**和输出序列**已经看见**的或者生成的词元来预测下一个词元。\n",
    "图9.7.1演示了如何在机器翻译中使用两个循环神经网络进行序列到序列学习。\n",
    "\n",
    "<center><img src='../img/seq2seq.svg' /></center>\n",
    "<center>图9.7.1 使用循环神经网络编码器和循环神经网络解码器的序列到序列学习</center>\n",
    "\n",
    "在图9.7.1中，\n",
    "特定的“&lt;eos&gt;”表示序列结束词元。\n",
    "一旦输出序列生成此词元，模型就会**停止预测。**\n",
    "在循环神经网络解码器的初始化时间步，有两个特定的设计决定：\n",
    "- 首先，特定的“&lt;bos&gt;”表示序列开始词元，它是解码器的输入序列的第一个词元。\n",
    "- 其次，使用循环神经网络编码器**最终**的隐状态来初始化解码器的隐状态。\n",
    "\n",
    "如图9.7.1所示，**编码器最终的隐状态在每一个时间步都作为解码器的输入序列的一部分**。\n",
    "类似于图9.7.1中语言模型的训练，可以允许**标签成为原始的输出序列**，\n",
    "从源序列词元“&lt;bos&gt;”, “Ils”, “regardent”, “.”到新序列词元“Ils”, “regardent”, “.”, “&lt;eos&gt;”来移动预测的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- **要点：**\n",
    "  - 序列到序列学习（seq2seq）是一种用于处理**长度可变**的输入和输出序列的学习任务。\n",
    "  - 在机器翻译中，使用两个循环神经网络的编码器和解码器实现seq2seq学习。\n",
    "  - 循环神经网络编码器将输入序列转换为**固定形状的隐状态**，将**输入序列的信息编码到隐状态中**。\n",
    "  - 循环神经网络解码器使用编码器的隐状态和输出序列已见或生成的词元来预测下一个词元，连续生成输出序列的词元。\n",
    "  - 特定的“&lt;eos&gt;”表示序列结束词元，在解码器的初始化时间步使用特定的“&lt;bos&gt;”表示序列开始词元，**并使用编码器最终的隐状态来初始化解码器的隐状态**。\n",
    "  - seq2seq学习中，可以允许标签成为原始的输出序列，通过移动预测的位置，实现不同的设计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **说明：如何理解编码器最终的隐状态在每一个时间步都作为解码器的输入序列的一部分？**\n",
    "- Seq2Seq模型中，编码器处理完整个输入序列后，会产生一个最终的隐状态（hidden state）。\n",
    "  - 这个隐状态被认为是输入序列的一个**浓缩表示**，包含了**整个输入序列的信息**。\n",
    "  - 在解码阶段，这个最终隐状态会被传递给解码器，并在解码的每一个时间步都被用作输入的一部分。\n",
    "- **编码器最终的隐状态:**\n",
    "  - **循环神经网络（RNN）的特性:** RNNs 能够处理序列数据，通过在每个时间步传递隐状态来捕捉序列中的信息。\n",
    "  - **编码器的作用:** 编码器RNN的任务是读取输入序列（例如，一个句子），并将其转换为一个固定长度的向量，即最终的隐状态。这个向量试图捕捉输入序列的**全部信息**。\n",
    "  - 最终隐状态的意义: 这个最终隐状态可以被看作是输入序列的<b>“意义”或“表示”</b> 。它包含了模型从输入序列中提取的所有重要信息。\n",
    "  - **在每一个时间步都作为解码器的输入序列的一部分:**\n",
    "    * **解码器的作用:** 解码器RNN的任务是基于编码器提供的最终隐状态，逐步生成输出序列（例如，翻译后的句子）。\n",
    "    * **时间步:** 解码器在**每个时间步**生成输出序列的一个元素（例如，一个单词）。\n",
    "    * **作为输入的一部分:** 在每个时间步，解码器不仅接收前一个时间步生成的输出作为输入，还会接收编码器最终的隐状态。这意味着，解码器在生成每个单词时，都可以“看到”**整个输入序列的信息**。\n",
    "\n",
    "- **主要功能**\n",
    "  * **传递信息:** 编码器的最终隐状态是连接编码器和解码器的**桥梁**。它将输入序列的信息传递给解码器，使得解码器能够生成与输入序列相关的输出。\n",
    "  * **提供上下文:** 通过在每个时间步都提供编码器的最终隐状态，解码器可以持续地获得输入序列的上下文信息，这对于生成准确的输出序列至关重要。\n",
    "- **具体实现方式:**\n",
    "  - 在实际实现中，编码器的最终隐状态通常会通过以下方式被用作解码器输入的一部分：\n",
    "    * **直接拼接:** 将最终隐状态与解码器当前时间步的输入（例如，前一个时间步的输出）拼接在一起，作为解码器RNN的输入。\n",
    "    * **作为初始隐状态:** 将最终隐状态作为解码器RNN的初始隐状态。这样，解码器在开始生成输出序列时，就拥有了输入序列的信息。\n",
    "    * **注意力机制:** 在更复杂的模型中，可以使用注意力机制来**动态地选择编码器隐状态的不同部分**，并将其作为解码器输入的一部分。\n",
    "- “编码器最终的隐状态在**每一个时间步**都作为解码器的输入序列的一部分”意味着，编码器将输入序列的信息压缩到一个最终隐状态中，并在解码的每个时间步将这个隐状态提供给解码器，以帮助解码器生成准确的输出序列。这种机制确保了输入序列的信息在整个解码过程中都被充分利用。\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 下面，我们动手构建 图9.7.1的设计，并将基 9.5节中介绍的“英－法”数据集来训练这个机器翻译模型。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional  as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 9.7.1 seq2seq编码器\n",
    "\n",
    "从技术上讲，编码器将长度可变的输入序列转换成\n",
    "**形状固定的上下文变量$\\mathbf{c}$，**\n",
    "并且将输入序列的信息在该上下文变量中进行**编码**(注意c是**固定长度**的)。\n",
    "如图9.7.1所示，可以使用循环神经网络来设计编码器。\n",
    "\n",
    "考虑由一个序列组成的样本（批量大小是$1$）。\n",
    "假设输入序列是$x_1, \\ldots, x_T$，\n",
    "其中$x_t$是输入文本序列中的第$t$个词元。\n",
    "在时间步$t$，循环神经网络将词元$x_t$的输入特征向量\n",
    "$\\mathbf{x}_t$和$\\mathbf{h} _{t-1}$（即上一时间步的隐状态）\n",
    "转换为$\\mathbf{h}_t$（即当前步的隐状态）。\n",
    "使用一个函数$f$来描述循环神经网络的循环层所做的变换：\n",
    "\n",
    "$$\\mathbf{h}_t = f(\\mathbf{x}_t, \\mathbf{h}_{t-1}) \\tag{9.7.1} $$\n",
    "\n",
    "总之，编码器通过选定的函数$q$，\n",
    "将所有时间步的隐状态转换为上下文变量：\n",
    "\n",
    "$$\\mathbf{c} =  q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T) \\tag{9.7.2}$$\n",
    "\n",
    "比如，当选择$q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T) = \\mathbf{h}_T$时\n",
    "（就像图9.7.1中一样），\n",
    "<b>上下文变量仅仅是输入序列在最后时间步的隐状态$\\mathbf{h}_T$</b>。\n",
    "（也就是上下文向量c只保留编码器最后的输出隐状态$H_t$，因此\n",
    "最后只取出$H_t$时刻的state[1]作为上下文变量$\\mathbf{c}$。\n",
    "）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "到目前为止，我们使用的是一个**单向循环神经网络来设计编码器**，\n",
    "其中隐状态只依赖于输入子序列，\n",
    "这个子序列是由输入序列的**开始位置到隐状态所在的时间步的位置**\n",
    "（包括隐状态所在的时间步）组成。\n",
    "我们也可以使用双向循环神经网络构造编码器，\n",
    "其中隐状态依赖于**两个输入子序列**，\n",
    "两个子序列是由隐状态所在的时间步的位置**之前的序列**和**之后的序列**（包括隐状态所在的时间步），\n",
    "因此**隐状态对整个序列的信息都进行了编码**。\n",
    "\n",
    "现在，让我们实现循环神经网络编码器。\n",
    "注意，我们使用了**嵌入层（embedding layer）**\n",
    "来获得输入序列中每个词元的特征向量。\n",
    "嵌入层的权重是一个**矩阵**，\n",
    "其**行数等于输入词表的大小（`vocab_size`）**，\n",
    "其**列数等于特征向量的维度（`embed_size`）**（也就是词表中的每个词是一个样本，每个样本的特征是特征向量）。\n",
    "对于任意输入词元的索引$i$，\n",
    "嵌入层获取权重矩阵的第$i$行（从$0$开始）以返回其**特征向量**。\n",
    "另外，本文选择了一个**多层门控循环单元**来实现编码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "- **要点：**\n",
    "  -  编码器将长度可变的输入序列转换为形状固定的上下文变量$\\mathbf{c}$，并将输入序列的信息在该上下文变量中进行编码。\n",
    "  - 使用循环神经网络来设计编码器，每个时间步$t$将词元$x_t$的输入特征向量$\\mathbf{x}_t$和上一时间步的隐状态$\\mathbf{h}_{t-1}$转换为当前时间步的隐状态$\\mathbf{h}_t$，通过函数$f(\\mathbf{x}_t, \\mathbf{h}_{t-1})$来描述循环层的变换。\n",
    "  - 编码器通过函数$q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T)$将所有时间步的隐状态转换为上下文变量$\\mathbf{c}$。当选择$q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T) = \\mathbf{h}_T$时，上下文变量仅仅是输入序列在最后时间步的隐状态$\\mathbf{h}_T$。\n",
    "  \n",
    "  - 可以使用双向循环神经网络构造编码器，其中隐状态依赖于输入序列的两个子序列，分别是隐状态所在的时间步**之前**的子序列和隐状态所在的时间步**之后**的子序列，从而对整个序列的信息进行编码。\n",
    "  - 在实现循环神经网络编码器时，使用嵌入层来获得输入序列中每个词元的**特征向量**，嵌入层的权重矩阵的行数等于输入词表的大小，列数等于特征向量的维度。对于任意输入词元的索引$i$，嵌入层获取权重矩阵的第$i$行（从$0$开始）以返回其特征向量。编码器选择多层门控循环单元来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **说明：**\n",
    "- **(1)为何上下文变量c是固定长度的？**\n",
    "  - 矩阵$\\mathbf{c}$是固定长度的是因为编码器的设计原则是将长度可变的输入序列**转换成形状固定**的上下文变量$\\mathbf{C}$，并将输入序列的信息在该上下文变量中进行编码。\n",
    "  - 在机器翻译任务中，输入序列可能是一个句子，而不同句子的长度可以是不同的，因此需要将这些长度可变的输入序列转换成一个**统一的上下文表示**，以便后续的解码器能够根据这个上下文变量生成输出序列。\n",
    "  - 在编码器的设计中，通常选择一个特定的函数$q$来将所有时间步的隐状态$\\mathbf{h}_1, \\ldots, \\mathbf{h}_T$转换为上下文变量$\\mathbf{c}$。\n",
    "  - 一个**常见的选择**是将上下文变量$\\mathbf{c}$设为输入序列在**最后时间步的隐状态**$\\mathbf{h}_T$，即$\\mathbf{c} = \\mathbf{h}_T$。这样，无论输入序列的长度是多少，编码器都会将其编码成一个固定长度的上下文变量$\\mathbf{c}$。\n",
    "  - 固定长度的上下文变量$\\mathbf{c}$在序列到序列学习中非常重要，因为**解码器需要一个固定长度的向量来初始化其隐状态**，以便连续生成输出序列的词元。\n",
    "  - **如果上下文变量$\\mathbf{c}$的长度也是可变的，那么解码器的初始化将变得复杂，并且会引入更多的不稳定性和不可预测性，影响模型的训练和性能**。\n",
    "  - 因此，通过将长度可变的输入序列编码成固定长度的上下文变量$\\mathbf{c}$，编码器为解码器提供了一个**统一的、有限的信息表示**，使得解码器能够更好地对输入序列进行建模和生成输出序列。\n",
    "  - 这种编码器-解码器架构在序列到序列学习任务中非常有效，并且已经被广泛应用于机器翻译、文本生成等自然语言处理任务中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(2)公式9.7.2：$\\mathbf{c} =  q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T)$如何理解？**\n",
    "  - 公式9.7.2表示编码器将长度可变的输入序列的所有时间步的隐状态$\\mathbf{h}_1, \\ldots, \\mathbf{h}_T$通过一个函数$q$进行转换，得到一个形状固定的上下文变量$\\mathbf{c}$。这个上下文变量$\\mathbf{c}$用于将整个输入序列的信息进行编码，并且将这个编码后的信息**传递给解码器**，供其用于生成输出序列。\n",
    "  - 具体来说，$\\mathbf{h}_1, \\ldots, \\mathbf{h}_T$是编码器在不同时刻$t$的隐状态。在时间步$t$，编码器通过一个循环层的变换函数$f(\\mathbf{x}_t, \\mathbf{h}_{t-1})$，将输入词元的特征向量$\\mathbf{x}_t$和上一时间步的隐状态$\\mathbf{h}_{t-1}$转换为当前时间步的隐状态$\\mathbf{h}_t$。这样，编码器在整个序列上运行，每个时间步都会产生一个隐状态$\\mathbf{h}_t$。\n",
    "  - 然后，函数$q$的作用是将所有时间步的隐状态$\\mathbf{h}_1, \\ldots, \\mathbf{h}_T$转换成一个**形状固定**的上下文变量$\\mathbf{c}$。这个函数$q$可以是任意的函数，用于将多个隐状态合并成一个固定长度的向量。例如，可以选择$q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T) = \\mathbf{h}_T$，即将上下文变量$\\mathbf{c}$设置为输入序列在最后时间步的隐状态$\\mathbf{h}_T$。这样，上下文变量$\\mathbf{c}$就是**整个输入序列的编码信息**，其中包含了输入序列中每个时间步的隐状态的信息。\n",
    "  - 在序列到序列学习中，编码器的目的是将输入序列的信息编码成一个固定长度的上下文变量，这个上下文变量作为解码器的初始隐状态，帮助解码器连续生成输出序列的词元。因此，通过函数$q$将多个隐状态合并成一个固定长度的上下文变量是十分关键的，它为解码器提供了一个**统一的、有限的**信息表示，使得解码器能够更好地对输入序列进行建模和生成输出序列。\n",
    "  - 公式(9.7.2)中的编码器函数$q$用于将所有时间步的隐状态$\\mathbf{h}_1, \\ldots, \\mathbf{h}_T$转换成一个形状固定的上下文变量$\\mathbf{c}$，这个上下文变量$\\mathbf{c}$用于将输入序列的信息编码成一个固定长度的向量，供解码器使用。具体来说，编码器的设计目的是将长度可变的输入序列编码成一个固定长度的上下文向量，以便后续解码器能够根据这个上下文向量生成输出序列。\n",
    "  - 在更复杂的模型中，如使用**注意力机制**的模型，函数𝑞可能是一个加权平均，比如$q(\\mathbf{h}_1, \\ldots, \\mathbf{h}_T)= 𝑤_1𝐡_1+…+𝑤_𝑇𝐡_𝑇$，其中$𝑤_1,…,𝑤_𝑇$是权重，可以通过训练数据学习得到。在这样的模型中，上下文向量𝐜是所有隐藏状态的加权平均，它不仅包含了最后一个时间步的信息，而且还包含了其他所有时间步的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(3)嵌入层的主要作用与功能是什么？**\n",
    "  - 嵌入层（Embedding Layer）是深度学习中常用的一种技术，其主要功能作用是将**离散型的输入**（如词元或类别）转换成**连续型的特征向量**。\n",
    "    - 在自然语言处理任务中，嵌入层通常用于将文本中的词元映射成实数向量，也称为**词嵌入（Word Embeddings）**。\n",
    "    - 嵌入层在文本处理、自然语言处理以及图像处理等领域都有广泛的应用。\n",
    "  - 嵌入层的主要作用有以下几个方面：\n",
    "    - **降维：** 嵌入层可以将**高维的离散输入**（如词表的大小）映射到**低维的连续空间**中。这样做的好处是，可以将原本**稀疏的高维特征表示**转换为**稠密的低维特征表示**，从而减少模型参数量，降低计算复杂度，并且提高模型的泛化能力。\n",
    "    - **语义表示：** 嵌入层通过学习将相似的词元映射到相近的特征向量，从而在嵌入空间中保持**语义的相似性**。这意味着，语义上相似的词元在**嵌入空间中的距离应该较近**，从而方便模型捕捉词元之间的语义关系。例如，\"king\" 和 \"queen\" 在嵌入空间中应该更接近，因为它们是同一语义类别的词元。\n",
    "    - **特征学习：** 嵌入层可以学习词元的分布式表示，使得每个维度对应于词元的某个特定特征。这样，模型可以根据需要灵活地选择和组合不同维度的特征来表达**不同的语义和上下文信息**，从而提高模型的表达能力和泛化能力。\n",
    "    - **稠密表示：** 嵌入层生成的特征向量是**连续的、稠密的**，而不是原始的离散表示。这种连续稠密表示有利于深度学习模型进行优化和训练，并且可以更好地捕捉数据中的**细微变化和模式**。\n",
    "    - **词元编码：** 嵌入层可以将不同的词元**编码成向量**，使得模型能够处理词元级别的输入，而不是直接处理词元的标识符。这样做可以更方便地在模型中进行处理和操作，同时**减少模型的复杂性和计算开销**。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络编码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # 嵌入层\n",
    "        '''\n",
    "        Embedding参数列表：\n",
    "        Num_embeddings (int) -嵌入字典（或词表）的大小，本例为10\n",
    "        Embedding_dim (int)  -每个嵌入向量的大小，本例为8\n",
    "        该类的详细说明见后。\n",
    "        '''\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        '''\n",
    "        通过GRU实现嵌入层。\n",
    "        （1）嵌入层维度，就是特征维度（一般8的倍数,在本例中是8）。\n",
    "        （2）隐状态单元数(本例中是16),循环层层数（本例是2）,dropout消除率（本例中缺省为0）。\n",
    "        例子传入4个参数的值为：8,16,2,0，此处的特征维数类似前面几节的独热编码。\n",
    "        二者其实区别不是很大。说到底，嵌入层就是一个表征方式而已。\n",
    "        '''\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        '''\n",
    "        嵌入层输出'X'的形状：(batch_size,num_steps,embed_size)        \n",
    "        本例中为(4,7),经过嵌入层之后X转换成(4,7,8)\n",
    "        '''\n",
    "        X = self.embedding(X)\n",
    "        \n",
    "        '''\n",
    "        在循环神经网络模型中，第1维对应于时间步数，\n",
    "        第2维是批量大小，第3维是嵌入向量大小\n",
    "        将维度从(4,7,8)变换成(7,4,8)。\n",
    "        '''\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # 如果未提及状态，则默认为0\n",
    "        '''\n",
    "        # output的形状:(num_steps,batch_size,num_hiddens)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        '''\n",
    "        output, state = self.rnn(X)        \n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 由于这里使用的是门控循环单元，所以在最后一个时间步的多层隐状态的形状是（隐藏层的数量，批量大小，隐藏单元的数量）。\n",
    "- 如果使用长短期记忆网络，`state`中还将包含记忆单元信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **说明：nn.Embedding类说明**\n",
    "  - nn.Embedding类：一个简单的查找表，存储固定字典的嵌入和大小。此模块通常用于存储词嵌入，并使用索引检索它们。模块的输入是一个索引列表，输出是相应的词嵌入。\n",
    "  - nn.Embedding的主要功能另一种解释是：为每个输入词元索引（整数）获取对应的嵌入向量。它将输入的整数索引映射到词嵌入矩阵中的**对应行**，并返回这些嵌入向量作为模型的输入。词嵌入矩阵是nn.Embedding类的一个参数，其**行数等于词汇表的大小**，**列数等于特征向量的维度**。\n",
    "  - 嵌入这个概念不是很好理解，说到底就是一个**向量**，用来表征某个语言模型里tokens的**特征**或图像的像素特征。词嵌入是自然语言处理（NLP）中语言模型与表征学习技术的统称。概念上而言，它是指**把一个维数为所有词的数量的高维空间嵌入到一个维数低得多的连续向量空间中，每个单词或词组被映射为实数域上的向量**。        \n",
    "  - 所谓词嵌入，通俗来讲，是指**将一个单词(word)转换为一个向量 (vector)表示**，所以词嵌入有时又被叫作“word2vec\"。 \n",
    "  - 所谓 word2vec，是指学习一个映射f，它可以将单词变成向量表示: vec = f(word)。在 RNN 的每一步输入中，不再用词语的独热表示，而是用映射之后的 vec输入模型，这样模型不仅会得到更丰富的有关词语的信息，而且**输入的维数还下降**了，因此性能会大大提高。嵌入层的权重是一个矩阵：(词表大小,特征维度)。\n",
    "  - 在此使用了torch的Embedding模型，本例中词嵌入维度是(10,8)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "- 循环层返回变量的说明可以参考8.6节。\n",
    "- 下面，我们实例化**上述编码器的实现**：\n",
    "  - 使用一个两层门控循环单元编码器，其隐藏单元数为$16$。\n",
    "  - 给定一小批量的输入序列`X`（批量大小为$4$，时间步为$7$）。\n",
    "  - 在完成所有时间步后，最后一层的隐状态的输出是一个张量（`output`由编码器的循环层返回）：\n",
    "    - 其形状为（时间步数，批量大小，隐藏单元数）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## num_hiddens原值为16\n",
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "'''\n",
    "eval函数将模块设置为评估模式。\n",
    "这只对某些模块有影响。\n",
    "如受影响，具体模块在训练/评估模式下的行为详见相关模块文档。\n",
    "'''\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "\n",
    "'''\n",
    "(1)output:输出层的形状为(时间步数,批量大小,隐状态单元数).\n",
    "   注意这个输出并非Y，而是所有时间步的最后一层的隐状态。可参考9.1节的解析。\n",
    "(2)state（隐状态）层的形状为(层数,批量大小,隐状态单元数)\n",
    "  落脚点仍是在隐状态。\n",
    "'''\n",
    "output.shape,state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "- **说明：output与state保存数据**\n",
    "  - output：这个变量保存了GRU在**所有时间步的隐状态**。其形状通常为 (序列长度或时间步数, 批量大小, 隐藏层大小)。这就意味着，对于输入序列中的每一个时间步，output都保存了经过GRU处理后的隐藏状态。\n",
    "  - state：这个变量保存了GRU的**最后一个时间步的隐状态**。对于GRU，这实际上与output的最后一个时间步是相同的，即 state 等价于 output[-1]。state 的形状通常为 (层数, 批量大小, 隐藏层大小)。\n",
    "  - 具体来说，output 保存了序列中**每个词元**的信息，这些信息可能会被解码器在生成每个元素时使用。而 state 保存了整个输入序列的上下文信息，这在一些seq2seq模型中，如基本的循环神经网络（RNN）中，被**作为解码器的初始隐状态**。\n",
    "  - 在实际的模型如注意力机制中，解码器可能会**更多地依赖 output** 而非 state 来获取输入序列的信息。\n",
    "  - 具体可参见GRU的官方文档：https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "<img src='..\\img\\9_7_3.png' width=600px/> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597],\n",
       "         [ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597],\n",
       "         [ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597],\n",
       "         [ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597]],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([[-0.2566, -0.0290, -0.0556,  0.3312, -0.5949,  0.3050,  0.2708,  0.0247,\n",
       "           0.0411,  0.3010, -0.1174, -0.3026, -0.7427,  0.1963, -0.1534, -0.4181],\n",
       "         [-0.2566, -0.0290, -0.0556,  0.3312, -0.5949,  0.3050,  0.2708,  0.0247,\n",
       "           0.0411,  0.3010, -0.1174, -0.3026, -0.7427,  0.1963, -0.1534, -0.4181],\n",
       "         [-0.2566, -0.0290, -0.0556,  0.3312, -0.5949,  0.3050,  0.2708,  0.0247,\n",
       "           0.0411,  0.3010, -0.1174, -0.3026, -0.7427,  0.1963, -0.1534, -0.4181],\n",
       "         [-0.2566, -0.0290, -0.0556,  0.3312, -0.5949,  0.3050,  0.2708,  0.0247,\n",
       "           0.0411,  0.3010, -0.1174, -0.3026, -0.7427,  0.1963, -0.1534, -0.4181]],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([[ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597],\n",
       "         [ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597],\n",
       "         [ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597],\n",
       "         [ 0.3092,  0.0095, -0.2642, -0.1144, -0.1634,  0.3695,  0.1200,  0.1150,\n",
       "          -0.0195, -0.0350,  0.2581, -0.0958,  0.0317,  0.1078,  0.2420, -0.4597]],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "输出状态Ht,只取出最上面一层的输出状态，就是用state[1]，也是所谓上下文变量c。\n",
    "后面的解码器要使用到编码器最后的输出状态也是该变量。\n",
    "output保存的序列中7个tokens的批量隐状态，即7个tokens的state[1]，\n",
    "而state[0]没保存在ouput中。\n",
    "'''\n",
    "state[1],state[0],output[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "上下文变量c的每一行其实相等。\n",
    "在RNN和GRU中 state[-1] 和 output[-1] 是相同的，\n",
    "但在其他类型的网络中可能并非如此，比如LSTM就不同。\n",
    "'''\n",
    "state[-1][0]==state[-1][1], state[-1] == output[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "## 9.7.2 seq2seq解码器\n",
    "正如上文提到的，编码器输出的上下文变量$\\mathbf{c}$\n",
    "对整个输入序列$x_1, \\ldots, x_T$进行编码。\n",
    "来自训练数据集的输出序列$y_1, y_2, \\ldots, y_{T'}$，\n",
    "对于每个时间步$t'$（与输入序列或编码器的时间步$t$不同），\n",
    "<b>解码器输出$y_{t'}$的概率取决于先前的输出子序列\n",
    "$y_1, \\ldots, y_{t'-1}$和上下文变量$\\mathbf{c}$，\n",
    "即$P(y_{t'} \\mid y_1, \\ldots, y_{t'-1}, \\mathbf{c})$。</b>\n",
    "\n",
    "为了在序列上模型化这种条件概率，\n",
    "我们可以使用另一个循环神经网络作为解码器。\n",
    "<b>在输出序列上的任意时间步$t^\\prime$，\n",
    "循环神经网络将来自上一时间步的输出$y_{t^\\prime-1}$\n",
    "和上下文变量$\\mathbf{c}$作为其输入，\n",
    "然后在当前时间步将它们和上一隐状态\n",
    "$\\mathbf{s}_{t^\\prime-1}$转换为隐状态$\\mathbf{s}_{t^\\prime}$</b>。\n",
    "因此，可以使用函数$g$来表示解码器的隐藏层的变换（需要使用到3个变量）：\n",
    "\n",
    "$$\\mathbf{s}_{t^\\prime} = g(y_{t^\\prime-1}, \\mathbf{c}, \\mathbf{s}_{t^\\prime-1}) \\tag{9.7.3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "在获得解码器的隐状态之后，\n",
    "我们可以使用输出层和**softmax操作**来计算在时间步$t^\\prime$时输出$y_{t^\\prime}$的**条件概率分布**\n",
    "$P(y_{t^\\prime} \\mid y_1, \\ldots, y_{t^\\prime-1}, \\mathbf{c})$。\n",
    "\n",
    "根据图9.7.1，当实现解码器时，\n",
    "我们**直接使用编码器最后一个时间步的隐状态来初始化解码器的隐状态**。\n",
    "这就要求使用循环神经网络实现的编码器和解码器具有**相同数量的层和隐藏单元**。\n",
    "为了进一步包含经过编码的输入序列的信息，\n",
    "**上下文变量在所有的时间步与解码器的输入进行拼接（concatenate）**。\n",
    "为了预测输出词元的概率分布，\n",
    "在循环神经网络解码器的最后一层使用全连接层来变换隐状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "- **要点：**\n",
    "  -  **解码器的目标**：在序列到序列模型中，解码器的目标是给定上下文变量 $c$，它对整个输入序列进行编码，生成对应的输出序列。\n",
    "  - **条件概率的模型化**：对于输出序列中的每一个时间步 $t'$，解码器输出 $y_{t'}$ 的概率取决于**先前的输出子序列** $y_1,…,y_{t'-1}$ 和上下文变量 $c$，即 $P(y_{t'}|y_1,…,y_{t'-1},c)$。这个条件概率是通过另一个循环神经网络（RNN）作为解码器来建模的。\n",
    "  - **解码器的输入**：在输出序列上的任意时间步 $t'$，RNN 将来自上一时间步的输出 $y_{t'-1}$ 和上下文变量 $c$ 作为其输入。\n",
    "  - **隐藏状态的变换**：RNN 在当前时间步将 $y_{t'-1}$、$c$ 和上一隐状态 $s_{t'-1}$ 转换为隐状态 $s_{t'}$，即 $s_{t'} = g(y_{t'-1}, c, s_{t'-1})$。\n",
    "  -  **输出的条件概率分布**：得到解码器的隐藏状态后，我们可以使用全连接层和 softmax 操作来计算在时间步 $t'$ 时输出 $y_{t'}$ 的条件概率分布 $P(y_{t'}|y_1,…,y_{t'-1},c)$。\n",
    "  - **初始化解码器的隐藏状态**：编码器在最后一个时间步的隐藏状态用来初始化解码器的隐藏状态。\n",
    "  - **拼接上下文变量和解码器的输入**：为了进一步包含经过编码的输入序列的信息，上下文变量在所有的时间步与解码器的输入进行拼接（concatenate）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "origin_pos": 18,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    \"\"\"用于序列到序列学习的循环神经网络解码器\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        '''\n",
    "        d2l.Decoder和d2l.Encoder都是接口类型，里面的函数没实现，\n",
    "        类似C++中的纯虚拟函数和Java中的interface。\n",
    "        注意在实现接口时，需要在子类中的初始化函数中通过super调用父类的初始化函数。\n",
    "        '''\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        '''\n",
    "        vocab_size, embed_size分别是词表大小和嵌入大小。\n",
    "        '''\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        '''\n",
    "        第一个输入大小：8+16=24，此处将嵌入层单元数与隐状态单元数相加是为了将隐状态和输入的维度拼接操作。\n",
    "        参数值依次为：24,16,2,0.\n",
    "        因此此处是就是“拼接上下文变量和解码器的输入”。\n",
    "        因为输入的嵌入层处理的数据(7,4,8)，将输入的最后一维8与上下文变量c的最后一维拼接，\n",
    "        也就是将8+16=24。\n",
    "        公式9.7.3\n",
    "        \n",
    "        '''\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "        ## 参数值依次为：16,10\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    \n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        '''\n",
    "        GRU前向传播返回两个值：一个是最后一层的所有时间步，所有批量的隐状态；\n",
    "        第二个是最后一个时间步的所有层的所有批量的隐状态。\n",
    "        两个值放在一个tuple里。\n",
    "        此处enc_outputs[1]是取出第二个值，即最后一个时间步的隐状态，\n",
    "        即output, state中的state\n",
    "        '''\n",
    "        return enc_outputs[1]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "        '''\n",
    "        尤其要注意：解码器的输入X是强制教学Teacher Forcing，后面有介绍。\n",
    "        初始X形状(4,7), embedding之后变成(4,7,8), permute之后变成(7,4,8)。\n",
    "        4是批量大小；7是序列长度(时间步数)；8是嵌入层大小\n",
    "        '''        \n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        \n",
    "        # 广播context，使其具有与X相同的num_steps\n",
    "        '''\n",
    "        state形状是(2, 4, 16),state[-1]的形状是(1, 4, 16)\n",
    "        将第一维复制(即X.shape[0]，X第一维的形状)，后两维不复制。\n",
    "        那么结果就是(7, 4, 16)\n",
    "        '''\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        \n",
    "        '''\n",
    "        上文中讲的：\n",
    "        为了进一步包含经过编码的输入序列的信息（经过模型左边的编码器进行了编码）， \n",
    "        上下文变量在所有的时间步与解码器的输入(强制教学)进行拼接（concatenate）.\n",
    "        实际上就是在第3个维度，将多个矩阵的列在横向进行拼接。\n",
    "        那么X_and_context形状变成：(7,4,24)\n",
    "        '''\n",
    "        X_and_context = torch.cat((X, context), 2)\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        前面定义的GRU(24, 16, 2, 0), \n",
    "        输入X_and_context的形状为：(7,4,24),\n",
    "        state形状为：(2, 4, 16)，注意是2层GRU。\n",
    "        \n",
    "        输出的output是(7, 4, 16)，\n",
    "        输出state形状保持不变。\n",
    "        '''\n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        \n",
    "        '''\n",
    "        GRU的输出要经过全连接稠密层的前馈网络，获取概率列表，即每个时间步的预测输出。\n",
    "        前面定义的Linear(16, 10),\n",
    "        此时output输出为(7, 4, 16)@(16, 10)，输出结果为(7, 4, 10),\n",
    "        最后经过permute之后，形状为(4, 7, 10)\n",
    "        '''\n",
    "        output = self.dense(output).permute(1, 0, 2)\n",
    "        # output的形状:(batch_size,num_steps,vocab_size)\n",
    "        # state的形状:(num_layers,batch_size,num_hiddens)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "- **说明：多维张量的复制,repeat函数用法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[13, 14, 15, 16],\n",
       "          [17, 18, 19, 20],\n",
       "          [21, 22, 23, 24]],\n",
       " \n",
       "         [[13, 14, 15, 16],\n",
       "          [17, 18, 19, 20],\n",
       "          [21, 22, 23, 24]],\n",
       " \n",
       "         [[13, 14, 15, 16],\n",
       "          [17, 18, 19, 20],\n",
       "          [21, 22, 23, 24]],\n",
       " \n",
       "         [[13, 14, 15, 16],\n",
       "          [17, 18, 19, 20],\n",
       "          [21, 22, 23, 24]]]),\n",
       " torch.Size([4, 3, 4]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 多维张量的复制\n",
    "r=torch.arange(1,25,1).reshape((2,3,4))\n",
    "r1=torch.arange(26,50,1).reshape((2,3,4))\n",
    "## repeat参数是指对应维度复制的次数，本例中第一维复制4次，后两维不复制。\n",
    "## r的维度是(2,3,4)，r[-1]的维度是(1,3,4),repeat之后是(4,3,4)\n",
    "r[-1].repeat(4,1,1), r[-1].repeat(4,1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24]],\n",
       " \n",
       "         [[13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24]],\n",
       " \n",
       "         [[13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24]],\n",
       " \n",
       "         [[13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24],\n",
       "          [13, 14, 15, 16, 13, 14, 15, 16],\n",
       "          [17, 18, 19, 20, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 21, 22, 23, 24]]]),\n",
       " torch.Size([4, 9, 8]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[-1].repeat(4,3,2),r[-1].repeat(4,3,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4, 26, 27, 28, 29],\n",
       "         [ 5,  6,  7,  8, 30, 31, 32, 33],\n",
       "         [ 9, 10, 11, 12, 34, 35, 36, 37]],\n",
       "\n",
       "        [[13, 14, 15, 16, 38, 39, 40, 41],\n",
       "         [17, 18, 19, 20, 42, 43, 44, 45],\n",
       "         [21, 22, 23, 24, 46, 47, 48, 49]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 当dim=2时，将矩阵里的列进行横向拼接\n",
    "torch.cat((r,r1),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "- 下面，我们用与前面提到的编码器中相同的超参数来**实例化解码器**。\n",
    "- 如我们所见，解码器的输出形状变为（批量大小，时间步数，词表大小），\n",
    "  - 其中张量的最后一个维度存储预测的词元分布。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_state.shape:  torch.Size([2, 4, 16])\n",
      "\n",
      "最终输出output和state的值分别是：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "decoder.eval()\n",
    "init_state = decoder.init_state(encoder(X))\n",
    "print('init_state.shape: ',init_state.shape)\n",
    "output, state = decoder(X, init_state)\n",
    "\n",
    "'''\n",
    "output的(4,7,10)，分别为：(批量大小，时间步数，词表大小)\n",
    "'''\n",
    "print('\\n最终输出output和state的值分别是：')\n",
    "output.shape, state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "- 总之，上述循环神经网络“编码器－解码器”模型中的各层如图9.7.2所示。\n",
    "\n",
    "<center><img src='../img/seq2seq-details.svg'/></center>\n",
    "<center>图9.7.2 循环神经网络编码器-解码器模型中的层</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## 9.7.3 seq2seq模型损失函数\n",
    "\n",
    "- 在每个时间步，解码器预测了输出词元的概率分布。\n",
    "类似于语言模型，可以**使用softmax来获得分布，\n",
    "并通过计算交叉熵损失函数来进行优化**。\n",
    "- 回想一下9.5节中，特定的填充词元被添加到序列的末尾，\n",
    "因此不同长度的序列可以以相同形状的小批量加载。\n",
    "但是，我们应该**将填充词元的预测排除在损失函数的计算之外**（使用mask掩码机制来实现）。\n",
    "\n",
    "- 为此，我们可以使用下面的`sequence_mask`函数\n",
    "**通过零值化屏蔽不相关的项**，\n",
    "以便后面任何不相关预测的计算都是与零的乘积，结果都等于零。\n",
    "- 例如，如果两个序列的有效长度（不包括填充词元）分别为$1$和$2$，\n",
    "则第一个序列的第一项和第二个序列的前两项之后的剩余项将被**清除为零**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "origin_pos": 26,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "## 序列屏蔽的目的在于将固定长度序列中的填充项零值化后以便不计算其权重\n",
    "## 此时文本序列的有效长度valid_len起作用了\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "    ## size函数的参数表示获取某个维的大小\n",
    "    ## 此处获取第二维的大小，然后在该维度上进行序列屏蔽\n",
    "    maxlen = X.size(1)\n",
    "    '''\n",
    "    小于号前面的张量纵向广播，后面张量横向广播，然后再进行比较。\n",
    "    注意None所谓索引时可以扩充张量的维度。\n",
    "    在本示例中：maxlen=3, 小于号左边部分是[[0,1,2]]，形状是(1, 3); 小于号右边部分是[[1],[2]]，形状为(2,1)\n",
    "    然后开始广播，左边是：[[0,1,2],[0,1,2]],右边是[[1,1,1],[2,2,2]];二者的形状皆变成(2, 3)\n",
    "    再按元素进行比较，mask是[[True, False, False],[True, True, False]]\n",
    "    '''\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    '''\n",
    "    ~mask=[[False, True, True],[False, False, True]]\n",
    "    下述表达式就是~mask为True的地方元素的值为value，即0。\n",
    "    其主要用意是将X每一行索引在val_len后面的元素设为0。\n",
    "    '''\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, torch.tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "- **说明：通过None扩展维度**\n",
    "  - 在下例中，使用索引操作`None` 为 `t` 和 `v` 添加一个额外的维度。\n",
    "    - `None` 索引等同于 np.newaxis，用于增加一个维度。\n",
    "  - `t[None,:]` 在 `t` 的第一维上添加一个维度，`v[:,None]` 在 `v` 的第二维上添加一个维度。\n",
    "  - 使用 `None` 来增加一个维度，变换得到的 `t` 和 `v` 形状如下：\n",
    "    - `t[None,:]` 的形状为 `(1, 3)`，表示为 `[[0, 1, 2]]`；\n",
    "    - `v[:,None]` 的形状为 `(2, 1)`，表示为 `[[1], [2]]`。\n",
    "  - 这一步的结果是两个形状为 `(1, 3)` 和 `(2, 1)` 的二维张量。\n",
    "  - 利用 PyTorch 的广播机制，将形状为 `(1, 3)` 和 `(2, 1)` 的两个张量进行比较。\n",
    "  - 根据广播机制，如果两个张量的尺寸不兼容，那么张量的形状会沿着长度为1的维度进行扩展，以匹配另一个张量的形状。\n",
    "  - 在这里，`t[None,:]`的形状会扩展为`(2, 3)`，`v[:,None]`的形状会扩展为 `(2, 3)`。\n",
    "  - 具体来说：\n",
    "    - `t[None,:]` 在第0维（行）上复制，扩展为 `(2, 3)`，表示为 `[[0, 1, 2], [0, 1, 2]]`；\n",
    "    - `v[:,None]` 在第1维（列）上复制，扩展为 `(2, 3)`，表示为 `[[1, 1, 1], [2, 2, 2]]`。\n",
    "  - 然后在比较操作中，PyTorch的广播机制会将两者扩展为相同的形状。\n",
    "  - 这样就得到了一个形状为 `(2, 3)` 的布尔张量，表示 `t` 中的每个元素是否小于 `v` 中的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2]]),\n",
       " tensor([[1],\n",
       "         [2]]),\n",
       " tensor([[ True, False, False],\n",
       "         [ True,  True, False]]),\n",
       " tensor([[False,  True,  True],\n",
       "         [False, False,  True]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0,1,2])\n",
    "v = torch.tensor([1, 2])\n",
    "t[None,:], v[:,None], t[None,:] < v[:,None], ~(t[None,:] < v[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]),\n",
       " tensor([[0., 1., 2., 3., 4., 5.]]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.]]),\n",
       " torch.Size([1, 6]),\n",
       " torch.Size([6, 1]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## [None,:]增加第一维; [:,None]，增加第二维。\n",
    "m=torch.arange(6,dtype=torch.float32)\n",
    "m.shape,m[None,:],m[:,None],m[None,:].shape,m[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 前者纵向广播，后者横向广播，直到二者形状相同，然后再按元素进行比较\n",
    "m[None,:]<m[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "- 我们还可以使用此函数屏蔽最后几个轴上的所有项。\n",
    "- 如果愿意，也可以使用指定的非零值来替换这些项。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "origin_pos": 30,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "maxlen = X.size(1)\n",
    "mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                    device=X.device)[None, :] < valid_len[:, None]\n",
    "（1）maxlen=3\n",
    "（2）mask=[[0,1,2]]<[[1],[2]]\n",
    "（3）mask的值是[[True, False, False],[True, True, False]]\n",
    "（4） ~mask=[[False, True, True],[False, False, True]]\n",
    "（5）转换索引就是：[0,1],[0,2],[1,2]被修改成-1，也就是被屏蔽的对象。\n",
    "（6）通俗讲，就是张量是包含2个3行4列的矩阵，此功能更就是在2个矩阵的行上进行屏蔽。\n",
    "     即第1个矩阵的第2,3两行被屏蔽，第2个矩阵的第3行被屏蔽。\n",
    "（7）首先是sequence_mask函数中的maxlen=X.size(1)，\n",
    "     其次[None, :]和[:, None]的用法表示是在X的第2维上进行屏蔽：\n",
    "     如果X是2维张量，那么就是在张量的列上进行屏蔽操作；\n",
    "     如果X是3维张量，那么就是在矩阵的行上进行操作，都是张量的第2维。\n",
    "'''\n",
    "X = torch.ones(2, 3, 4)\n",
    "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 32
   },
   "source": [
    "- 我们可以**通过扩展softmax交叉熵损失函数来遮蔽不相关的预测**。\n",
    "  - 最初，所有预测词元的掩码都设置为1。\n",
    "  - 一旦给定了有效长度，与**填充词元**对应的掩码将被设置为0。\n",
    "  - 最后，将所有词元的损失乘以掩码，以过滤掉损失中填充词元产生的不相关预测。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        ## 应该是将固定长度序列的填充部分给屏蔽\n",
    "        ## 当然不是直接屏蔽，而是通过与权重0相乘，将其设为零\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        \n",
    "        ## permute(0, 2, 1)将张量中的矩阵分别转置\n",
    "        ## pred重排之后的形状是(batch_size,vocab_size,num_steps)\n",
    "        ## label形状是(batch_size,num_steps)\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        ## unweighted_loss * weights是将屏蔽的部分权重损失设置为0\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **说明：CrossEntropyLoss的参数顺序以及为何代码中为何调用pred.permute(0, 2, 1)**\n",
    "  - 在本例中，词表的大小即表示类型的多少。参数的d1,...dk在此处是指序列长度（时间步数）。\n",
    "  - 因而在计算交叉熵时，输入input张量的形状应该是(批量大小，词表(类型)大小，序列长度)\n",
    "  - `pred.permute(0, 2, 1)` 是用来改变 `pred` 的张量的维度顺序的。`permute` 函数接收一系列维度索引，返回按这些索引重排的新张量。\n",
    "  - 在 PyTorch 中，交叉熵损失函数 `nn.CrossEntropyLoss()` 要求输入 `pred` 的形状是 `(N, C, ...)`，其中 `N` 是批次大小，`C` 是类别数量，后面的 `...` 代表任意数量的额外维度。而本例中 `pred` 的原始形状是 `(batch_size, num_steps, vocab_size)`，即 `(N, ..., C)`。\n",
    "  - 这是与交叉熵损失函数的要求不符的。因此，本例使用 `permute(0, 2, 1)` 来交换第二个和第三个维度，使得 `pred` 的形状变为 `(batch_size, vocab_size, num_steps)`，即 `(N, C, ...)`，这样就符合交叉熵损失函数的要求了。\n",
    "  - CrossEntropyLoss的输入输出形状：\n",
    "<img src='../img/9_7_1.png' width=600 height=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7949, 2.4466, 2.7947, 0.7909, 3.1993, 3.2717, 2.9942],\n",
       "        [2.9812, 4.2825, 1.4594, 2.9519, 3.1399, 2.3589, 2.9363],\n",
       "        [2.8042, 1.8205, 2.4484, 2.6666, 5.1029, 3.6224, 2.6319],\n",
       "        [1.2541, 2.7896, 1.9238, 3.5010, 3.0225, 2.6173, 3.6890]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 交叉熵损失计算\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(4, 7, 10, requires_grad=True)\n",
    "target = torch.empty(4, 7, dtype=torch.long).random_(5)# 类似tensor([2, 2, 0])\n",
    "loss.reduction = 'none'\n",
    "output = loss(input.permute(0,2,1), target)\n",
    "# 此调用方式效果一样\n",
    "# output = loss.forward(input.permute(0,2,1), target)\n",
    "# 损失\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7949, 2.4466, 2.7947, 0.7909, 3.1993, 3.2717, 2.9942],\n",
       "        [2.9812, 4.2825, 1.4594, 2.9519, 3.1399, 2.3589, 2.9363],\n",
       "        [2.8042, 1.8205, 2.4484, 2.6666, 5.1029, 3.6224, 2.6319],\n",
       "        [1.2541, 2.7896, 1.9238, 3.5010, 3.0225, 2.6173, 3.6890]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "全手工实现：\n",
    "（1）计算对象是张量中所包含矩阵的列，也就是第3维\n",
    "（2）前面代码中的pred.permute(0, 2, 1),将预测结果的维度进行重排。\n",
    "     即将作为预测结果的vocab_size从第3维重排到第2维，也就是将行重排成列。\n",
    "     从(4, 7, 10)重排成(4，10, 7)，也就是每个小批量的7个tockens的vocab索引独热编码\n",
    "     在矩阵中是以列的形式存在的。\n",
    "（3）因此在交叉熵损失也是计算利用tokens的预测独热编码与词表实际索引标签进行对比来计算的。\n",
    "'''\n",
    "output2 = torch.zeros(4,7)\n",
    "input2 = input.permute(0, 2, 1)\n",
    "## 最外层循环是张量的矩阵个数，此处为2\n",
    "for i in torch.arange(input2.shape[0]):\n",
    "    ## 里层迭代是每个矩阵的列，注意是shape[1]表示矩阵的列数，此处为4\n",
    "    for j in torch.arange(input2[i].shape[1]):\n",
    "        '''\n",
    "        交叉熵计算：-X[label]+log(sum(exp(X[j])))\n",
    "        (1) X[label]表示标签索引对应该列第label个元素，\n",
    "            此处为input[i,:,j][target[i,j]]，\n",
    "            input[i,:,j]为X，\n",
    "            target[i,j]为该列的标签；\n",
    "        (2) exp(X[j])对该列各数据求e的X[j]次方；\n",
    "        (3) 然后对上述各值求和；\n",
    "        (4) 对和求自然对数。\n",
    "        (5) 再将X[label]与对数相加，即得出该列的交叉熵。\n",
    "        '''\n",
    "        output2[i,j] = -input2[i,:,j][target[i,j]]+torch.log(torch.sum(torch.exp(input2[i,:,j])))        \n",
    "        \n",
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.7963, grad_fn=<DivBackward0>),\n",
       " tensor(2.7963, grad_fn=<NllLoss2DBackward0>))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均损失：手工计算与调用torch的cross_entropy计算，结果一致\n",
    "torch.sum(output2)/(input2.shape[0]*input2.shape[2]),F.cross_entropy(input2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([4, 10, 7]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1480, 1.6679, 0.6607, 0.1792], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 掩码交叉熵损失，或掩码softmax损失的手工实现过程\n",
    "valid_len=torch.tensor([3,4,2,1])\n",
    "celoss = MaskedSoftmaxCELoss()\n",
    "celoss(input, target, valid_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算掩码权重矩阵\n",
    "X = torch.ones(4,7)\n",
    "weights = sequence_mask(X, valid_len)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.7949, 2.4466, 2.7947, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [2.9812, 4.2825, 1.4594, 2.9519, 0.0000, 0.0000, 0.0000],\n",
       "         [2.8042, 1.8205, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [1.2541, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "        grad_fn=<MulBackward0>),\n",
       " tensor([1.1480, 1.6679, 0.6607, 0.1792], grad_fn=<MeanBackward1>))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算掩码损失，然后计算批量中每个序列的平均损失（即按照每个序列词元的损失进行平均）\n",
    "(output*weights), (output*weights).mean(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 36
   },
   "source": [
    "- 可以创建三个相同的序列来进行**代码健全性检查**，\n",
    "- 然后分别指定这些序列的有效长度为$4$、$2$和$0$。\n",
    "- 结果就是，第一个序列的损失应为第二个序列的两倍，而第三个序列的损失应为零。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "origin_pos": 38,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "## 9.7.4 seq2seq模型训练\n",
    "\n",
    "\n",
    "- 在下面的循环训练过程中，如图9.7.1所示，\n",
    "特定的序列开始词元（“&lt;bos&gt;”）和**原始的输出序列（不包括序列结束词元“&lt;eos&gt;”）拼接在一起作为解码器的输入**。\n",
    "- 这被称为**强制教学（teacher forcing）**，因为原始的输出序列（词元的标签）被送入解码器。\n",
    "- 或者，将来自上一个时间步的**预测**得到的词元作为解码器的当前输入。\n",
    "<center><img src='../img/seq2seq.svg' /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"训练序列到序列模型\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        '''\n",
    "        两种模型的参数初始化方式还不一样\n",
    "        （1）xavier_uniform_等初始化函数的参数都是Tensor类型。\n",
    "        （2）Linear的权重参数保存在weight里，weight是一个Parameter类型，而Parameter是Tensor\n",
    "             的子类，因此也是Tensor类型，可以作为初始化函数的参数。偏置保存在bias里，此处只初始化了\n",
    "             Linear的权重参数。\n",
    "        （3）GRU有多个参数，比如更新门、重置门、隐状态的隐藏层参数。每类参数作为一个Parameter对象保存在\n",
    "             list里，因此需要迭代逐个取出作为初始化函数的参数，进行初始化。\n",
    "             同样也只初始化权重参数。此处方法用到字典通过参数名取出参数张量进行初始化。\n",
    "        \n",
    "        '''\n",
    "        if type(m) == nn.Linear:\n",
    "            ## 只初始化权重，偏置不在此处初始化。\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            ## 取出参数名，然后通过参数名迭代进行初始化\n",
    "            for param in m._flat_weights_names:\n",
    "                ## 只初始化权重，偏置不在此处初始化\n",
    "                ## 通过判断参数名字符串里是否包含'weight'来判断该参数是否为权重\n",
    "                ## 然后在_parameters里通过参数名取出参数\n",
    "                ## _parameters是一个OrderedDict类型参数，键名有序排列，即按照声明顺序排列。\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    ## 将初始化函数应用到模型\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    ## 优化器的第一个参数是模型的待初始化参数，是一个生成器。\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    ## 模型进入训练模式\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                     xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)  # 训练损失总和，词元数量\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            '''\n",
    "            X: 源语言张量，形状: (64,10)，保存固定长度的、由词元序列构成的语句，\n",
    "               长度为10，序列长度不足10，则填充到长度10.\n",
    "            X_valid_len：(64,)的张量，保存每个序列的有效长度，即取出填充之后的序列长度。\n",
    "            \n",
    "            Y,Y_valid_len: 目标语言张量，涵义同上。\n",
    "            '''\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            ## 目标语言中<bos>符号的索引张量，形状为(64,1)\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                          device=device).reshape(-1, 1)\n",
    "            '''\n",
    "            强制教学的涵义需要仔细理解。但是下述代码很好理解：\n",
    "            就是将bos符号插入目标语言训练数据的第一列，去掉目标语言的最后一列，\n",
    "            然后保存到dec_input。\n",
    "            '''\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学\n",
    "            ## 调用模型第二个参数是强制教学输入\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            ## 损失函数\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            ## 反向传播计算梯度\n",
    "            l.sum().backward() # 损失函数的标量进行“反向传播”\n",
    "            ## 梯度裁剪\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            ## 优化参数\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "        f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "- **说明：'英-法'语料库数据形状**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意在中文环境下运行 d2l.load_data_nmt(64, 10)有可能报错，需要修改d2l包原代码torch.py：d:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\d2l\\torch.py\n",
    "的858行，此行代码增加encoding='utf-8'.\n",
    "<img src='..\\img\\9_7_2.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## '英-法'语料的形状\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总长度： 10\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "训练数据train_iter的形状：\n",
    "list[10*tuple(tensor(64,10),tensor(64),tensor(64,10),tensor(64))]\n",
    "即10个小批量；\n",
    "每个小批量保存：\n",
    "(1) 源语言编码64*10的矩阵，长度向量(64, )\n",
    "(2) 目标语言编码64*10的矩阵，长度向量(64, )\n",
    "(3) 注意源语言与目标语言的语料数据都是句子，作为tokens的序列保存，\n",
    "    编码矩阵里保存每个序列在词表中的编码，源语言与目标语言各自有一个词表。\n",
    "(4) 长度向量分别保存句子序列的实际长度(有效长度)。\n",
    "'''\n",
    "print('数据总长度：',len(list(iter(train_iter))))\n",
    "for i in train_iter:\n",
    "    print(i[0].shape)\n",
    "    print(i[1].shape)\n",
    "    print(i[2].shape)\n",
    "    print(i[3].shape)\n",
    "    #print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 201)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 词表长度,源语言与目标语言词表长度还不一致\n",
    "len(src_vocab),len(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight_ih_l0',\n",
       " 'weight_hh_l0',\n",
       " 'bias_ih_l0',\n",
       " 'bias_hh_l0',\n",
       " 'weight_ih_l1',\n",
       " 'weight_hh_l1',\n",
       " 'bias_ih_l1',\n",
       " 'bias_hh_l1']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.GRU(7,256,2)\n",
    "#参数名称\n",
    "rnn._flat_weights_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 44
   },
   "source": [
    "- 在机器翻译数据集上，可以创建和训练一个循环神经网络“编码器－解码器”模型用于序列到序列的学习。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## d2l包里的EncoderDecoder类\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"The base class for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        ## 使用编码层的输出作为解码层隐状态初始化的参数\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "origin_pos": 45,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.019, 10083.2 tokens/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"262.1875pt\" height=\"183.35625pt\" viewBox=\"0 0 262.1875 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-11-29T15:26:25.498951</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 262.1875 183.35625 \n",
       "L 262.1875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "L 50.14375 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 77.081681 145.8 \n",
       "L 77.081681 7.2 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m0ef8d3db28\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0ef8d3db28\" x=\"77.081681\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(70.719181 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 110.754095 145.8 \n",
       "L 110.754095 7.2 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0ef8d3db28\" x=\"110.754095\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(101.210345 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 144.426509 145.8 \n",
       "L 144.426509 7.2 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0ef8d3db28\" x=\"144.426509\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(134.882759 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 178.098922 145.8 \n",
       "L 178.098922 7.2 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0ef8d3db28\" x=\"178.098922\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(168.555172 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 211.771336 145.8 \n",
       "L 211.771336 7.2 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0ef8d3db28\" x=\"211.771336\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(202.227586 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m0ef8d3db28\" x=\"245.44375\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(235.9 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(132.565625 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 50.14375 118.69597 \n",
       "L 245.44375 118.69597 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path id=\"m8a8d89c97b\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8a8d89c97b\" x=\"50.14375\" y=\"118.69597\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 122.495189) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 50.14375 85.749252 \n",
       "L 245.44375 85.749252 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8a8d89c97b\" x=\"50.14375\" y=\"85.749252\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 89.548471) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 50.14375 52.802534 \n",
       "L 245.44375 52.802534 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8a8d89c97b\" x=\"50.14375\" y=\"52.802534\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 56.601753) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 50.14375 19.855816 \n",
       "L 245.44375 19.855816 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8a8d89c97b\" x=\"50.14375\" y=\"19.855816\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 23.655035) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(14.798437 86.157813) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 50.14375 13.5 \n",
       "L 56.878233 50.858784 \n",
       "L 63.612716 77.508867 \n",
       "L 70.347198 95.643928 \n",
       "L 77.081681 107.297331 \n",
       "L 83.816164 115.349785 \n",
       "L 90.550647 121.10537 \n",
       "L 97.285129 125.439587 \n",
       "L 104.019612 128.343615 \n",
       "L 110.754095 130.219175 \n",
       "L 117.488578 132.229737 \n",
       "L 124.22306 133.563897 \n",
       "L 130.957543 134.289465 \n",
       "L 137.692026 135.487789 \n",
       "L 144.426509 135.484406 \n",
       "L 151.160991 136.803888 \n",
       "L 157.895474 136.854723 \n",
       "L 164.629957 137.41103 \n",
       "L 171.36444 138.059396 \n",
       "L 178.098922 137.877053 \n",
       "L 184.833405 138.32012 \n",
       "L 191.567888 138.308241 \n",
       "L 198.302371 138.278208 \n",
       "L 205.036853 138.70556 \n",
       "L 211.771336 138.76103 \n",
       "L 218.505819 138.658103 \n",
       "L 225.240302 138.944175 \n",
       "L 231.974784 139.246865 \n",
       "L 238.709267 139.5 \n",
       "L 245.44375 138.868 \n",
       "\" clip-path=\"url(#p9ddd71eb06)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 50.14375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 245.44375 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 7.2 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p9ddd71eb06\">\n",
       "   <rect x=\"50.14375\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()\n",
    "\n",
    "## 参数值:(64,10)\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "'''\n",
    "len(src_vocab)=184\n",
    "参数值(184, 32, 32, 2, 0.1)\n",
    "返回值：\n",
    "output的形状:(num_steps,batch_size,num_hiddens): (10, 64, 32)\n",
    "state的形状:(num_layers,batch_size,num_hiddens)：(2, 64, 32)\n",
    "'''\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "\n",
    "'''\n",
    "len(tgt_vocab)=201\n",
    "参数值(201, 32, 32, 2, 0.1)\n",
    "output的形状:(batch_size,num_steps,vocab_size)：(64, 10, 201)\n",
    "state的形状:(num_layers,batch_size,num_hiddens)：(2, 64, 32)\n",
    "'''\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                        dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "#\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 46
   },
   "source": [
    "## 9.7.5 seq2seq模型预测\n",
    "\n",
    "- 为了采用一个接着一个词元的方式预测输出序列，\n",
    "每个解码器当前时间步的输入都将来自于前一时间步的预测词元。\n",
    "- 与训练类似，序列开始词元（“&lt;bos&gt;”）\n",
    "在初始时间步被输入到解码器中。\n",
    "- 该预测过程如 图9.7.3所示，\n",
    "当输出序列的预测遇到序列结束词元（“&lt;eos&gt;”）时，预测就结束了。\n",
    "\n",
    "<center><img src='../img/seq2seq-predict.svg'/></center>\n",
    "<center>图9.7.3 使用循环神经网络编码器-解码器逐词元地预测输出序列</center>\n",
    "\n",
    "- 将在9.8节中介绍不同的序列生成策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "origin_pos": 48,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "#@save\n",
    "## 预测参数函数：src_vocab：184，tgt_vocab：201，num_steps：10\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"序列到序列模型的预测\"\"\"\n",
    "    # 在预测时将net设置为评估模式\n",
    "    net.eval() ##与train函数对应\n",
    "    '''\n",
    "    以'go .'为例, src_tokens是['go', ' ', '.', '<eos>'],\n",
    "    经过如下处理之后变成[9, 0, 4, 3]\n",
    "    '''\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]    \n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    \n",
    "    ## 将源tokens截断或填充为长度10的序列\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    \n",
    "    # 添加批量维，enc_x的形状从(10,)变成为(1,10)\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    编码层的输入(1,10)的序列,有效长度为：4\n",
    "    初始化编码层和解码层，注意解码层的的输入使用了编码层输出。\n",
    "\n",
    "    enc_outputs包含两个：一个是所有时间步的隐状态，一个是最后一个时间步的隐状态。\n",
    "    dec_state：(2,1,32)\n",
    "    '''\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    \n",
    "    ## 添加批量轴，此处是解码器起始预测token，即'<bos>'    \n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        # Y:(1,1,201), dec_state:(2,1,32)\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)    \n",
    "        \n",
    "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
    "        ## 这就是模型进行预测时，要将上一个时间步的输出Y_t-1'作为本时间步的输入\n",
    "        ## 注意：这种操作只是在预测阶段发生，在训练阶段没有\n",
    "        dec_X = Y.argmax(dim=2)        \n",
    "        \n",
    "        ## item()函数从张量中提取标量,是词表中的索引，通过idx_to_token函数获取词元\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        \n",
    "        # 保存注意力权重（后面章节将重点讨论）,本例没有attention_weights变量\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tensor([[2]], device='cuda:0'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_vocab['<bos>'], torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_vocab['<eos>'],tgt_vocab['<pad>'],tgt_vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[200]]), 200, tensor(200))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = torch.arange(1*1*201).reshape(1,1,201)\n",
    "arg.argmax(dim=2), (arg.argmax(dim=2)).squeeze(dim=0).item(),arg.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "- **说明：unsqueeze与squeeze函数用法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4]]),\n",
       " torch.Size([1, 4]),\n",
       " tensor([[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " torch.Size([4, 1]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.tensor([1,2,3,4])\n",
    "s1=torch.unsqueeze(s,dim=0)\n",
    "s2=torch.unsqueeze(s,dim=1)\n",
    "s1,s1.shape,s2,s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), tensor([1, 2, 3, 4]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3=torch.squeeze(s1)\n",
    "s3.shape, s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 0, 4, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['go'],src_vocab[' '],src_vocab['.'],src_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 源词表和目标词表的'eos'编码是一样的\n",
    "src_vocab['<eos>'],tgt_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('va', '!', '<eos>')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## go .的预测结果\n",
    "tgt_vocab.idx_to_token[16],tgt_vocab.idx_to_token[5],tgt_vocab.idx_to_token[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3), 3, int)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 使用tensor的item()函数返回一个标量(此处是int类型)，而不是张量\n",
    "s1.argmax(),s1.argmax().item(),type(s1.argmax().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 50
   },
   "source": [
    "## 9.7.6 seq2seq模型预测序列的评估\n",
    "\n",
    "- 可以通过与真实的标签序列进行比较来评估预测序列。\n",
    "- 虽然BLEU(Bilingual Evaluation Understudy)，最先是用于评估机器翻译的结果，\n",
    "但现在它已经被广泛用于**测量许多应用的输出序列的质量**。\n",
    "- 原则上说，对于预测序列中的任意$n$元语法（n-grams），\n",
    "BLEU的评估都是**这个$n$元语法是否出现在标签序列中**。\n",
    "- BLEU定义为：\n",
    "$$ \\exp\\left(\\min\\left(0, 1 - \\frac{\\mathrm{len}_{\\text{label}}}{\\mathrm{len}_{\\text{pred}}}\\right)\\right) \\prod_{n=1}^k p_n^{1/2^n} \\tag{9.7.4}$$\n",
    "  - 其中$\\mathrm{len}_{\\text{label}}$表示标签序列中的词元数和\n",
    "$\\mathrm{len}_{\\text{pred}}$表示预测序列中的词元数，\n",
    "$k$是用于匹配的最长的$n$元语法。\n",
    "  - 另外，用$p_n$表示$n$元语法的精确度，它是两个数量的比值：\n",
    "    - 第一个是预测序列与标签序列中匹配的$n$元语法的数量，\n",
    "    - 第二个是预测序列中$n$元语法的数量的比率。\n",
    "  - 具体地说，给定标签序列$A$、$B$、$C$、$D$、$E$、$F$和预测序列$A$、$B$、$B$、$C$、$D$，\n",
    "我们有$p_1 = 4/5$、$p_2 = 3/4$、$p_3 = 1/3$和$p_4 = 0$。\n",
    "\n",
    "- 根据公式9.7.4中BLEU的定义，\n",
    "当预测序列与标签序列完全相同时，BLEU为$1$。\n",
    "- 此外，由于$n$元语法越长则匹配难度越大，\n",
    "所以BLEU为更长的$n$元语法的精确度分配更大的权重。\n",
    "  - 具体来说，当$p_n$固定时，$p_n^{1/2^n}$\n",
    "会随着$n$的增长而增加（原始论文使用$p_n^{1/n}$）。\n",
    "  - 而且，由于预测的序列越短获得的$p_n$值越高，\n",
    "所以公式9.7.4中乘法项之前的系数用于惩罚较短的预测序列。\n",
    "  - 例如，当$k=2$时，给定标签序列$A$、$B$、$C$、$D$、$E$、$F$\n",
    "和预测序列$A$、$B$，尽管$p_1 = p_2 = 1$，\n",
    "惩罚因子$\\exp(1-6/2) \\approx 0.14$会降低BLEU。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 50
   },
   "source": [
    "- **BLEU的代码实现**如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "origin_pos": 51,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k):  #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    \n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814773296495302"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 简单测试bleu函数\n",
    "bleu('A B B C D','A B C D E F',k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814773296495301"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手工计算过程\n",
    "import numpy as np\n",
    "np.exp(-0.2)*((4/5)**(1/2))*((3/4)**(1/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 52
   },
   "source": [
    "- 最后，利用训练好的循环神经网络“编码器－解码器”模型，\n",
    "**将几个英语句子翻译成法语**，并计算BLEU的最终结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "origin_pos": 53,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va ceci !, bleu 0.000\n",
      "i lost . => j'ai perdu perdu perdu ., bleu 0.651\n",
      "he's calm . => fais-moi confiance bien perdu ., bleu 0.000\n",
      "i'm home . => je suis chez partie ., bleu 0.752\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    '''\n",
    "    eng是一个句子。num_steps=10\n",
    "    '''\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 55
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 根据“编码器-解码器”架构的设计，\n",
    "  我们可以使用两个循环神经网络来设计一个序列到序列学习的模型。\n",
    "* 在实现编码器和解码器时，我们可以使用多层循环神经网络。\n",
    "* 我们可以使用遮蔽来过滤不相关的计算，例如在计算损失时。\n",
    "* 在“编码器－解码器”训练中，强制教学方法将原始输出序列（而非预测结果）输入解码器。\n",
    "* BLEU是一种常用的评估方法，它通过测量预测序列和标签序列之间的$n$元语法的匹配度来评估预测。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
