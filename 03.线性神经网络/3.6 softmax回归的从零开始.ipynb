{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 3.6 softmax回归的从零开始实现\n",
    "- **目录**\n",
    "  -  3.6.1 初始化模型参数\n",
    "  -  3.6.2 定义softmax操作\n",
    "  -  3.6.3 定义模型\n",
    "  -  3.6.4 定义损失函数\n",
    "  -  3.6.5 分类精度\n",
    "  -  3.6.6 训练\n",
    "  -  3.6.7 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 本例使用Fashion-MNIST数据集，并设置数据迭代器的批量大小为256。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "- **说明：IPython.display模块简介**\n",
    "  - `IPython.display` 模块提供了一组用于在 IPython 环境（例如 Jupyter Notebook）中显示各种数据类型的函数。\n",
    "  - 这些函数可以用来显示：\n",
    "    * **富文本**: HTML, JavaScript, Markdown\n",
    "    * **图片**: PNG, JPEG, SVG\n",
    "    * **视频**\n",
    "    * **音频**\n",
    "    * **数学公式**: LaTeX\n",
    "    * **进度条**\n",
    "    * **自定义的交互式控件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$E=mc^2$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IPython的交互性功能\n",
    "display.Latex(r'$E=mc^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Hello World!</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.HTML('<h2>Hello World!</h2>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x = np.arange(0,2*np.pi,0.01)\n",
    "y = np.sin(x)\n",
    "fig,ax = plt.subplots(1,figsize=(3,3))\n",
    "ax.plot(x,y)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "## d2l包的load_data_fashion_mnist和前一节一致\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 训练集和测试集的形状\n",
    "train_iter.dataset.data.shape, test_iter.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader,\n",
       " torchvision.datasets.mnist.FashionMNIST,\n",
       " torch.Tensor)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 注意FashionMNIST继承自torch.utils.data.Dataset类\n",
    "type(train_iter), type(train_iter.dataset), type(train_iter.dataset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## 3.6.1 初始化模型参数\n",
    "\n",
    "- 每个样本都将用固定长度的向量表示。\n",
    "- 原始数据集中的每个样本都是$28 \\times 28$的图像，本节中**将展平每个图像，把它们看作长度为784的向量。**\n",
    "- 每个像素位置都可看作成一个特征。\n",
    "- softmax回归的输出与类别个数一致，**因为数据集有10个类别，所以网络输出维度为10**。\n",
    "- 权重将构成一个$784 \\times 10$的矩阵，\n",
    "- 偏置将构成一个$1 \\times 10$的行向量。\n",
    "- 与线性回归类似，本例将使用正态分布初始化权重`W`，偏置初始化为0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_inputs = 784 ##展平后的图像数据向量长度(或维度)\n",
    "num_outputs = 10 ##与Fashion-MNIST数据的标签类型数量一致\n",
    "'''\n",
    "W的形状是(输入大小，输出大小)，即(784, 10)。\n",
    "对于每一张图片数据经过全连接层的计算方式：(784,)@(784,10)=(10,)。\n",
    "如果是n张图片，则是(n,784)@(784,10)=(n,10)，然后再通过softmax求解分类概率。\n",
    "即矩阵-向量乘法，结果仍是是一个向量。\n",
    "'''\n",
    "\n",
    "##注意requires_grad都设为True，表示W,b是需要自动求梯度的张量，用于更新变量\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## W和b的形状\n",
    "W.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "## 3.6.2 定义softmax操作\n",
    "\n",
    "- `sum`运算符如何沿着张量中的特定维度工作, 给定一个矩阵`X`，**默认情况**下`sum`函数对**所有元素求和**。\n",
    "-  也可以只求同一个轴上的元素，即同一列（轴0）或同一行（轴1）。\n",
    "- 如果`X`是一个形状为`(2, 3)`的张量，如对列进行求和， 则结果将是一个具有形状`(3,)`的向量。\n",
    "- 当调用`sum`运算符时，可以指定**保持在原始张量的轴数**，而**不折叠**求和的维度，这将产生一个具有形状`(1, 3)`的二维张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "origin_pos": 10,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 7., 9.]]),\n",
       " tensor([[ 6.],\n",
       "         [15.]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "## keepdim=True表示即便进行sum,mean等降维操作，仍保持结果和原张量的维度一致\n",
    "## 此处计算的结果和X张量一样，保持二维张量的计算结果\n",
    "X.sum(0, keepdim=True), X.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "- 实现softmax由三个步骤组成：\n",
    "  1. 对每个项求幂（使用`exp`）；\n",
    "  1. 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；\n",
    "  1. 将每一行除以其规范化常数，确保结果的和为1。\n",
    "- 回顾一下这个表达式：\n",
    "$$\n",
    "\\mathrm{softmax}(\\mathbf{X})_{ij} = \\frac{\\exp(\\mathbf{X}_{ij})}{\\sum_k \\exp(\\mathbf{X}_{ik})}.\n",
    "$$\n",
    "分母又称为**规范化常数**。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "origin_pos": 14,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    ## 比如本例中，partion是对X_exp行求和，即对每行的10个(列)元素求和\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    ## 返回softmax函数值\n",
    "    return X_exp / partition  # 这里应用了广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "- 对于任何随机输入，**将每个元素变成一个非负数**。\n",
    "- 此外，依据概率原理，**每行总和为1**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0823, 0.2326, 0.5270, 0.1230, 0.0349],\n",
       "         [0.5019, 0.0950, 0.0774, 0.1196, 0.2061]]),\n",
       " tensor([1.0000, 1.0000]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.normal(0, 1, (2, 5))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "- 注意：矩阵中的非常大或非常小的元素可能造成数值上溢或下溢，但我们没有采取措施来防止这点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "## 3.6.3 定义模型\n",
    "\n",
    "- 定义softmax操作后，可以**实现softmax回归模型**。\n",
    "- 下面的代码定义了输入如何通过网络映射到输出。\n",
    "- 将数据传递到模型之前，需使用`reshape`函数**将每张原始图像展平为向量**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "origin_pos": 19,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    '''\n",
    "    通过reshape函数强制将数据的形状变成与W的形状相互协调，进而进行张量计算。\n",
    "    如果有60000张图片数据是，那么其形状是(60000,28,28)，经过reshape后变成(60000,784)。\n",
    "    X@W=(60000,784)@(784,10)=(60000,10)，最后再与偏置求和。\n",
    "    与偏置求和需使用广播机制，偏置的形状从(10,)广播成(60000, 10)\n",
    "    '''\n",
    "    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## 3.6.4 定义损失函数\n",
    "\n",
    "- 使用交叉熵损失函数，该函数是深度学习中最常见的损失函数\n",
    "- 交叉熵采用真实标签的预测概率的负对数似然。\n",
    "- 张量计算：**创建一个数据样本`y_hat`，其中包含2个样本在3个类别的预测概率，以及它们对应的标签`y`。**\n",
    "- 有了`y`，便知道在第一个样本中，第一类是正确的预测；而在第二个样本中，第三类是正确的预测。\n",
    "- 然后**使用`y`作为`y_hat`中概率的索引**，选择第一个样本中第一个类的概率和第二个样本中第三个类的概率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1000, 0.5000]), tensor([2.3026, 0.6931]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "计算交叉熵的一种快速向量算法，而不是使用一般的循环迭代。\n",
    "下述例子中，将正确与错误分类的概率都取出来，然后用于计算交叉熵。\n",
    "很显然在y_hat中，第一个样本的分类概率是错误的，第二个样本是正确的。\n",
    "\n",
    "具体说明：\n",
    "（1）一共有3个类型，其标签分别为：0, 1, 2。\n",
    "（2）y的两个值：0表示第一个样本属于标签0类；2表示第二个样本属于标签2类。\n",
    "（3）y_hat模拟分类结果，很显然其实softmax函数返回值，分别表示2个样本数据在属于3个类型各自的概率。\n",
    "'''\n",
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y_hat[[0, 1], y],  -torch.log(y_hat[[0, 1], y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5000]]),\n",
       " tensor([0.1000, 0.5000]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用独热编码方式和上述计算方式是一样的\n",
    "y1 = torch.tensor([[1,0,0],[0,0,1]])\n",
    "# 第二个计算公式是典型的交叉熵计算公式\n",
    "y1*y_hat,(y1*y_hat).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " -(y1*torch.log(y_hat)).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 23
   },
   "source": [
    "- **实现交叉熵损失函数**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "origin_pos": 24,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 0.6931])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    \n",
    "    ## 使用到了前一个cell代码的原理：使用标签作为索引取出y_hat中的概率值\n",
    "    ## 然后计算交叉熵损失\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "## 很显然，根据上一个cell中的数据，第一个样本错误分类的损失很大\n",
    "# 第二个正确分类的损失很小\n",
    "cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "## 3.6.5 分类精度\n",
    "\n",
    "- 给定预测概率分布`y_hat`，当必须输出**硬预测（hard prediction）** 时，通常选择预测概率最高的类。比如输出概率为 [0.3, 0.2, 0.5]，那么硬预测就是类型2（所有类型标签为0,1,2）。\n",
    "\n",
    "- 当预测与标签分类`y`一致时，即是正确的。分类精度即正确预测数量与总预测数量之比。\n",
    "- 精度是最重要的性能衡量标准，在训练分类器时几乎总会关注它。\n",
    "\n",
    "- 为保证计算精度可执行以下操作:\n",
    "  - 首先，如果`y_hat`是矩阵，那么假定第二个维度存储每个类的预测分数，使用`argmax`获得每行中最大元素的索引来获得预测类别。\n",
    "  - 然后**将预测类别与真实`y`元素进行比较**。由于等式运算符“`==`”对数据类型很敏感，因此需将`y_hat`的数据类型转换为与`y`的数据类型一致。结果是一个包含0（错）和1（对）的张量。\n",
    "  - 最后，对“`==`”的结果求和得到正确预测的数量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"    \n",
    "    ''' \n",
    "    (1) len(y_hat.shape) > 1表示有多个维度(此处是二维数组)，即有多个样本数据，每个样本数据又有多个分类概率。\n",
    "    (2)  y_hat.shape[1] > 1 表示第二维，即列数大于1，表示每个样本的分类概率有多个，一般等于类型个数。\n",
    "    '''\n",
    "     \n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        ## 调用argmax按行取最大值，即每一行中最大值所在的索引\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    ## 注意此处返回的是分类正确的样本总数\n",
    "    ## 如若需要计算分类的精度还要除以总样本量\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(torch.tensor([1]) == torch.tensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False,  True,  True,  True, False]), tensor(3))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ==双等号的用法\n",
    "eq = torch.tensor([1,2,1,3,4]) == torch.tensor([3,2,1,3,5])\n",
    "eq,eq.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 28
   },
   "source": [
    "- 继续使用之前定义的变量`y_hat`和`y`分别作为预测的概率分布和标签。\n",
    "  - 第一个样本的预测类别是2（该行的最大元素为0.6，索引为2），这与实际标签0不一致。\n",
    "  - 第二个样本的预测类别是2（该行的最大元素为0.5，索引为2），这与实际标签2一致。\n",
    "  - 这两个样本的分类精确率为0.5。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "origin_pos": 29,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat, y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "- 对于任意数据迭代器`data_iter`可访问的数据集，**我们可以评估在任意模型`net`的精度**。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    '''\n",
    "    net.eval()将模型设为评估模式，会影响Batch Normalization和Dropout操作，\n",
    "    因为在评估模型下二者的某些功能将被停止或减少。后面相应章节内容将涉及到。\n",
    "    '''\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 33
   },
   "source": [
    "- 定义一个实用程序类`Accumulator`（累加器），用于对多个变量进行累加。\n",
    "- 在上面的`evaluate_accuracy`函数中，`Accumulator`实例中创建了2个变量，分别用于**存储正确预测的数量和预测的总数量**。\n",
    "- 当遍历数据集时，两者都将随着时间的推移而累加。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "origin_pos": 34,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "        \n",
    "    '''\n",
    "    注意此处*args的用法，其长度和n相同，\n",
    "    比如后面例子中是3。\n",
    "    '''\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'a')\n",
      "(2, 'b')\n"
     ]
    }
   ],
   "source": [
    "## 即便两个list的长度不一样，也可以进行zip操作\n",
    "## 自动进行长度匹配\n",
    "z1 = [1, 2]\n",
    "z2 = ['a','b','c']\n",
    "for z in zip(z1, z2):\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "- 由于本例使用随机权重初始化`net`模型，因此该模型的精度应接近于随机猜测。\n",
    "- 例如在有10个类别情况下的精度为0.1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "origin_pos": 36,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1025"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(net, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 37
   },
   "source": [
    "## 3.6.6 训练\n",
    "- 首先定义一个函数来训练一个迭代周期。\n",
    "- 请注意，`updater`是更新模型参数的常用函数，它接受批量大小作为参数。\n",
    "它可以是`d2l.sgd`函数，也可以是框架的内置优化函数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "origin_pos": 39,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        \n",
    "        ## 判断模型是使用torch自带优化器，还是自定义优化器\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            ## 每次迭代小批量时，需要将梯度重置为0，因为每个小批量是重新计算的，不累计\n",
    "            updater.zero_grad() \n",
    "            \n",
    "            ''' \n",
    "            此处是使用mean方法，也就是需要对梯度除以小批量的batch_size。\n",
    "            结果为每个小批量中所有样本数据的平均梯度，更加符合梯度的本质。\n",
    "            '''\n",
    "            l.mean().backward()\n",
    "            ## 更新（优化）参数W和b\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            ## 此处就没有除以batch_size\n",
    "            ## 在自定义的优化器里除以batch_size，求平均梯度\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        ## 往Accumulator对象里增加小批量训练迭代的测量或评估数据\n",
    "        ## 包括每个批量训练的损失之和，训练精度和批量的样本数\n",
    "        ## 注意accuracy函数是计算每个批量中正确预测的数量，而不是计算精度\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回平均训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 41
   },
   "source": [
    "- 定义一个在动画中绘制数据的实用程序类`Animator`用于展示训练函数的实现，用于简化本书其余部分的代码。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        ## 设置matplotlib显示图片的格式\n",
    "        ## 将图片输出设置为SVG，即可缩放矢量图形（Scalable Vector Graphics）格式\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        ## 捕获matplotlib的各种参数\n",
    "        self.config_axes = lambda: d2l.set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        # x是周期epoch的值，y是三个模型训练结果()的值\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "            print('\\n----------X:',self.X,'\\n----------Y:',self.Y)\n",
    "        # 清除当前坐标的图形，为下一次绘制做准备，进而达到动画效果。\n",
    "        # 该函数只清除当前坐标轴的内容，而不是整个图形或窗口。\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt) # 在当前坐标轴上绘制图形，但并不触发图形的渲染和显示\n",
    "        self.config_axes()\n",
    "        ## 每个epoch训练结束即显示一次训练的相关测量指标，包括训练和测试精度\n",
    "        ## 然后清除输出的小批量训练结果。注意此处使用IPython的图形显示函数\n",
    "        display.display(self.fig)\n",
    "        # `wait=True` 参数确保在清除之前的输出之前，新的输出已经准备好显示，从而避免闪烁\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "**说明：Animator中各部分运行机制细节**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], [], []]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造空二维数组或空的2层嵌套列表\n",
    "# self.X = [[] for _ in range(n)]\n",
    "[[] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hasattr函数的用法\n",
    "l = [1,2,3,4]\n",
    "t = (1,2,3,4,5)\n",
    "tensor1 = torch.tensor([2,3,4,5])\n",
    "np1 = np.array([1,2,3,4])\n",
    "hasattr(l,'__len__'),hasattr(t,'__len__'),hasattr(tensor1,'__len__'),hasattr(np1,'__len__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animator类的add函数运行机制示例\n",
    "x = [1,1,1]\n",
    "y = (0.4431475378672282, 0.85005, 0.8285)\n",
    "X = [[] for _ in range(3)]\n",
    "Y = [[] for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1], [1], [1]], [[0.4431475378672282], [0.85005], [0.8285]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (m, n) in enumerate(zip(x, y)):\n",
    "    X[i].append(m)\n",
    "    Y[i].append(n)\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 43
   },
   "source": [
    "- 接下来实现一个**训练函数**：\n",
    "  - 该函数在`train_iter`访问到的训练数据集上训练一个模型`net`。\n",
    "  - 该训练函数将会运行多个迭代周期（由`num_epochs`指定）。\n",
    "  - 在每个迭代周期结束时，利用`test_iter`访问到的测试数据集对模型进行评估。\n",
    "  - 利用`Animator`类来可视化训练进度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "origin_pos": 44,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        # train_metrics是一个tuple，保存训练损失和训练精度\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        #动态显示每个周期的训练结果\n",
    "        #周期数、(训练损失，训练精度，测试精度)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "    print('训练损失:',train_loss,'训练精度:', train_acc, '测试精度:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tuple, int)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1,)), type((1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 45
   },
   "source": [
    "- 作为一个从零开始的实现，此处使用3.2节中定义的\n",
    "**小批量随机梯度下降来优化模型的损失函数**，设置学习率为0.1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "origin_pos": 46,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "## updater函数在train_epoch_ch3被调用，是自定义的优化器\n",
    "def updater(batch_size):\n",
    "    ## 注意如果调用自定义的优化方法，本例中是调用张量的sum函数后再调用反向传播函数\n",
    "    ## 然后在自定义优化器里除以batch_size。\n",
    "    return d2l.sgd([W, b], lr, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 48
   },
   "source": [
    "- 训练模型**10个迭代周期**。\n",
    "- 请注意，迭代周期（`num_epochs`）和学习率（`lr`）都是**可调节的超参数**。\n",
    "通过更改其值，可以提高模型的分类精度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "origin_pos": 49,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练损失: 0.4474636308034261 训练精度: 0.8485333333333334 测试精度: 0.8173\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"183.35625pt\" viewBox=\"0 0 238.965625 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-08-15T12:17:01.445295</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 238.965625 183.35625 \n",
       "L 238.965625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "L 30.103125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 51.803125 145.8 \n",
       "L 51.803125 7.2 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"md57d891dbb\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md57d891dbb\" x=\"51.803125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(48.621875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 95.203125 145.8 \n",
       "L 95.203125 7.2 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md57d891dbb\" x=\"95.203125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(92.021875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 138.603125 145.8 \n",
       "L 138.603125 7.2 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md57d891dbb\" x=\"138.603125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(135.421875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 182.003125 145.8 \n",
       "L 182.003125 7.2 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md57d891dbb\" x=\"182.003125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(178.821875 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md57d891dbb\" x=\"225.403125\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(219.040625 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(112.525 174.076563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 30.103125 122.7 \n",
       "L 225.403125 122.7 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"mc67ac6e0b6\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc67ac6e0b6\" x=\"30.103125\" y=\"122.7\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 126.499219) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 30.103125 76.5 \n",
       "L 225.403125 76.5 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc67ac6e0b6\" x=\"30.103125\" y=\"76.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 80.299219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 30.103125 30.3 \n",
       "L 225.403125 30.3 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mc67ac6e0b6\" x=\"30.103125\" y=\"30.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 34.099219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 30.103125 33.535247 \n",
       "L 51.803125 83.160409 \n",
       "L 73.503125 93.808593 \n",
       "L 95.203125 99.490857 \n",
       "L 116.903125 102.887218 \n",
       "L 138.603125 105.516927 \n",
       "L 160.303125 107.707736 \n",
       "L 182.003125 109.089695 \n",
       "L 203.703125 110.568334 \n",
       "L 225.403125 111.735901 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 30.103125 41.93085 \n",
       "L 51.803125 27.3586 \n",
       "L 73.503125 24.49805 \n",
       "L 95.203125 22.65005 \n",
       "L 116.903125 21.78765 \n",
       "L 138.603125 21.19475 \n",
       "L 160.303125 20.3516 \n",
       "L 182.003125 20.1822 \n",
       "L 203.703125 19.47765 \n",
       "L 225.403125 19.0888 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 30.103125 33.7188 \n",
       "L 51.803125 29.3067 \n",
       "L 73.503125 27.5973 \n",
       "L 95.203125 24.4095 \n",
       "L 116.903125 23.9937 \n",
       "L 138.603125 24.3633 \n",
       "L 160.303125 24.5712 \n",
       "L 182.003125 23.8089 \n",
       "L 203.703125 24.4326 \n",
       "L 225.403125 26.3037 \n",
       "\" clip-path=\"url(#p56d5819db3)\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 30.103125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 145.8 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 145.8 \n",
       "L 225.403125 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 7.2 \n",
       "L 225.403125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 140.634375 100.017188 \n",
       "L 218.403125 100.017188 \n",
       "Q 220.403125 100.017188 220.403125 98.017188 \n",
       "L 220.403125 54.982812 \n",
       "Q 220.403125 52.982812 218.403125 52.982812 \n",
       "L 140.634375 52.982812 \n",
       "Q 138.634375 52.982812 138.634375 54.982812 \n",
       "L 138.634375 98.017188 \n",
       "Q 138.634375 100.017188 140.634375 100.017188 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_20\">\n",
       "     <path d=\"M 142.634375 61.08125 \n",
       "L 152.634375 61.08125 \n",
       "L 162.634375 61.08125 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_10\">\n",
       "     <!-- train loss -->\n",
       "     <g transform=\"translate(170.634375 64.58125) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"292.333984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"353.515625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"405.615234\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_21\">\n",
       "     <path d=\"M 142.634375 75.759375 \n",
       "L 152.634375 75.759375 \n",
       "L 162.634375 75.759375 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- train acc -->\n",
       "     <g transform=\"translate(170.634375 79.259375) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"232.763672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"264.550781\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"325.830078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"380.810547\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_22\">\n",
       "     <path d=\"M 142.634375 90.4375 \n",
       "L 152.634375 90.4375 \n",
       "L 162.634375 90.4375 \n",
       "\" style=\"fill: none; stroke-dasharray: 9.6,2.4,1.5,2.4; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- test acc -->\n",
       "     <g transform=\"translate(170.634375 93.9375) scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"100.732422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"152.832031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"192.041016\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"223.828125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"285.107422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"340.087891\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p56d5819db3\">\n",
       "   <rect x=\"30.103125\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 50
   },
   "source": [
    "## 3.6.7 预测\n",
    "\n",
    "- 训练完成后即可**对图像进行分类预测**。\n",
    "- 给定一系列图像，模型将比较它们的实际标签（文本输出的第一行）和模型预测（文本输出的第二行）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "origin_pos": 51,
    "tab": [
     "pytorch"
    ],
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"516.6pt\" height=\"114.698357pt\" viewBox=\"0 0 516.6 114.698357\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-08-15T12:17:40.459375</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.8.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 114.698357 \n",
       "L 516.6 114.698357 \n",
       "L 516.6 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 7.2 107.498357 \n",
       "L 78.942857 107.498357 \n",
       "L 78.942857 35.7555 \n",
       "L 7.2 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#pc158324f22)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"imagefe5d8d4e95\" transform=\"scale(1 -1) translate(0 -72)\" x=\"7.2\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 7.2 107.498357 \n",
       "L 7.2 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 78.942857 107.498357 \n",
       "L 78.942857 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 7.2 107.498357 \n",
       "L 78.942857 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 7.2 35.7555 \n",
       "L 78.942857 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- ankle boot -->\n",
       "    <g transform=\"translate(11.348304 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"61.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"124.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"182.568359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"210.351562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"271.875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"303.662109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"367.138672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"428.320312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"489.501953\"/>\n",
       "    </g>\n",
       "    <!-- ankle boot -->\n",
       "    <g transform=\"translate(11.348304 29.7555) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-61\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"61.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"124.658203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"182.568359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"210.351562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"271.875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-62\" x=\"303.662109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"367.138672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"428.320312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"489.501953\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 93.291429 107.498357 \n",
       "L 165.034286 107.498357 \n",
       "L 165.034286 35.7555 \n",
       "L 93.291429 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p13092e0e1b)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image0e9d12b2bb\" transform=\"scale(1 -1) translate(0 -72)\" x=\"93.291429\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 93.291429 107.498357 \n",
       "L 93.291429 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 165.034286 107.498357 \n",
       "L 165.034286 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 93.291429 107.498357 \n",
       "L 165.034286 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 93.291429 35.7555 \n",
       "L 165.034286 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_2\">\n",
       "    <!-- pullover -->\n",
       "    <g transform=\"translate(104.836607 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"154.638672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"182.421875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"243.603516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"302.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"364.306641\"/>\n",
       "    </g>\n",
       "    <!-- pullover -->\n",
       "    <g transform=\"translate(104.836607 29.7555) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-70\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"154.638672\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"182.421875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-76\" x=\"243.603516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"302.783203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"364.306641\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 179.382857 107.498357 \n",
       "L 251.125714 107.498357 \n",
       "L 251.125714 35.7555 \n",
       "L 179.382857 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p64f692ad02)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image7e70a8f484\" transform=\"scale(1 -1) translate(0 -72)\" x=\"179.382857\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 179.382857 107.498357 \n",
       "L 179.382857 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 251.125714 107.498357 \n",
       "L 251.125714 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 179.382857 107.498357 \n",
       "L 251.125714 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 179.382857 35.7555 \n",
       "L 251.125714 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_3\">\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(193.812723 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(193.812723 29.7555) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_4\">\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 265.474286 107.498357 \n",
       "L 337.217143 107.498357 \n",
       "L 337.217143 35.7555 \n",
       "L 265.474286 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p9ccc49fe01)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image9f481a329f\" transform=\"scale(1 -1) translate(0 -72)\" x=\"265.474286\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 265.474286 107.498357 \n",
       "L 265.474286 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 337.217143 107.498357 \n",
       "L 337.217143 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 265.474286 107.498357 \n",
       "L 337.217143 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 265.474286 35.7555 \n",
       "L 337.217143 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_4\">\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(279.904152 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(279.904152 29.7555) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_5\">\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 351.565714 107.498357 \n",
       "L 423.308571 107.498357 \n",
       "L 423.308571 35.7555 \n",
       "L 351.565714 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p96816ddf4a)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image81c74cf194\" transform=\"scale(1 -1) translate(0 -72)\" x=\"351.565714\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 351.565714 107.498357 \n",
       "L 351.565714 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 423.308571 107.498357 \n",
       "L 423.308571 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 351.565714 107.498357 \n",
       "L 423.308571 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 351.565714 35.7555 \n",
       "L 423.308571 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_5\">\n",
       "    <!-- shirt -->\n",
       "    <g transform=\"translate(374.023393 16.318125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"115.478516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"143.261719\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"184.375\"/>\n",
       "    </g>\n",
       "    <!-- shirt -->\n",
       "    <g transform=\"translate(374.023393 29.7555) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"52.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"115.478516\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"143.261719\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"184.375\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_6\">\n",
       "   <g id=\"patch_27\">\n",
       "    <path d=\"M 437.657143 107.498357 \n",
       "L 509.4 107.498357 \n",
       "L 509.4 35.7555 \n",
       "L 437.657143 35.7555 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p158449a6ec)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "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\" id=\"image8ef2d40adf\" transform=\"scale(1 -1) translate(0 -72)\" x=\"437.657143\" y=\"-35.498357\" width=\"72\" height=\"72\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path d=\"M 437.657143 107.498357 \n",
       "L 437.657143 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path d=\"M 509.4 107.498357 \n",
       "L 509.4 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path d=\"M 437.657143 107.498357 \n",
       "L 509.4 107.498357 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path d=\"M 437.657143 35.7555 \n",
       "L 509.4 35.7555 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_6\">\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(452.087009 16.318125) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "    <!-- trouser -->\n",
       "    <g transform=\"translate(452.087009 29.7555) scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"78.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"139.253906\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"202.632812\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"254.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"316.255859\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc158324f22\">\n",
       "   <rect x=\"7.2\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p13092e0e1b\">\n",
       "   <rect x=\"93.291429\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p64f692ad02\">\n",
       "   <rect x=\"179.382857\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p9ccc49fe01\">\n",
       "   <rect x=\"265.474286\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p96816ddf4a\">\n",
       "   <rect x=\"351.565714\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p158449a6ec\">\n",
       "   <rect x=\"437.657143\" y=\"35.7555\" width=\"71.742857\" height=\"71.742857\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 900x150 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_ch3(net, test_iter, n=6):  #@save\n",
    "    \"\"\"预测标签（定义见第3章）\"\"\"\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true +'\\n' + pred for true, pred in zip(trues, preds)]\n",
    "    d2l.show_images(\n",
    "        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\n",
    "\n",
    "predict_ch3(net, test_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 52
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 借助softmax回归，我们可以训练多分类的模型。\n",
    "* 训练softmax回归循环模型与训练线性回归模型非常相似：<b>先读取数据，再定义模型和损失函数，然后使用优化算法训练模型。大多数常见的深度学习模型都有类似的训练过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "- **说明：torch.utils.data.DataLoader的用法**\n",
    "  - 在本节开始的代码`train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)`返回就是一个`DataLoader`对象。\n",
    "`torch.utils.data.DataLoader` 是一个用于加载数据的工具类，它可以将输入数据（通常是由自定义数据集类封装的数据）分批次（batch）并进行**打乱**、**采样**等操作。它使得在训练和评估神经网络时可以方便地使用小批量数据。\n",
    "\n",
    "  - 初始化 `DataLoader`：创建一个 `DataLoader` 实例，需要传递一些参数：\n",
    "\n",
    "    - `dataset`: 一个实现了 `__getitem__()` 和 `__len__()` 方法的数据集对象（通常是一个继承自` torch.utils.data.Dataset` 的类实例）。\n",
    "    - `batch_size`: 每个批次包含的样本数量。默认值为`1`。\n",
    "    - `shuffle`: 布尔值，表示是否在每个epoch开始时打乱数据。对于训练数据，通常设置为 `True` 以提高模型泛化能力；对于验证或测试数据，通常设置为 `False`。默认值为`False`。\n",
    "    - `sampler`: 可选参数，用于指定如何从数据集中抽取样本。默认情况下，如果 `shuffle=True`，则使用 `RandomSampler`；否则使用 `SequentialSampler`。\n",
    "    - `num_workers`: 用于数据加载的子进程数。默认值为`0`，表示在主进程中加载数据。增加 `num_workers` 可以利用多核CPU并行加载数据，提高数据加载速度。**此参数慎用，有可能出错**。\n",
    "    - `pin_memory`: 布尔值，表示是否将数据存储在固定内存（CUDA pinned memory）中。对于GPU训练，设置为True可以加速数据从CPU到GPU的传输。默认值为 `False`。\n",
    "    - 其他参数，如 `collate_fn`（定义如何将多个样本组合成一个批次）、`drop_last`（布尔值，表示是否丢弃最后一个不完整的批次），等。\n",
    "  \n",
    "  - `DataLoader` 是一个可迭代对象，因此你可以直接在 `for` 循环中使用它来遍历数据。每次迭代返回一个批次的数据（通常是一对输入和标签）。例如：`for inputs, labels in data_loader:`在这个迭代中进行小批量数据处理，更新参数等。\n",
    "\n",
    "  - **示例**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[ 0.6209,  1.9145,  0.5645],\n",
      "        [-2.6522, -0.4375,  0.3523],\n",
      "        [-0.2786,  1.1414,  1.5453],\n",
      "        [ 1.1538,  1.1126,  0.7759],\n",
      "        [-0.8173, -0.4234, -0.1316],\n",
      "        [-1.4438, -1.1009,  0.4670],\n",
      "        [-1.5261,  0.9095,  0.2599],\n",
      "        [ 0.2395,  0.3588, -0.5085],\n",
      "        [-0.7853,  0.5052, -1.1464],\n",
      "        [ 0.6240, -0.9912, -1.4868]])\n",
      "Labels: tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "Inputs: tensor([[ 0.4284,  0.3846, -2.2233],\n",
      "        [-2.5599,  0.6723, -0.7586],\n",
      "        [-0.3915, -0.7430,  0.0284],\n",
      "        [ 0.1503,  0.9303, -1.0305],\n",
      "        [-0.9903,  1.2597,  0.4988],\n",
      "        [-0.0128,  0.7694,  0.0325],\n",
      "        [-1.0266, -2.0273, -0.0694],\n",
      "        [-1.6367,  0.2958,  0.1520],\n",
      "        [-0.4374,  1.3355,  0.3531],\n",
      "        [-0.4360,  0.6908, -0.0801]])\n",
      "Labels: tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 1])\n",
      "Inputs: tensor([[-1.1537, -0.0262, -0.5848],\n",
      "        [-0.5474,  0.2360, -0.2686],\n",
      "        [ 0.8353,  0.5126, -0.1830],\n",
      "        [ 0.4092, -0.4380,  0.8775],\n",
      "        [-0.6824, -2.1586,  1.4201],\n",
      "        [-0.9911, -0.7733,  1.6969],\n",
      "        [-0.0649,  0.7976,  1.0599],\n",
      "        [ 0.1151,  0.9515, -1.4177],\n",
      "        [ 0.7929,  0.5828, -0.0762],\n",
      "        [-0.3270, -0.7865, -0.7823]])\n",
      "Labels: tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 0])\n",
      "Inputs: tensor([[ 0.7688, -1.0820, -0.1738],\n",
      "        [ 1.6466,  0.6495, -0.4149],\n",
      "        [-1.2605, -0.9003, -0.9003],\n",
      "        [ 0.1285,  0.7460, -0.9519],\n",
      "        [-1.5056, -0.2380, -0.7525],\n",
      "        [ 2.2634, -0.3184,  0.6028],\n",
      "        [ 1.0922, -0.1823,  0.7051],\n",
      "        [ 0.5105, -1.2588, -0.6746],\n",
      "        [ 1.3591, -0.2058,  1.2200],\n",
      "        [ 0.5177,  0.8672,  0.1679]])\n",
      "Labels: tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "Inputs: tensor([[ 1.2099, -1.3045,  1.3326],\n",
      "        [ 0.0675,  0.1366,  0.7149],\n",
      "        [ 2.5127, -0.0684,  1.9456],\n",
      "        [ 0.1780, -0.9386,  0.5444],\n",
      "        [-0.7175, -1.1370,  2.2040],\n",
      "        [ 1.9120, -0.5537,  1.5993],\n",
      "        [-0.2524, -0.4357,  1.0716],\n",
      "        [ 1.8006,  0.7346, -0.1506],\n",
      "        [ 1.1849,  1.4794,  1.3989],\n",
      "        [ 2.1199,  1.1091,  0.2078]])\n",
      "Labels: tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 1])\n",
      "Inputs: tensor([[ 0.1846,  0.4919, -1.6905],\n",
      "        [ 1.3632, -0.1839, -2.0440],\n",
      "        [ 1.4528, -2.5282, -0.2542],\n",
      "        [ 2.2106, -0.1013, -0.7154],\n",
      "        [ 0.0040, -0.2545,  0.9270],\n",
      "        [-1.6382,  0.1964,  0.6377],\n",
      "        [-1.8584, -0.2015,  0.6028],\n",
      "        [ 0.3848, -1.1797,  0.2200],\n",
      "        [-0.2284,  0.8739,  1.1863],\n",
      "        [ 0.5142, -0.9477, -0.5949]])\n",
      "Labels: tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 0])\n",
      "Inputs: tensor([[ 1.4988,  0.2024,  0.9567],\n",
      "        [ 0.4868, -0.3972, -0.4268],\n",
      "        [-1.8178, -0.2706,  0.9360],\n",
      "        [-0.2111,  0.2401,  2.3263],\n",
      "        [-0.1649,  1.2617, -0.1985],\n",
      "        [ 0.2174,  0.7258,  1.4781],\n",
      "        [-0.8960, -0.6128, -0.3895],\n",
      "        [ 0.2017, -1.0413,  1.7198],\n",
      "        [ 1.2346,  0.1264, -1.7072],\n",
      "        [-0.8923, -0.5102,  0.3064]])\n",
      "Labels: tensor([1, 0, 1, 0, 0, 1, 0, 1, 1, 0])\n",
      "Inputs: tensor([[ 1.2953,  2.0458, -1.2759],\n",
      "        [ 0.7331, -0.1914, -0.2201],\n",
      "        [-0.3360,  0.0539, -0.2162],\n",
      "        [ 0.1004,  0.7011, -0.4648],\n",
      "        [ 0.3944,  1.5187, -0.7433],\n",
      "        [ 1.2562,  1.5805,  1.0880],\n",
      "        [-0.0269,  0.2659, -0.2348],\n",
      "        [ 0.9221, -1.0842,  0.2309],\n",
      "        [-0.0073,  1.6156,  1.0494],\n",
      "        [-0.6157, -1.4079, -1.3686]])\n",
      "Labels: tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "Inputs: tensor([[-4.0371e-01, -6.2247e-02,  1.2153e+00],\n",
      "        [-9.3209e-01, -1.3723e+00,  8.0291e-01],\n",
      "        [-1.5973e+00, -8.4460e-01, -4.7754e-01],\n",
      "        [ 3.0185e-01, -6.1756e-01,  1.2495e+00],\n",
      "        [-5.7049e-01, -2.2254e-01, -8.3983e-01],\n",
      "        [-1.3331e+00, -2.0393e+00,  1.9078e+00],\n",
      "        [-1.4158e-03,  8.1162e-01,  1.4474e+00],\n",
      "        [-9.6822e-01,  6.3161e-01,  4.1619e-01],\n",
      "        [ 2.0919e-01, -1.1129e-01,  1.1713e+00],\n",
      "        [ 3.3798e-01, -2.5709e-01, -1.7682e+00]])\n",
      "Labels: tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
      "Inputs: tensor([[-1.5941,  0.5922, -0.8651],\n",
      "        [-0.0393, -0.7306, -1.6666],\n",
      "        [-0.1636, -2.0630, -1.1269],\n",
      "        [-0.0164, -1.8922, -1.0815],\n",
      "        [-0.7369, -0.0762, -2.1604],\n",
      "        [-0.9186, -1.7198, -0.2673],\n",
      "        [-0.7322, -0.7321,  0.5573],\n",
      "        [-0.7302,  1.4592,  1.6488],\n",
      "        [ 0.9901,  1.3033,  0.2484],\n",
      "        [ 0.7605, -1.6750, -0.6532]])\n",
      "Labels: tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# 自定义数据集类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# 示例数据\n",
    "data = torch.randn(100, 3)\n",
    "labels = torch.randint(0, 2, (100,))\n",
    "\n",
    "# 创建数据集实例\n",
    "my_dataset = MyDataset(data, labels)\n",
    "\n",
    "# 创建 DataLoader 实例\n",
    "data_loader = DataLoader(my_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 使用 DataLoader 遍历数据\n",
    "for inputs, labels in data_loader:\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac19aad4d4d2ac8d665b4089a9c7c0f17e7180844f2ba09430e412cac8dc2328"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
