{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a495d989-6bdc-4b0d-a7cc-9dd79875cbc2",
   "metadata": {},
   "source": [
    "# 16.3 大语言模型部署与应用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f043b-2857-4422-80df-63b736d67ff9",
   "metadata": {},
   "source": [
    "## 16.3.1 Gradio简介\r\n",
    "- Gradio是一个开源的 Python 库，它允许你快速地为机器学习模型创建可交互的网页界面。使用Gradio，研究人员和开发人员可以方便地展示他们的工作，使得非技术用户也能够轻松地尝试机器学习模型的功能，无需进行复杂的安装或设置。\r\n",
    "- **核心特性：**\r\n",
    "  - **易用性**：\r\n",
    "    - Gradio 可以用几行代码就将机器学习模型变为交互式应用。它提供了各种输入和输出组件，如文本框、图像上传、滑块等。\r\n",
    "  - **灵活性**：\r\n",
    "    - 支持多种数据类型的输入和输出，包括文本、图像、音频和视频。\r\n",
    "  - **兼容性**：\r\n",
    "    - 可以与 TensorFlow、PyTorch、scikit-learn 等主流机器学习框架无缝集成。\r\n",
    "  - **即时反馈**：\r\n",
    "     - 用户可以实时看到他们输入数据的模型预测结果，这是一个强大的特性，尤其是在演示模型时。\r\n",
    "  - **共享和部署**：\r\n",
    "    - Gradio 提供了一个链接，通过这个链接其他用户可以访问你的模型，无需设置服务器或使用云服务。\r\n",
    "  - **隐私保护**：\r\n",
    "    - 所有数据都在用户的本地计算机上处理，不通过外部服务器。\r\n",
    "  - **集成到科学生态系统**：\r\n",
    "    - 可以集成到 Jupyter 笔记本或 Python 脚本中。\r\n",
    "  - **定制化**：\r\n",
    "    - 提供了样式和布局的自定义选项，以及用于更复杂交互的接口供了样式和布局的自定义选项，以及用于更复杂交互的接口。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bbc4a-8642-4a95-a0ba-24736b3d1814",
   "metadata": {},
   "source": [
    "- **高级用法：** Gradio 也支持更复杂的输入和输出类型，例如：\n",
    "  - 输入/输出为图像的图像分类器界面。\n",
    "  - 输入为文本，输出为音频的文本到语音系统界面。\n",
    "  - 多输入多输出的界面，如同时接受图像和文本输入的模型。\n",
    "- **定制和部署：**\n",
    "  - 可以通过 CSS 定制 Gradio 界面的外观，也可以通过 `share` 参数在 Gradio 提供的服务器上临\n",
    "  - 时部署你的界面，从而使其他人可以通过互联网访问它。\n",
    "- **安装：**\n",
    "```\n",
    "pip install gradio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfceaa4-91e5-42b4-bf68-1ae9177b27c1",
   "metadata": {},
   "source": [
    "- **示例：简单应用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eced4481-df4a-4e4f-85a4-39d2ed43c630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 一个最简单的示例\n",
    "import gradio as gr\n",
    "\n",
    "def greet(name,history):\n",
    "    return \"Hello, \" + name  + \"!\"\n",
    "gr.ChatInterface(fn=greet).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c201ba9-ca8c-4218-92a6-51f79469bb1d",
   "metadata": {},
   "source": [
    "## 16.3.1 利用Gradio部署开源大语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5af13fe-7831-4b21-b21e-71d7c202d642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9eb496289224487a4c2f313c1b590ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gradio as gr\n",
    "# 模型保存路径，模型权重文件和配置文件保存在本程序代码上层目录huggingface中\n",
    "model_path = \"../huggingface/chatglm3-6b-32k\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "# 加载模型的权重文件，然后将参数从float32转换成float16（half函数），最后将模型迁移到GPU内存（cuda函数）\n",
    "model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda()\n",
    "# 将模型转换成评估状态\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890aca26-e334-4867-b814-225981922fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history1 = model.chat(tokenizer, '你好', history=[])\n",
    "def chat(name,history):\n",
    "    print('history===========0',history)\n",
    "    print('history1----------0',history1)\n",
    "    response, history1 = model.chat(tokenizer, name, history=history1)\n",
    "    print('history===========\\n',history)\n",
    "    print('history1----------\\n',history1)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10eefd3-3be4-4cc3-ae3c-09f7f0f1bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history===========0\n",
      " []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/gradio/routes.py\", line 534, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1554, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1190, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/gradio/utils.py\", line 634, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/gradio/chat_interface.py\", line 403, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/user/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/ipykernel_7691/2175263216.py\", line 4, in chat\n",
      "    print('history1----------0\\n',history1)\n",
      "UnboundLocalError: local variable 'history1' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "# 构造对话框，显示复制按钮\n",
    "chatbot=gr.Chatbot(show_copy_button=True)\n",
    "# 对话框的标签\n",
    "chatbot.label=\"问答机器人\"\n",
    "# 构造输入框以及输入框提示\n",
    "textbox = gr.Textbox(placeholder=\"在此处输入问题...\", autofocus=True, scale=40)\n",
    "# 构造对话界面\n",
    "gr.ChatInterface(fn=chat, title=\"人工智能对话系统(测试版)\",chatbot=chatbot,textbox =textbox,\n",
    "                 submit_btn=\"提交\",stop_btn=\"停止\", retry_btn=\"🔄 重试\",\n",
    "                undo_btn=\"↩️ 撤销最后一个对话\",clear_btn=\"🗑️ 清除历史对话\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d507fc72-7d38-413f-8c9d-b2469e095b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[list[str | tuple[str] | tuple[str | Path, str] | None]] | Callable | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcolor_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dict[str, str] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mevery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshow_label\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcontainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmin_width\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvisible\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0melem_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0melem_classes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[str] | str | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlatex_delimiters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'list[dict[str, str | bool]] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrtl\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshow_share_button\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshow_copy_button\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mavatar_images\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'tuple[str | Path | None, str | Path | None] | None'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msanitize_html\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrender_markdown\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbubble_full_width\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mline_breaks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlayout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Literal['panel', 'bubble'] | None\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Displays a chatbot output showing both user submitted messages and responses. Supports a subset of Markdown including bold, italics, code, tables. Also supports audio/video/image files, which are displayed in the Chatbot, and other kinds of files which are displayed as links.\n",
       "Preprocessing: passes the messages in the Chatbot as a {List[List[str | None | Tuple]]}, i.e. a list of lists. The inner list has 2 elements: the user message and the response message. See `Postprocessing` for the format of these messages.\n",
       "Postprocessing: expects function to return a {List[List[str | None | Tuple]]}, i.e. a list of lists. The inner list should have 2 elements: the user message and the response message. The individual messages can be (1) strings in valid Markdown, (2) tuples if sending files: (a filepath or URL to a file, [optional string alt text]) -- if the file is image/video/audio, it is displayed in the Chatbot, or (3) None, in which case the message is not displayed.\n",
       "\n",
       "Demos: chatbot_simple, chatbot_multimodal\n",
       "Guides: creating-a-chatbot\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Parameters:\n",
       "    value: Default value to show in chatbot. If callable, the function will be called whenever the app loads to set the initial value of the component.\n",
       "    color_map: This parameter is deprecated.\n",
       "    label: component name in interface.\n",
       "    every: If `value` is a callable, run the function 'every' number of seconds while the client connection is open. Has no effect otherwise. Queue must be enabled. The event can be accessed (e.g. to cancel it) via this component's .load_event attribute.\n",
       "    show_label: if True, will display label.\n",
       "    container: If True, will place the component in a container - providing some extra padding around the border.\n",
       "    scale: relative width compared to adjacent Components in a Row. For example, if Component A has scale=2, and Component B has scale=1, A will be twice as wide as B. Should be an integer.\n",
       "    min_width: minimum pixel width, will wrap if not sufficient screen space to satisfy this value. If a certain scale value results in this Component being narrower than min_width, the min_width parameter will be respected first.\n",
       "    visible: If False, component will be hidden.\n",
       "    elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.\n",
       "    elem_classes: An optional list of strings that are assigned as the classes of this component in the HTML DOM. Can be used for targeting CSS styles.\n",
       "    height: height of the component in pixels.\n",
       "    latex_delimiters: A list of dicts of the form {\"left\": open delimiter (str), \"right\": close delimiter (str), \"display\": whether to display in newline (bool)} that will be used to render LaTeX expressions. If not provided, `latex_delimiters` is set to `[{ \"left\": \"$$\", \"right\": \"$$\", \"display\": True }]`, so only expressions enclosed in $$ delimiters will be rendered as LaTeX, and in a new line. Pass in an empty list to disable LaTeX rendering. For more information, see the [KaTeX documentation](https://katex.org/docs/autorender.html).\n",
       "    rtl: If True, sets the direction of the rendered text to right-to-left. Default is False, which renders text left-to-right.\n",
       "    show_share_button: If True, will show a share icon in the corner of the component that allows user to share outputs to Hugging Face Spaces Discussions. If False, icon does not appear. If set to None (default behavior), then the icon appears if this Gradio app is launched on Spaces, but not otherwise.\n",
       "    show_copy_button: If True, will show a copy button for each chatbot message.\n",
       "    avatar_images: Tuple of two avatar image paths or URLs for user and bot (in that order). Pass None for either the user or bot image to skip. Must be within the working directory of the Gradio app or an external URL.\n",
       "    sanitize_html: If False, will disable HTML sanitization for chatbot messages. This is not recommended, as it can lead to security vulnerabilities.\n",
       "    render_markdown: If False, will disable Markdown rendering for chatbot messages.\n",
       "    bubble_full_width: If False, the chat bubble will fit to the content of the message. If True (default), the chat bubble will be the full width of the component.\n",
       "    line_breaks: If True (default), will enable Github-flavored Markdown line breaks in chatbot messages. If False, single new lines will be ignored. Only applies if `render_markdown` is True.\n",
       "    layout: If \"panel\", will display the chatbot in a llm style layout. If \"bubble\", will display the chatbot with message bubbles, with the user and bot messages on alterating sides. Will default to \"bubble\".\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.10/site-packages/gradio/components/chatbot.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Chatbot"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gr.Chatbot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3caae2c-efb4-4d85-951a-b4a6570826ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquery\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrole\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32768\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.cache/huggingface/modules/transformers_modules/chatglm3-6b-32k/modeling_chatglm.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.chat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d6ed6-fe9e-4517-b039-7becd66517cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
