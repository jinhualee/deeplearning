{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 1 引言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **目录**\n",
    "  - 1.1 深度学习的基本概念和操作\n",
    "    - 1.1.1 深度学习的基本概念\n",
    "    - 1.1.2 深度学习的基本步骤和操作¶\n",
    "  - 1.2 深度学习的任务\n",
    "  - 1.3 深度学习关键组件\n",
    "    - 1.3.1 数据\n",
    "    - 1.3.2 模型\n",
    "    - 1.3.3 目标函数\n",
    "    - 1.3.4 优化算法\n",
    "  - 1.4 机器学习分类\n",
    "    - 1.4.1 监督学习\n",
    "    - 1.4.2 无监督学习\n",
    "  - 1.5 深度学习发展历程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 1.1 深度学习的基本概念和操作\n",
    "### 1.1.1 深度学习的基本概念\n",
    "- **概念：** 深度学习是一种机器学习的分支，其主要特点是使用<b>深层神经网络</b>，从大量数据中提取有用特征来完成学习任务。\n",
    "- 深度学习的典型应用包括：**图像和语音识别、自然语言处理、游戏AI**等领域。\n",
    "- 深度学习与传统机器学习的最大区别是深度学习中**不需要手动提取特征**，而是通过网络**自动提取特征**进行学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "---------------\n",
    "- <b>说明：何为深层神经网络</b>（Deep Neural Networks，简称DNNs）？\n",
    "  - DNNs是一种通过模仿人脑的结构和功能来学习和做出决策的机器学习模型。\n",
    "  - 称为“**深层**”是因为它们含有多个层次的人为神经元或节点，这些层次使得网络能够学习数据中复杂和高度抽象的特征。\n",
    "  - 深层神经网络是深度学习技术的基础。深层神经网络的每一层都包含了若干的**节点**，每个节点将前一层的输出作为输入接收，进行**加权**、**求和**，然后通过**激活函数**生成输出。\n",
    "  - 激活函数的作用是增加网络的**非线性**，使得网络能够捕捉到数据中的**复杂模式**和**特征**。\n",
    "  - 深层网络中每一层都会对输入数据的不同特征进行不同程度的抽象，低层可能捕捉边缘和纹理等**基础特征**，而高层则可能理解物体的**更高层次概念**，如形状或标志。\n",
    "  - 深层网络通常通过一种叫做“**反向传播**”的算法和“**梯度下降**”的优化方法来训练。\n",
    "    - 在训练过程中，每次网络的预测输出与实际结果之间的误差会被计算出来，然后误差信息会从网络的输出层反向传播回网络的每一层，每层中的**权重（Weight）**和**偏置（Bias）** 会相应地做出调整，以便在随后的训练中**减少**这个误差。\n",
    "    - **重复进行**该过程，直到网络的性能达到事先设定的标准或者不再显著改进。\n",
    "  - 深层神经网络的一个关键优势在于其能够随着足够的数据和计算资源进行**自我改进**。\n",
    "  - 由于网络层次的深度和网络节点的数量，深层神经网络能够建模极其复杂的函数，使之能够解决以往用传统算法难以解决的问题，如图像和语音识别、自然语言处理等。\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "- 深度学习与机器学习以及人工智能三者之间的关系如下图所示：\n",
    "<center><img src='../img/1_1_1.png' width=500px></center>\n",
    "<center>图1.1.1 深度学习、机器学习与人工智能之间的关系</center>\n",
    "\n",
    "- **架构：** 深度学习的核心是神经网络，神经网络可以看作是一个**函数逼近器**，它将输入映射到输出。\n",
    "- 深层神经网络可以通过多个层次逐渐提取数据的**更高级别**的抽象特征。\n",
    "- 同时，深度学习的训练过程由数据驱动，使得模型的**泛化**能力也越来越强。\n",
    "<center><img src='../img/1_1_2.png' width=500px></center>\n",
    "<center><img src='../img/1_1_3.png' width=500px></center>\n",
    "<center>图1.1.2 神经网络以及深层神经网络架构</center>\n",
    "- **算法：**\n",
    "  - **线性和非线性处理单元** 的交替，通常称为 **层（layers）** 。\n",
    "  - 使用**链式规则**（也称为**反向传播（backpropagation）**）调整网络中的全部参数。\n",
    "\n",
    "- 总结来说，深度学习通过使用深层神经网络从海量数据中学习**抽象特征**，实现对各种任务的**高精度预测和识别**，目前已经在各个领域展现了强大的潜力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "- **说明：何为函数逼近器？**\n",
    "  - 函数逼近器是一种数学工具,用于近似复杂或未知的函数。其核心思想是用一个已知的、相对简单的函数来逼近目标函数,使得在给定范围内,两个函数之间的差异尽可能小。\n",
    "  - 基本概念:\n",
    "    - 假设有一个未知或复杂的目标函数 $f(x)$,我们希望用一个已知的函数 $g(x)$ 来近似它。\n",
    "    - 函数逼近的目标是找到一个 $g(x)$,使得在给定的定义域内,$f(x)$ 和 $g(x)$ 之间的差异最小化。\n",
    "  - 逼近的度量:通常使用某种距离或误差度量来衡量逼近的质量。常见的度量包括:\n",
    "    - 均方误差(MSE): $∫ [f(x) - g(x)]^2 dx$，离散型为：$\\frac{1}{n}\\sum_{i=1}^n [f(x_i) - g(x_i)]^2$\n",
    "    - 最大绝对误差: $max |f(x) - g(x)|$，离散型为： $\\max_{1\\leq i \\leq n} |f(x_i) - g(x_i)|$\n",
    "    - $L1$范数: $∫ |f(x) - g(x)| dx$，离散型为：$\\sum_{i=1}^n |f(x_i) - g(x_i)| $\n",
    "  - 常见的逼近方法:\n",
    "    - 多项式逼近: 使用多项式函数来逼近目标函数——**泰勒级数展开**就是一种多项式逼近。\n",
    "    - 傅里叶级数: 将函数表示为正弦和余弦函数的线性组合。\n",
    "    - 样条函数: 使用分段多项式函数来逼近复杂函数。\n",
    "    - **神经网络**: 使用多层神经元的组合来逼近复杂函数，即通用逼近定理(Universal Approximation Theorem)。\n",
    "  - 以多项式逼近为例,其数学原理如下:\n",
    "    - 假设用n阶多项式 $P_n(x) = a_0 + a_1x + a_2x^2 + ... + a_nx^n $来逼近函数$ f(x)$。\n",
    "    - 目标是最小化误差函数:$E = ∫ [f(x) - P_n(x)]^2 dx$\n",
    "    - 通过求解 $∂E/∂a_i = 0 (i = 0, 1, ..., n)$,可以得到最优的系数 $a_i$。\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "origin_pos": 0
   },
   "source": [
    "### 1.1.2 深度学习的基本步骤和操作\n",
    "\n",
    "- **（1）搭建神经网络架构**\n",
    "  - **神经元模型**：深度学习中的基本单元，模仿人脑的**神经元**。每个神经元可以接收**输入**，进行计算后产生**输出**。\n",
    "  - **层次结构**：神经网络由多层神经元组成，包括**输入层**（接收原始数据）、**隐藏层**（进行数据处理）和**输出层**（输出结果）。\n",
    "- **（2）前向传播**\n",
    "  - **数据输入**：原始数据输入到网络的输入层。\n",
    "  - **加权和激活**：每个神经元将输入数据与**权重相乘**，然后**加总**。之后通过激活函数（如ReLU或Sigmoid）转换这个**加权和**。\n",
    "- **（3）损失函数**\n",
    "  - **定义损失**：损失函数衡量预测值与真实值之间的**差异**。\n",
    "  - 常见的损失函数包括**均方误差（Mean Squared Error，MSE）**和**交叉熵（ Cross-Entropy）**。\n",
    "- **（4）反向传播和优化**\n",
    "  - **计算梯度**：使用反向传播算法计算损失函数相对于每个权重的梯度。\n",
    "  - **更新权重**：根据梯度和**学习率**调整神经网络中的权重。\n",
    "  - 这个过程是迭代的，使用如梯度下降这类**优化算法**。\n",
    "- **（5）迭代训练**\n",
    "  - **批处理和迭代**：数据通常分批处理，每批数据通过网络进行一次前向和反向传播过程，称为一个**迭代**。\n",
    "  - **多次迭代**：整个训练数据集通常需要多次通过网络进行学习，每次完整的通过称为一个epoch。\n",
    "- **（6）正则化和防止过拟合**\n",
    "  - **过拟合问题**：如果模型在训练数据上表现得太好，可能无法**泛化**到新数据上。这称为**过拟合**。\n",
    "  - **解决方法**：包括正则化技术（如L1、L2正则化）、Dropout（在训练过程中随机关闭一些神经元）等。\n",
    "- **（7）超参数调整**\n",
    "  - **超参数**：与模型训练过程中自动学习的参数不同，超参数是在**训练前设置**的，例如学习率、批大小、epoch等参数的值。\n",
    "  - **调整和优化**：通过调整这些参数，可以**改善**模型的训练效果和泛化能力。\n",
    "- **（8）评估和测试**\n",
    "  - **分割数据集**：通常将数据分为**训练集、验证集和测试集**。\n",
    "  - **性能评估**：使用验证集和测试集来评估模型的性能和泛化能力。\n",
    "- **（9）应用和部署**\n",
    "  - **模型保存和加载**：训练完成后，模型可以保存并在实际应用中加载使用。\n",
    "  - **实际应用**：深度学习模型可以应用于各种领域，如图像识别、语音识别、自然语言处理等。\n",
    "- **（10） 持续优化**\n",
    "  - **收集更多数据**：模型性能可以通过使用**更多更高质量**的数据来改善。\n",
    "  - **模型迭代**：随着技术的发展，持续对模型进行迭代和优化是必要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 深度学习的任务\n",
    "以下是深度学习或大量使用深度学习的方法在不同领域的数千个任务中的一些列表:\n",
    "- **（1）图像处理**\n",
    "  - **图像分类**：识别图像中的主要对象。\n",
    "    - 例如，确定一张照片是狗、猫还是车。\n",
    "    - 通常通过卷积神经网络（CNN）实现。\n",
    "    - 比如ImageNet图像识别竞赛，识别精度已经人类的识别精度。\n",
    "  - **目标检测**：在图像中识别和定位多个对象，以及确定这些对象在图像中的具体位置。\n",
    "    - 比如YOLO(You Only Look Once)已经发展到v10版本。\n",
    "    - 基于深度学习的目标检测在视频监控分析、自动驾驶中的障碍物识别、零售中的商品识别、无人机的目标跟踪方面应用已经很成熟。\n",
    "  - **图像分割**：更精细的任务，旨在将图像分割成多个区域或像素集合，每个区域代表不同的对象或图像的一部分。\n",
    "    - 比如U-Net算法特别设计用于医学图像分割。\n",
    "    - U-Net拥有一个**对称的U形结构**，包括收缩路径和扩张路径，可以细致地捕捉到图像的上下文信息和精确的定位信息。 \n",
    "  - **图像生成**：使用如生成对抗网络（GAN）之类的模型生成全新的图像，常用于艺术创作、游戏设计等领域。\n",
    "    - GANs由两部分组成：生成器和鉴别器。\n",
    "    - 生成器的目标是产生足以欺骗鉴别器的假图像，而鉴别器的任务是区分真图像和生成器产生的假图像。\n",
    "    - 通过这种对抗训练，GANs能够生成高质量、高分辨率的图像。\n",
    "    - GANs已被广泛应用于艺术创作、游戏角色设计、风格转换等领域。\n",
    "    - OpenAI的**DALL·E 3**是这方面的翘楚。\n",
    "    - 其他技术包括**Stable Diffusion**等。\n",
    "  - **风格迁移**：将一种艺术风格应用到一张图像上，例如将一张普通照片转换成梵高风格的画作。\n",
    "    - 包括CycleGAN、AdaIN（Adaptive Instance Normalization）、StyleGAN等。\n",
    "  - **超分辨率**：从低分辨率的图像中创建高分辨率版本，常用于恢复老照片或提高图像质量。\n",
    "- **（2）语音和音频处理**\n",
    "  - **语音识别**：将人的语音转换为文本。这是智能助手和语音控制系统的核心技术。\n",
    "  - **语音合成**：从文本生成语音，即“文本到语音”，用于阅读器、智能助手等。\n",
    "  - **音乐生成**：创造全新的音乐作品，可以是简单的旋律或完整的曲目。\n",
    "  - **声音分类**：识别音频中的特定声音，如区分不同的声音来源或环境声音。\n",
    "  - 最新应用是OpenAI的**GPT-4o**，其人机语音对话体验已经非常接近人与人之间的实时对话。\n",
    "- **（3）自然语言处理（NLP）**\n",
    "  - **机器翻译**：自动将一种语言翻译成另一种语言，如Google翻译。\n",
    "  - **文本分类**：自动将文本分为不同的类别，例如情感分析是判断文本的情感倾向。\n",
    "  - **命名实体识别**：从文本中识别和分类实体（人名、地名、组织名等）。\n",
    "  - **自动摘要**：创建文本的简短摘要，保留主要信息。\n",
    "  - **问答系统**：自动回答用户的问题，常见于在线客服和智能助手。\n",
    "  - **语言生成**：生成连贯、有意义的文本，如编写新闻稿或故事。\n",
    "  - 深度学习在NLP领域的成功应用当属**大语言模型**，其中尤以OpenAI的**ChatGPT**最为突出。\n",
    "- **（4）游戏和模拟**\n",
    "  - **强化学习**：训练AI在游戏或模拟环境中完成特定任务，如玩视频游戏或控制机器人。比如Dota 2等。\n",
    "  - **策略游戏AI**：在如国际象棋或围棋等策略游戏中，训练AI与人类或其他AI竞赛。比如AlphaGo和AlphaZero等。\n",
    "- **（5）视频处理**\n",
    "  - **动作识别**：分析视频来识别其中的人类动作，如行走、跳跃等。具体技术有PoseNet和OpenPose等。\n",
    "  - **视频分类**：识别视频的整体主题或类别，如将视频分为电影、运动或新闻等类别。一些数据集和模型包括YouTube-8M等。\n",
    "  - **视频生成和编辑**：创建新的视频片段或对现有视频进行编辑和增强。\n",
    "    - 比如Adobe的Project Cloak视频编辑工具，利用深度学习来智能删除视频中的不需要的元素，比如删掉穿过场景的物品或者遮挡的人物 \n",
    "- **（6）异常检测**\n",
    "  - **欺诈检测**：在金融交易中识别欺诈行为，保护消费者和银行不受欺诈活动的影响。\n",
    "    - 比如ZestFinance等采用深度学习对借款人的信用风险进行评估。\n",
    "  - **系统入侵检测**：在网络安全中检测未经授权的访问或异常行为。\n",
    "    - 比如Darktrace 提供企业级网络安全解决方案，其系统可以自我学习，检测并响应在线威胁，防止未经授权的访问\n",
    "- **（7）生物信息学和医疗应用**\n",
    "  - **疾病诊断**：从医学图像（如X光片、MRI）中自动诊断疾病。\n",
    "    - DeepMind的眼科疾病诊: DeepMind 与英国国家卫生服务体系（NHS）合作，开发了一种深度学习系统，能够分析眼底扫描图像并准确识别出推动性视网膜疾病。\n",
    "    - PathAI: PathAI 开发了基于深度学习的工具，用于帮助病理学家更准确地诊断疾病，如癌症。它通过分析病理图像，提高了疾病诊断的准确性和效率。\n",
    "  - **药物发现**：加速新药物的发现过程，通过分析化学结构和生物数据。\n",
    "    - Atomwise: Atomwise 使用深度学习技术进行药物研发，利用其 AI 模型预测分子与蛋白质之间的相互作用，加快了新药物的筛选过程。\n",
    "    - Insilico Medicine: 生成新的药物候选分子，针对特定的疾病靶标，加速了药物的发现和开发过程。\n",
    "  - **基因组学**：分析基因数据，用于疾病预测、个性化医疗等。\n",
    "    - DeepVariant: 由Google Brain团队开发，是一个使用深度学习来识别基因组中的变体，如SNPs（单核苷酸多态性）和Indels（插入和删除），从而提高变体的检测准确性。\n",
    "    - AlphaFold: DeepMind 的 AlphaFold 程序成功地预测了蛋白质的3D结构，这对于理解生物体的工作方式和开发新药有着重要意义。\n",
    "- **（8）机器人学**\n",
    "  - **自动驾驶车辆**：让汽车自动驾驶，包括路线规划、障碍物避让等。\n",
    "    - Tesla Autopilot: 应用深度学习算法来实现车辆的自主驾驶功能，包括视觉识别、路线规划以及障碍物识别和避让。\n",
    "    - Waymo:采用深度学习在处理来自雷达、摄像头和激光雷达的输入数据，实现准确的环境感知和决策制定。\n",
    "  - **机器人导航和控制**：使机器人能够在复杂环境中自主导航和执行任务。\n",
    "    - Boston Dynamics: 该公司的Atlas和Spot等技术通过使用深度学习进行图像识别和环境感知，能够灵活地在多种地形中导航并执行复杂任务。\n",
    "    - 大疆无人机: 大疆无人机利用深度学习技术让无人机执行复杂任务，比如自主飞行、避障、目标跟踪等。机器学习方法帮助无人机理解环境并作出快速反应。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 1.3 深度学习关键组件\n",
    "- 深度学习的关键组件包括：可以学习的<b>数据</b>，用于转换和处理数据的<b>模型</b>，用来量化模型有效性的<b>目标函数</b>（在深度学习领域通常称为**损失函数**），调整模型参数以优化目标函数的<b>算法</b>。\n",
    "\n",
    "### 1.3.1 数据\n",
    "\n",
    "- 每个数据集由一个个<b>样本（example, sample）</b>组成，遵循<b>独立同分布</b>。样本有时也叫做<b>数据点（data point）</b>或者<b>数据实例（data instance）</b>，通常每个样本由一组称为<b>特征（features，或协变量（covariates））</b>的属性组成。\n",
    "- 机器学习模型会根据这些属性进行预测。监督学习问题中预测属性称为<b>标签（label，或目标（target））</b>。\n",
    "- 举例：\n",
    "   - 图像数据，每一张单独的照片即为一个样本，它的特征由每个像素数值的有序列表表示。比如，$200\\times200$彩色照片由$200\\times200\\times3=120000$个数值组成，其中的“3”对应于每个空间位置**通道**个数，比如图片的红、绿、蓝3个通道。\n",
    "- 当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的<b>维数（dimensionality）</b>。\n",
    "- 数据量越大，对于深度学习的效果越好；数据的正确性也很重要。\n",
    "- 非均衡数据集。比如数据中包含一些社会偏见时，模型就很有可能有偏见。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "-------------\n",
    "- **说明：何为独立同分布？**\n",
    "  - **独立同分布(independently and identically distributed, i.i.d.)** 是统计学中的一个重要概念，它通常用于描述一组随机变量的性质。\n",
    "    - 1. **独立（Independently）**：在这里，独立意味着变量之间没有相互依赖或关联。也就是说，任何一个变量的取值都不会影响到另一个变量的取值。在更正式的统计学术语中，如果随机变量A的出现不影响随机变量B的概率分布，就可以说A和B是独立的。\n",
    "    - 2. **同分布（Identically Distributed）**：这一部分指的是所有的变量都有相同的概率分布。也就是说，每一个变量都是从同一个分布中随机抽取的，它们共享相同的**平均数（mean）**、**方差（variance）** 、**偏度（skewness）** 等统计性质。\n",
    "  - 当说一组变量是i.i.d.时，意味着这些变量是从同一个概率分布中**独立抽取**的，且每个抽取的过程都**不会影响**到其他的抽取过程或变量的分布情况。\n",
    "  - 在机器学习与数据分析中，理想情况下，数据被**假设**为i.i.d.，这简化了许多模型的训练和预测过程。\n",
    "    - 例如，在训练一个机器学习模型时，通常假设训练数据是i.i.d.的，这意味着每个数据点都能代表整个数据的分布，并且每个点都是独立出现的，避免了数据之间的相互依赖产生偏差。\n",
    "  - 在现实中很多数据都不是严格的i.i.d.，例如时间序列数据，其中相邻的点往往是相关联的，因此在处理非i.i.d.数据时需要采用特定的模型和方法，比如**自回归移动平均模型（Autoregressive Moving Average Model，简称ARMA）** 等。\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 1.3.2 模型\n",
    "- 深度学习与传统机器学习的区别主要在于：深度学习的<b>模型</b>是由神经网络错综复杂交织在一起，包含**层层数据转换**，这也是<b>深度</b>之意的来源。\n",
    "- 深度学习的模型基于人工神经网络的**算法结构**，用于**学习和模拟数据中复杂的模式和关系**。\n",
    "  - 这些模型由多个层次构成，每个层次由一系列的神经元或节点组成。\n",
    "- 模型类型主要包括：\n",
    "  - **卷积神经网络（CNN）：** 特别适合处理图像数据。\n",
    "  - **循环神经网络（RNN）：** 适用于时间序列数据和语言处理。\n",
    "  - **Transformer和注意力机制：** 在自然语言处理领域表现突出。\n",
    "  - **生成对抗网络（GAN）：** 用于生成数据，如图像和音频。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 1.3.3 目标函数\n",
    "\n",
    "- 深度学习模型的优劣程度由<b>目标函数（objective function）</b>或<b>损失函数（loss function，或cost function）</b>进行度量，该函数一般是<b>\"可优化（optimizable）\"</b>的。\n",
    "- 在机器学习和深度学习中，一般需要将目标函数或损失函数优化到<b>最低点</b>(或最高点，二者本质是一样的，将最低点取负就是最高点)。\n",
    "- 最常见的损失函数是<b>平方误差（squared error）</b>，即**预测值**与**实际值**（比如标签）之差的平方。\n",
    "- 当试图解决分类问题时，最常见的目标函数是**最小化错误率**，即预测与实际情况不符的样本比例。\n",
    "- 将一个数据集分割成<b>训练数据集（training dataset)</b>和<b>测试数据集(test dataset)</b>，有时候还要分割出<b>验证数据集(validation dataset)</b>，然后通过训练数据集优化目标函数，当目标函数达到最低值时的参数即是最优参数。\n",
    "- 然后使用测试数据集评估拟合的模型。但是当一个模型在训练集上表现良好，但是在测试集上表现很差时，一般称这个模型是<b>“过拟合”（overfitting）</b>。\n",
    "- 在大多数深度学习场景中，训练所得**最优参数**即是深度学习模型的最终成果。\n",
    "  - 比如大语言模型中的参数文件或权重文件，GPT-4的权重文件据说有1.8万亿个参数。\n",
    "  - 开源的Meta-Llama-3-70B参数文件有112G左右(一说是40G，但是对照其30个参数文件累加后是112G)，参数数量为700亿，具体参见该模型在huggingface上的[模型卡片](https://huggingface.co/meta-llama/Meta-Llama-3-70B)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 1.3.4 优化算法\n",
    "\n",
    "- 算法用于搜索出模型的最佳参数。\n",
    "  - 一般是通过**最小化损失函数**来实现。\n",
    "- 深度学习的优化算法通常基于一种基本方法--<b>梯度下降（gradient descent）<b>。\n",
    "  - 梯度下降的基本原理：在模型训练相关步骤中，梯度下降检查所有参数，然后在可以减少损失的方向上优化参数。\n",
    "- 主要优化算法包括：\n",
    "  - **梯度下降法（gradient descent）：** 是深度学习中最常用的优化算法，可以通过不断优化模型参数来最小化损失函数。\n",
    "  - **随机梯度下降法（stochastic gradient descent）**和**小批量随机梯度下降（minibatch gradient descent）：** 是梯度下降法的变体，通过每次随机选择一部分数据来计算梯度，从而加快训练速度。\n",
    "  - **动量法（momentum）：** 通过积累过去梯度的方向和大小，使优化方向更加稳定，收敛速度更快。\n",
    "  - **自适应学习率算法（adaptive learning rate）：** 如Adagrad、Adadelta和Adam，可以根据训练过程中梯度的变化、历史梯度平方值来自适应地调整学习率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 1.4 机器学习分类\n",
    "### 1.4.1 监督学习（supervised learning）\n",
    "- 概念：\n",
    "  - 在“给定输入**特征**”的情况下预测标签。\n",
    "  - 每个“**特征-标签**”对都称为一个<b>样本</b>。\n",
    "- 实际训练中，为模型提供一个**数据集**，其中每个样本都有真实的**标签**。\n",
    "- 在监督学习中，模型根据样本“**预测估计给定输入特征的标签**”的条件概率。比如：\n",
    "  * 根据计算机断层扫描（CT）肿瘤图像，预测是否为癌症。\n",
    "  * 给出一个英语句子，预测正确的法语翻译。\n",
    "  * 根据本月的财务报告数据，预测下个月股票的价格。\n",
    "    \n",
    "- **监督学习过程：**\n",
    "\n",
    "<center><img src='../img/1_4_1.png' width=500px></center>\n",
    "<center>图1.4.1 监督学习过程</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "#### 1.4.1.1 **回归**\n",
    "- 定义：回归分析是一种建立**自变量（输入特征）** 和 **因变量（目标输出）** 之间关系的统计方法。\n",
    "  - 在机器学习中，回归模型通过学习训练数据中的模式，来预测未知数据的**连续数值**输出。\n",
    "- 在机器学习中，回归模型的学习过程通常包括：\n",
    "  - 选择合适的模型结构。\n",
    "  - 定义损失函数（如均方误差）。\n",
    "  - 使用优化算法（如梯度下降）最小化损失函数。\n",
    "  - 通过迭代调整模型参数，使预测结果与实际值之间的误差最小化。\n",
    "- 任何有关“**多少**”的问题很可能就是回归问题。比如：\n",
    "  * 当地房价是多少？ \n",
    "  * 这个手术需要多少小时？\n",
    "  * 在未来六小时，某地会有多少降雨量？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **加利福利亚住房数据集（California Housing Dataset）**\n",
    "  - 常用的机器学习数据集，尤其应用于回归分析。\n",
    "  - 20,640个样本，每个样本有8个特征变量和1个目标变量。\n",
    "  - 前10条数据样本如下：\n",
    "    \n",
    "| MedInc (中位收入) | HouseAge (房龄) | AveRooms (平均房间数) | AveBedrms (平均卧室数) | Population (人口) | AveOccup (平均占用) | Latitude (纬度) | Longitude (经度) | MedianHouseValue (房屋中位价值) |\n",
    "|-------------------|-----------------|------------------------|------------------------|-------------------|---------------------|-----------------|------------------|----------------------------------|\n",
    "| 3.1250            | 29.0            | 5.2873                 | 1.0810                 | 853.0             | 3.0810              | 37.88           | -122.23          | 170700.0                         |\n",
    "| 4.5625            | 41.0            | 6.1242                 | 0.9735                 | 1102.0            | 2.8842              | 37.86           | -122.22          | 212500.0                         |\n",
    "| 3.8750            | 21.0            | 5.8900                 | 1.1290                 | 741.0             | 2.7179              | 37.85           | -122.24          | 194200.0                         |\n",
    "| 5.0000            | 52.0            | 6.3750                 | 1.0810                 | 1005.0            | 2.6981              | 37.84           | -122.25          | 242500.0                         |\n",
    "| 2.7500            | 37.0            | 4.9280                 | 1.0568                 | 697.0             | 3.1250              | 37.85           | -122.26          | 140000.0                         |\n",
    "| 4.1875            | 46.0            | 5.5461                 | 1.0809                 | 929.0             | 2.9405              | 37.83           | -122.27          | 205600.0                         |\n",
    "| 3.6250            | 33.0            | 5.7321                 | 1.1029                 | 812.0             | 2.8056              | 37.84           | -122.28          | 187500.0                         |\n",
    "| 5.3125            | 18.0            | 6.7654                 | 1.0230                 | 1158.0            | 2.5478              | 37.82           | -122.24          | 268400.0                         |\n",
    "| 4.8750            | 25.0            | 6.0123                 | 1.0987                 | 1024.0            | 2.7234              | 37.81           | -122.25          | 235000.0                         |\n",
    "| 3.3750            | 34.0            | 5.4567                 | 1.1123                 | 789.0             | 3.0345              | 37.83           | -122.26          | 178900.0                         |\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "#### 1.4.1.2 **分类**\n",
    "- 定义：希望模型能够预测样本属于哪个**类别（category，正式称为类class）**。\n",
    "  - 最简单的分类问题是只有两类，称之为<b>二元分类(binary classification)</b>。例如，数据集可能由动物图像组成，标签可能是{猫, 狗}两类。\n",
    "  - 当分类标签有两个以上的类别时，称为<b>多元分类（multiclass classification）</b>问题。常见的例子包括手写字符识别：$\\mathrm{\\{0, 1, 2, ... 9, a, b, c, ...\\}}$。\n",
    "  - 在回归中训练一个回归函数来输出一个数值；而在分类中是训练一个分类器，它的输出即为**预测的类别**。\n",
    "  - 分类问题的常见损失函数被称为<b>交叉熵（cross-entropy）</b>。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **鸢尾花数据集(Iris Dataset)**\n",
    "  - 机器学习和统计学中最为著名的数据集之一。\n",
    "  - 该数据集包含了三种不同品种的鸢尾花的测量数据，是分类和聚类算法的经典测试数据集。\n",
    "    - 样本数量：150个样本\n",
    "    - 特征数量：4个特征\n",
    "    - 类别数量：3个类别（每类50个样本）\n",
    "  - 特征包括：\n",
    "    - sepal length (cm) - 花萼长度（厘米）\n",
    "    - sepal width (cm) - 花萼宽度（厘米）\n",
    "    - petal length (cm) - 花瓣长度（厘米）\n",
    "    - petal width (cm) - 花瓣宽度（厘米）\n",
    "  - 类别包括：\n",
    "    - Iris Setosa - 山鸢尾\n",
    "    - Iris Versicolour - 变色鸢尾\n",
    "    - Iris Virginica - 维吉尼亚鸢尾\n",
    "  - 数据示例：\n",
    "\n",
    "| sepal length (cm)<br>花萼长度（厘米） | sepal width (cm)<br>花萼宽度（厘米） | petal length (cm)<br>花瓣长度（厘米） | petal width (cm)<br>花瓣宽度（厘米） | species<br>种类 |\n",
    "|---------------------------------------|-------------------------------------|---------------------------------------|-------------------------------------|-----------------|\n",
    "| 6.5                                   | 2.8                                 | 4.6                                   | 1.5                                 | versicolor      |\n",
    "| 5.7                                   | 2.8                                 | 4.5                                   | 1.3                                 | versicolor      |\n",
    "| 6.3                                   | 3.3                                 | 4.7                                   | 1.6                                 | versicolor      |\n",
    "| 4.9                                   | 2.4                                 | 3.3                                   | 1.0                                 | versicolor      |\n",
    "| 6.6                                   | 2.9                                 | 4.6                                   | 1.3                                 | versicolor      |\n",
    "| 5.2                                   | 2.7                                 | 3.9                                   | 1.4                                 | versicolor      |\n",
    "| 6.3                                   | 3.3                                 | 6.0                                   | 2.5                                 | virginica       |\n",
    "| 5.8                                   | 2.7                                 | 5.1                                   | 1.9                                 | virginica       |\n",
    "| 7.1                                   | 3.0                                 | 5.9                                   | 2.1                                 | virginica       |\n",
    "| 6.3                                   | 2.9                                 | 5.6                                   | 1.8                                 | virginica       |\n",
    "| 6.5                                   | 3.0                                 | 5.8                                   | 2.2                                 | virginica       |\n",
    "| 7.6                                   | 3.0                                 | 6.6                                   | 2.1                                 | virginica       |\n",
    "| 4.9                                   | 2.5                                 | 4.5                                   | 1.7                                 | virginica       |\n",
    "| 7.3                                   | 2.9                                 | 6.3                                   | 1.8                                 | virginica       |\n",
    "| 6.7                                   | 2.5                                 | 5.8                                   | 1.8                                 | virginica       |\n",
    "| 7.2                                   | 3.6                                 | 6.1                                   | 2.5                                 | virginica       |\n",
    "| ...                                   | ...                                 | ...                                   | ...                                 | ...             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "#### 1.4.1.3 其他监督学习问题\n",
    "- <b>标记问题</b>：学习预测不相互排斥的类别的问题称为**多标签分类（multi-label classification）**。\n",
    "  - 技术博客上贴的标签，比如“机器学习”、“技术”、“小工具”、“编程语言”、“Linux”、“云计算”、“AWS”。\n",
    "  - 一篇典型的文章可能会用5-10个标签。\n",
    "- <b>搜索</b>： 首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素。\n",
    "  - 其中最典型的例子就是谷歌搜索引擎所使用的算法**PageRank**。\n",
    "  - PageRank算法是一种由谷歌的创始人拉里·佩奇和谢尔盖·布林开发的网页排名算法。\n",
    "  - 其核心思想是基于网页之间的超链接关系来评估它们的重要性。\n",
    "- <b>推荐系统</b>：向特定用户进行“个性化”推荐。比如电子商务网站向用户推荐商品。\n",
    "  - 推荐系统算法经过优化，可以捕捉用户的偏好。\n",
    "  - 关于如何处理审查、激励和反馈循环的许多问题，都是重要的开放性研究问题。\n",
    "- <b>序列学习</b>：\n",
    "  - 通常情况下序列学习的输入和输出都是可变长度的序列。\n",
    "  - 最典型的应用包括：标记解析、机器翻译、自动语音识别、文本到语音转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 无监督学习\n",
    "- 概念：数据中**不含有“目标”** 的机器学习问题通常被为<b>无监督学习（unsupervised learning）</b>\n",
    "- 包括：\n",
    "  - **聚类（clustering）**\n",
    "  - **主成分分析（principal component analysis）**\n",
    "  - **因果关系（causality）和概率图模型（probabilistic graphical models）**\n",
    "  - **生成对抗性网络（generative adversarial networks）**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 深度学习中的监督学习与无监督学习\n",
    "  - **卷积神经网络（CNN）** 在图像分类任务中的应用属于监督学习类型。训练数据包括大量标记了类别的图像，模型通过学习这些标记来识别新图像的类别。\n",
    "  - **自编码器（Autoencoder）** 用于降维和特征提取，属于无监督学习类型。自编码器学习将输入数据压缩到低维表示，再从低维表示重构出原始数据，从而捕捉数据的主要特征。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 1.5 深度学习发展历程\n",
    "\n",
    "- 互联网的高速发展积累**大规模数据集**。\n",
    "- 廉价又高质量的传感器、数据存储、廉价计算芯片（摩尔定律），**GPU**等等，积累的大规模算力。\n",
    "  - 摩尔定律：计算机处理器的性能每18到24个月翻一番，或芯片单位面积上的晶体管数量翻一番。\n",
    "- 数据集vs计算机内存和计算能力：\n",
    "\n",
    "| 年代 | 数据规模              | 内存   | 每秒浮点运算        |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| 1970 | 100 （鸢尾花）      | 1 KB   | 100 KF (Intel 8080) |\n",
    "| 1980 | 1 K （波士顿房价）    | 100 KB | 1 MF (Intel 80186)  |\n",
    "| 1990 | 10 K （光学字符识别） | 10 MB  | 10 MF (Intel 80486) |\n",
    "| 2000 | 10 M （网页）         | 100 MB | 1 GF (Intel Core)   |\n",
    "| 2010 | 10 G （广告）         | 1 GB   | 1 TF (Nvidia C2050) |\n",
    "| 2020 | 1 T （社交网络）      | 100 GB | 1 PF (Nvidia DGX-2) |\n",
    "\n",
    "- 机器学习和统计的关注点从（广义的）线性模型和核方法转移到了深度神经网络。\n",
    "- 算法：多层感知机 、卷积神经网络、长短期记忆网络、Q学习。\n",
    "- 深度学习框架：\n",
    "  - [Caffe](https://github.com/BVLC/caffe)\n",
    "  - [Torch](https://github.com/torch)\n",
    "  - [Theano](https://github.com/Theano/Theano)\n",
    "  - [TensorFlow](https://github.com/tensorflow/tensorflow)\n",
    "  - [Keras](https://github.com/keras-team/keras)\n",
    "  - [CNTK](https://github.com/Microsoft/CNTK)\n",
    "  - [Caffe 2](https://github.com/caffe2/caffe2)\n",
    "  - [Apache MXNet](https://github.com/apache/incubator-mxnet)\n",
    "  - [Chainer](https://github.com/chainer/chainer)\n",
    "  - [Gluon API](https://github.com/apache/incubator-mxnet)\n",
    "  - [Jax](https://github.com/google/jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "- **说明：\"Torch\"和\"PyTorch\"的区别与联系**\n",
    "  - \"Torch\"和\"PyTorch\"在机器学习和深度学习领域都是非常知名的库，它们之间既有联系也有区别。\n",
    "  - **Torch：** Torch是一个科学计算框架，提供了广泛的算法来创建机器学习应用。它主要使用 Lua 语言进行编程，这是一种轻量级的脚本语言。它最大的特点是有一个强大的N维数组，并且支持面向GPU的编程，使得数据操作和计算可以快速进行。Torch 在神经网络、计算机视觉以及数字信号处理等领域被广泛使用。\n",
    "  - **PyTorch：** PyTorch 是 Torch 的一个衍生版本，它由Facebook的人工智能小组开发。PyTorch 继承了 Torch 的很多特性，并且采用Python 作为编程语言，结合了强大的计算能力和 Python 的易用性。它提供了两个高级特性：一是动态计算图（称为动态神经网络），它允许用户在运行时改变计算图的行为；二是自动微分系统（称为Autograd），使得神经网络的反向传播变得简单。PyTorch也被广泛应用在研究和工业界，尤其是被视为友好的研究平台，因为它的灵活性更适合快速原型设计和实验。\n",
    "  - **联系：**\n",
    "    - PyTorch 是基于 Torch 的理念构建的，两者都是面向神经网络设计和深度学习的框架。\n",
    "    - PyTorch 保留了 Torch 的很多核心功能，比如张量计算和GPU加速。\n",
    "  - **区别：**\n",
    "    - 编程语言不同：Torch 主要使用 Lua 语言，而 PyTorch 使用 Python。\n",
    "    - 设计理念不同：PyTorch 提供了动态计算图和自动微分功能，使得模型设计更加灵活和便捷。\n",
    "    - 用户群体不同：虽然两者都被研究和工业界使用，PyTorch 由于更符合人工智能和机器学习社区的流行语言习惯（Python），所以其用户基础更广泛且正在快速增加。\n",
    "    - 由于 Python 的流行和 PyTorch 的这些优势，PyTorch 已经成为了深度学习领域一个非常流行的选择，而 Torch 现在较少被新项目采用。\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。\n",
    "* 表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。\n",
    "  * 所谓表示学习就是关注如何从原始数据中自动学习到有效的**特征表示**,以便于后续的学习任务。\n",
    "* 深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。\n",
    "* 最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（通过GPU）算力的突破来触发的。\n",
    "* 整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
